{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javmencia/COBWEBfiles/blob/main/STA410_Week8_HW8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c83339c",
      "metadata": {
        "id": "5c83339c"
      },
      "source": [
        "# STA410 Week 8 Homework (4 points)\n",
        "\n",
        "Due 12 PM Feb 28 (before class starts)\n",
        "\n",
        "\n",
        "1. **Paired or individual assignment.** Work may be shared within pairs without restriction, but collaborations beyond the pairs must be limited to \"hints\" and may not share complete solutions.\n",
        "\n",
        "\n",
        "2. You are encouraged to adapt code you find available online **(including using AI chat bot suppport tools)** into your notebook; however, if you do so please provide a link to the utilized resource. ***If you don't and multiple students have the same answer an academic integrity proceeding may be undertaken.***  \n",
        "\n",
        "\n",
        "3. **Library imports are limited** to only libraries imported in the starter code and the [standard python modules](https://docs.python.org/3/py-modindex.html). Automated code tests that fail because of additional library imports will not recieve credit. Unless a problem instructs differently you may use any functions available from the Python stdlib and the libraries imported in the starter code.\n",
        "\n",
        "\n",
        "<details><summary><span style=\"color: blue; text-decoration: underline; cursor: pointer;\">Additional Details</span></summary>\n",
        "\n",
        "> **Do not delete, replace, or rearranged cells.** This erases `cell ids` upon which automated code tests are based. The \"Edit > Undo Delete Cells\" option in the notebook editor might be helpful; otherwise, redownload the notebook (so it has the correct required `cells ids`) and repopulate it with your answers (assuming you don't overwrite them when you redownload the notebook). ***You may add cells for scratch work*** but if required answers are not submitted through the provided cells where the answers are requested your answers may not be marked. Due to potential problems with `cell ids` **the only environments supported in this class are** [UofT JupyterHub](https://datatools.utoronto.ca/) or [Google Colab](https://colab.research.google.com/)\n",
        ">\n",
        "> **No jupyter shortcut commands** such as `! python script.py 10` or `%%timeit` may be included in the final submission as they will cause subsequent automated code tests to fail.\n",
        ">\n",
        "> **No cells may have any runtime errors** because this causes subsequent automated code tests to fail and you will not get marks for tests which fail because of previous runtime errors. ***Restart and re-run the cells in your notebook to ensure there are no runtime errors before submitting your work.***\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6009d48a",
      "metadata": {
        "id": "6009d48a"
      },
      "source": [
        "## Student and Contribution\n",
        "\n",
        "Are you working with a partner to complete this assignment?  \n",
        "- If not, assign  the value of `None` into the variable `Partner`.\n",
        "- If so, assign the name of the person you worked with into the variable `Partner`.\n",
        "    - Format the name as `\"<First Name> <Last Name>\"` as a `str` type, e.g., \"Scott Schwartz\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9e558c4d",
      "metadata": {
        "id": "9e558c4d"
      },
      "outputs": [],
      "source": [
        "Partner = None\n",
        "# This cell will produce a runtime error until you assign a value to this variable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d8b75ad",
      "metadata": {
        "id": "7d8b75ad"
      },
      "source": [
        "What was your contribution in completing the code for this assignments problems?  \n",
        "Assign one of the following into each of the `Contribution` variable below.\n",
        "\n",
        "- `\"I worked alone\"`\n",
        "- `\"I contributed more than my partner\"`\n",
        "- `\"My partner and I contributed equally\"`\n",
        "- `\"I contributed less than my partner\"`\n",
        "- `\"I did not contribute\"`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3b3b54a2",
      "metadata": {
        "id": "3b3b54a2"
      },
      "outputs": [],
      "source": [
        "Contribution = \"I worked alone\"\n",
        "# This cell will produce a runtime error until you assign a value to this variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "51be707a",
      "metadata": {
        "id": "51be707a"
      },
      "outputs": [],
      "source": [
        "# you may use any functions available from the following library imports\n",
        "\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "692b7c21",
      "metadata": {
        "id": "692b7c21"
      },
      "source": [
        "## Part 1: Bases<br><sub>Coordinate System based Representations</sub>\n",
        "\n",
        "An interpretation of $A_{n\\times m}x_{m\\times 1} = b_{n\\times 1}$ is that point $b$ in $n$-dimensional space can be expressed in terms of the coordinates $x_j$ with respect to the axes of $m$-dimensional space defined by the column vectors $A_{\\cdot j}$ of $A$\n",
        "\n",
        "$$b = \\underset{\\quad\\;\\;\\textrm{the so-called }\\textbf{standard basis}\\textrm{ vectors }e_i}{b_1 \\left[ \\begin{array}{c}1\\\\0\\\\\\vdots\\\\0 \\end{array}\\right] + b_2 \\left[ \\begin{array}{c}0\\\\1\\\\\\vdots\\\\0 \\end{array}\\right] + \\cdots + b_n \\left[ \\begin{array}{c}0\\\\0\\\\\\vdots\\\\1 \\end{array}\\right]} = \\sum_{i=1}^m b_i e_{i} = \\sum_{j=1}^m x_j A_{\\cdot j} = Ax$$\n",
        "\n",
        "> Another important **basis** is the **eigenvector basis** where for\n",
        "> - $A_{n\\times n} V_{\\cdot j} = \\lambda_j V_{\\cdot j}$ or $(A_{n\\times n} - \\lambda_j I) V_{\\cdot j} = 0$\n",
        "> - $x = \\sum_{j} c_j V_{\\cdot j}$\n",
        ">$$Ax= A\\left(\\sum_{j} c_j V_{\\cdot j}\\right) = \\sum_{j} c_j A  V_{\\cdot j} = \\sum_{j} c_j \\lambda_j V_{\\cdot j}$$\n",
        "> analyzes the rate of the expansion (and/or contraction) along the invariant directions of the transformation $A$.\n",
        "\n",
        "---\n",
        "\n",
        "The columns of $V$ of the **approximate SVD** $X_{n\\times m} \\approx U_{n\\times d}D_{d\\times d}[V^T]_{d\\times m}$ generally define a **non-standard basis** in which the (row) coordinates of $X$ are re-expressed as $x_i \\approx V(Du_i)$. The points $Du_i$ with respect to the constraints of the $V$ **basis** in which they are representated are (in some sense) \"close\" to their corresponding $x_i$.\n",
        "\n",
        "> Principal components analysis (PCA) and principal components regression (PCR) are based on the **SVD**.\n",
        "\n",
        "The **approximation** used above indicates that the $V$ **basis** cannot perfectly represent the (row) coordinates $X$ (as a result of a lack of equivalence between the **span** of the $V$ **basis** and the **span** of the **standard basis**).\n",
        "\n",
        "> Recall another recently encountered **appoximation** $ \\underset{\\textrm{floating-point representation}}{y = 2^p\\times(1 + \\sum_{i=1}^{52} b_i2^{-i})} $ for integer $|p| \\leq 1023$.\n",
        "\n",
        "A further recently encountered **approximation** is $X \\hat \\beta = \\sum_{j=1}^p X_{\\cdot j} \\hat \\beta_j = \\hat y = X(X^TX)^{-1}X^Ty \\approx y$\n",
        "\n",
        "> The \"hat matrix\" $H = X(X^TX)^{-1}X^T$ \"puts the hat on $y$\" via $Hy=\\hat y$ and is a **projection matrix** projecting $y$ onto the **column space** of $X$ (the **span** of the **basis** formed by the columns of $X$) **orthogonally** in the sense that $X(y - \\hat y)=0$ so the **resdiual** $\\epsilon = (y - \\hat y)$ cannot be represented in the **span** of $X$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5a468b51",
      "metadata": {
        "id": "5a468b51"
      },
      "outputs": [],
      "source": [
        "p1q1 = \"Basis vectors must be C\"\n",
        "# A: orthogonal\n",
        "# B: orthonormal\n",
        "# C: linearly independent\n",
        "# D: all of the above\n",
        "\n",
        "p1q2 = \"An eigenvector basis corresponding to distinct eigenvalues must be C\"\n",
        "# Same options as above\n",
        "\n",
        "p1q3 = \"An eigenvector basis for $X^TX$ for full rank $X$ must be B\"\n",
        "# Same options as above\n",
        "\n",
        "p1q4 = \"The basis vectors (relative to row x_i) from SVD of full rank X are B\"\n",
        "# Same options as above\n",
        "\n",
        "p1q5 = \"The columns of U of a SVD X (relative to row x_i) are \"+\\\n",
        "       \"known as the principal components of X and are B\"\n",
        "# Same options as above\n",
        "\n",
        "p1q6 = \"The singular values of full rank X are the square root \"+\\\n",
        "       \"as the egivenvalues of the gramian X.T@X and are \"+\\\n",
        "       \"all positive\"\n",
        "\n",
        "p1q7 = \"The egivenvalues of the gramian X.T@X of full rank X are \"+\\\n",
        "       \"all positive making \"+\\\n",
        "       \"the gramian postive \"+\\\n",
        "       \"definite\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "61dec2f3",
      "metadata": {
        "id": "61dec2f3"
      },
      "outputs": [],
      "source": [
        "p1q8 = 'The \"hat\" matrix is symmetric due to A'\n",
        "# A: (AB)^T = B^TA^T and A^{-T} = (A^{-1})^T = (A^T)^{-1}\n",
        "# B: X.T@X(X.T@X)^{-1} = I\n",
        "# C: A and B\n",
        "# D: none of the above\n",
        "\n",
        "p1q9 = 'The \"hat\" matrix is idempotent due to C'\n",
        "# Same options as above\n",
        "\n",
        "p1q10 = 'The projection of the \"hat\" matrix is not orthogonal '+\\\n",
        "        'due to D'\n",
        "# Same options as above\n",
        "\n",
        "p1q11 = 'The \"hat\" projection matrix is not an orthogonal basis'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0d0e44c6",
      "metadata": {
        "id": "0d0e44c6"
      },
      "outputs": [],
      "source": [
        "p1q12 = \"For 𝑦≈𝑋𝛽̂ above taken as an analog of b=Ax above \"+\\\n",
        "        \"The basis for the 𝛽̂ representation of y is A\"\n",
        "# A: the columns of X\n",
        "# B: the rows of X\n",
        "# C: the columns of V from the SVD of X\n",
        "# D: the columns of U from the SVD of X\n",
        "\n",
        "p1q13 = \"The basis vectors used to represent 𝐻𝑦=𝑦̂ must be C\"\n",
        "# A: orthogonal\n",
        "# B: orthonormal\n",
        "# C: linearly independent\n",
        "# D: all of the above\n",
        "\n",
        "p1q14 = \"If we perform PCR using U from the SVD of X rather than X \"+\\\n",
        "        \"the basis vectors used to represent 𝐻𝑦=𝑦̂ must be B\"\n",
        "# Same options as above\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "61ac6f7f",
      "metadata": {
        "id": "61ac6f7f"
      },
      "outputs": [],
      "source": [
        "p1q15 = \"As oppposed to PCA, independent components analysis (ICA) \"+\\\n",
        "        \"seeks to represent X in a basis which is C\"\n",
        "# A: orthogonal\n",
        "# B: orthonormal\n",
        "# C: linearly independent\n",
        "# D: none of the above\n",
        "\n",
        "p1q16 = \"For X_nXp representing n samples from a p-dimensional \"+\\\n",
        "        \"multivariate normal distribution, statistical independence \"+\\\n",
        "        \"is equivalent to C\"\n",
        "# A: linearly independent columns of X\n",
        "# B: orthogonality of the columns of X\n",
        "# C: uncorrelated random variables X_ij\n",
        "# D: none of the above\n",
        "\n",
        "p1q17 = 'For X_nXp representing n samples from a p-dimensional '+\\\n",
        "        'multivariate normal distribution, the columns of U (also known as \"principle components\") from the SVD of X '+\\\n",
        "        '(which has been \"centered and scale standardized\") can be used '+\\\n",
        "        \"to estimate a p-dimensional multivariate normal distribution \"+\\\n",
        "        \"which will have mean $0$ and covariance $U^TU$ and hence the \"+\\\n",
        "        \"columns of U are D\"\n",
        "# A: linearly independent\n",
        "# B: empirically statistically independent\n",
        "# C: empirically uncorrelated\n",
        "# D: all of the above\n",
        "\n",
        "p1q18 = 'Through U of the SVD, PCA creates random variables in U columns that '+\\\n",
        "        \"are empirically observed to be A which in conjunction with an \"+\\\n",
        "        \"assumption that the data has a multivariate normal distribution means \"+\\\n",
        "        \"the random variables in U column data is empirically observed to be C\"\n",
        "# A: linearly independent\n",
        "# B: statistically independent\n",
        "# C: uncorrelated\n",
        "# D: none of the above\n",
        "\n",
        "p1q19 = 'In contrast to PCA which seeks to \"decorrelate\" the covariance structure '+\\\n",
        "        \"of random variables, ICA presumes each (row) observation is comparised of \"+\\\n",
        "        \"a weighted sum of B random variables and seeks to identify the \"+\\\n",
        "        \"actualizations of these random variables and their relative contributions \"+\\\n",
        "        \"to each (row) observation\"\n",
        "# A: linearly independent\n",
        "# B: statistically independent\n",
        "# C: uncorrelated\n",
        "# D: all of the above\n",
        "\n",
        "p1q20 = 'PCA finds linear combinations (\"basis directions\") for the data '+\\\n",
        "        'which maximize B while ICA finds \"basis directions\" '+\\\n",
        "        \"which maximize D which means PCA can be most effective \"+\\\n",
        "        \"when the data is the most approximately like a \"+\\\n",
        "        \"multivariate normal distribution; wheres, ICA can be the most \"+\\\n",
        "        \"when the data is the least approximately like a \"+\\\n",
        "        \"multivariate normal distribution\"\n",
        "\n",
        "# A: the first moment\n",
        "# B: the second moment (variance)\n",
        "# C: the third moment (skew)\n",
        "# D: the fourth moment (kurtosis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2b7e736",
      "metadata": {
        "id": "a2b7e736"
      },
      "source": [
        "## Part 2: Function Spaces<br><sub>as opposed to Vector Spaces</sub>\n",
        "\n",
        "The **approximation** $X \\hat \\beta = \\sum_{j=1}^p X_{\\cdot j} \\hat \\beta_j = \\hat y = X(X^TX)^{-1}X^Ty \\approx y$ can be generalized in terms of the **basis functions** $b_{k}(x_{ij})$ used to contruct the **basis vector** columns of the **design matrix** $X$.\n",
        "\n",
        "$$\\hat y_i =  \\sum_{j=1}^p \\hat \\beta_{jk} b(x_{ij}) \\approx \\sum_{k=1}^\\infty \\sum_{j=1}^p \\hat \\beta_j b_k(x_{ij}) = y_i$$\n",
        "\n",
        "> The most commonly encountered **basis functions** are the **monomials**\n",
        "> - $b_1(x_{ij}) = x_{ij}, \\; b_2(x_{ij}) = x_{ij}^2, \\; b_3(x_{ij}) = x_{ij}^3,$ etc.  \n",
        "> where using only $b(x_{ij}) = b_1(x_{ij}) = x_{ij}$ recovers the columns of the original design matrix $X$.\n",
        ">\n",
        "> > The **inner product** for numeric vectors is the **dot product** $x^Ty$\n",
        "and two numeric vectors are **orthogonal** if their dot product is $0$.\n",
        "> > The **inner product** for functions is analogously\n",
        "> >\n",
        "> > $$\\langle f(x), g(x) \\rangle = \\int f(x)g(x)w(x)dx$$\n",
        "> >\n",
        "> > so that every point in the functions are multiplied by each other and all these evaluations are accumulated together over the integral (with respect to **weight function** $w(x)$).\n",
        "> >\n",
        "> > The analytical $\\langle f(x), g(x) \\rangle$ calculation would, assuming a **uniform weight function** $w(x)$, be discretely approximated as the dot product `fx.dot(gx)`.\n",
        ">\n",
        "> The **monomials** are not **orthogonal** functions for a **uniform weight function** over $[0,1]$.\n",
        "\n",
        "\n",
        "The $b_k(x_{ij})$ **basis functions** define the **basis vectors** (columns of the **design matrix**) used in the representation of $\\hat y$ (given by coordinate $\\hat \\beta$). But the complete transition from a **vector space** to a **function space** occurs as a result of the two **limits**\n",
        "\n",
        "$$n \\longrightarrow \\infty \\textrm{ (relative to index $i$) } \\quad \\textrm{ and } \\quad k \\longrightarrow \\infty $$\n",
        "\n",
        "which convey the notion that the limit of the vector `fx = f(x)` for `x = np.linspace(a, b, num=n)` as $n \\rightarrow \\infty$ is the function $f$ defined by `f(x)`, and that for $y$ of size $n$ the dimension of the **vector/function space** which can perfectly represent must be $k\\equiv n \\rightarrow \\infty$.\n",
        "\n",
        "\n",
        "\n",
        "<!-- $\\sum_{k=0}^p \\langle f, b_k \\rangle b_k \\approx \\sum_{k=0}^\\infty \\langle f, b_k \\rangle b_k$ -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa998308",
      "metadata": {
        "id": "fa998308"
      },
      "source": [
        "### Order-k Lagrange Piecewise Polynomial\n",
        "\n",
        "Write a function `construct_Lagrange_piecewise_polynomial(x, y, order)` which returns function that\n",
        "**interpolates** the points $\\{(x_{(i)},y_{(i)}): i= 1,\\cdots,n\\}$\n",
        "\n",
        "- where this indexing indicates \"sorting by $x$\"\n",
        "- so $x_{(i)} < x_{(j)}$ for $i<j$ with $y_{(j)}$ corresponding to $x_{(j)}$\n",
        "\n",
        "based on the piecewise continuous concatentation of $m$ **order-k Lagrange polynomials**\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "   h(w) = {} & \\left[\\overset{\\text{Piecewise}}{\\underset{\\text{summation}}{ \\sum_{g=0}^{m-1}}} \\underset{\\textrm{defined for } w\\, \\in\\, \\left[x_{\\left(gk^\\vphantom{1pt}\\right)},\\, x_{\\left(gk+k^\\vphantom{1pt}\\right) } \\right) }{\\overset{\\textbf{Order-k Lagrange polynomial}}{{ \\sum_{j=0}^{k} y_{(gk+j)} l_{gj}(w)} }} \\right] + \\underset{\\text{so } h(x_{(n)}) = y_{(n)}}{y_{(n)} 1_{x_{(n)}}(w)}  \\\\\n",
        "   l_{gj}(w) = {} & \\underset{i \\neq gk+j \\; \\leftarrow \\textrm{ exclude $\\div$ by $0 \\,$ } }{\\prod_{i = gk}^{(g+1)k} { \\frac{w-x_{(i)}}{x_{(gk+j)}-x_{(i)}}}}  \\underset{ 1_A(a)=1 \\text{ if } a\\in A; \\text{ else $0$}}{\\times\\; 1_{\\left[x_{\\left(gk^\\vphantom{1pt}\\right)},\\, x_{\\left(gk+k^\\vphantom{1pt}\\right) } \\right)}(w)}  \n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "The $g$ indexes $m$ \"groups\" of subsets of $k$ sequential data points, which share \"overlapping\" endpoints with their \"previous\" and \"next\" groups as follows.\n",
        "\n",
        "$$\\begin{array}{c|ccc|ll}\n",
        "g & +0 & \\cdots & +k & \\text{basis functions} & \\text{domain} \\\\\\hline\n",
        "0 & x_{(0)} & \\cdots & x_{(k)} & l_{00},\\cdots, l_{0k} & \\left[x_{(0)}, x_{(k)}\\right)\\\\\n",
        "1 & x_{(k)} & \\cdots & x_{(2k)} & l_{10},\\cdots, l_{1k}& \\left[x_{(k)}, x_{(2k)}\\right)\\\\\n",
        "\\vdots\\\\\n",
        "g & x_{(gk)} & \\cdots & x_{(gk+k)}& l_{g0},\\cdots, l_{gk}& \\left[x_{(gk)}, x_{(gk+k)}\\right)\\\\\n",
        "\\vdots &\\\\\n",
        "m-2 & x_{(n-2k)} & \\cdots & x_{(n-k)} & l_{(m-2)0},\\cdots, l_{(m-2)k}& \\left[x_{(n-2k)}, x_{(n-k)}\\right)\\\\\n",
        "m-1 & x_{(n-k)} & \\cdots & x_{(n)} & l_{(m-1)0},\\cdots, l_{(m-1)k}& \\left[x_{(n-k)}, x_{(n)}\\right]\\\\\n",
        "\\end{array}$$\n",
        "\n",
        "Each $l_{gj}(w)$ is the $j^{th}$ of $k+1$ ***Lagrange polynomial basis function*** defined over the domain of the $g^{th}$ group (of $m$ total groups).\n",
        "\n",
        "> Mapping a function through points, as is done here by the **Lagrange piecewise polynomial** is called **interpolation** and this is distinct from **approximation** in which a truncated series is used to provide a reduced representation of an object. Both of these are again distinct from **estimation**, in which the parameters indexing a family of functional forms are chosen so the resulting function resembles observed data points. And finally, these are all again distinct from **smoothing**, in which the family of functional forms is chosen to be simple and parsimonious and yet still capable of representating the important characteristics of the data.\n",
        ">\n",
        "> *This problem and conlcuding comments are inspired by **Lagrange polynomials** in the **Models for Interpolation** and **Models for Smoothing Data** sections of Chapter 4.1 **Function Approximation and Smoothing** on pages 154-156 and 157 and the paragraphs in the **introduction** and **Estimation** sections of Chapter **Approximation of Functions** on page 147 and 162 of James E. Gentle's **Computational Statistics** textbook. [Errata Warning: on page 156, cubic Lagrange polynomials join four adjacent points, not three; and, piecewise Lagrangian polynomials are not necessarily smooth at knots.]*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dfeb31b",
      "metadata": {
        "id": "9dfeb31b"
      },
      "source": [
        "### Lagrange Polynomials\n",
        "\n",
        "An ***order-k Lagrange polynomial basis function*** is $\\displaystyle l_j(w) = \\prod_{i=0, i \\not = j}^k \\frac{w-x_{(i)}}{x_{(j)}-x_{(i)}}$.\n",
        "\n",
        "An ***order-k Lagrange polynomial function*** is $h(w) = \\displaystyle \\sum_{j=0}^k y_{(j)} l_j(w)$.\n",
        "\n",
        "Before attempting to create the `construct_Lagrange_piecewise_polynomial` function first define the\n",
        "- `construct_jth_Lagrange_basis_function` and\n",
        "- `construct_Lagrange_polynomial` functions\n",
        "\n",
        "and confirm the correctness of your function by verifying graphically that the **Lagrange polynomial** correctly travels through `x` and `y` with\n",
        "\n",
        "```python\n",
        "x,y = np.sort(stats.norm.rvs(size=5)), stats.norm.rvs(size=5)\n",
        "plt.plot(x,y,'r.')\n",
        "grid = np.linspace(x[0],x[-1], 100)\n",
        "for j in range(len(x)):\n",
        "    plt.plot(grid, construct_jth_Lagrange_basis_function(j, x)(grid), 'k--')\n",
        "plt.plot(grid, construct_Lagrange_polynomial(x,y)(grid))\n",
        "#check the above first, before expanding it to the piecewise version below\n",
        "#plt.plot(grid, construct_Lagrange_piecewise_polynomial(x, y, order=2)(grid))\n",
        "#plt.plot(grid, construct_Lagrange_piecewise_polynomial(x, y, order=1)(grid))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "118a05a8",
      "metadata": {
        "id": "118a05a8"
      },
      "outputs": [],
      "source": [
        "def construct_jth_Lagrange_basis_function(j, x):\n",
        "    # order will be len(x)-1\n",
        "    @np.vectorize  # function should accept w an np.array while it is\n",
        "    def jth_Lagrange_basis_function(w): # defined as if for scalar w\n",
        "        num = np.ones(len(x))\n",
        "        den = np.ones(len(x))\n",
        "        num[j] = w - x[j]\n",
        "        den[j] = x[j] - x[j]\n",
        "        for i in range(len(x)):\n",
        "            if i != j:\n",
        "                num[i] = w - x[i]\n",
        "                den[i] = x[i] - x[j]\n",
        "        return np.prod(num)/np.prod(den)\n",
        "    return jth_Lagrange_basis_function\n",
        "\n",
        "def construct_Lagrange_polynomial(x,y):\n",
        "    # the sum of the j Lagrange basis function each evaluated at w\n",
        "    @np.vectorize  # function should accept w an np.array while it is\n",
        "    def Lagrange_polynomial(w):  # defined as if for scalar w\n",
        "        num = np.zeros(len(x))\n",
        "        for j in range(len(x)):\n",
        "            num[j] = y[j]*construct_jth_Lagrange_basis_function(j, x)(w)\n",
        "        return np.sum(num)\n",
        "        #        return sum(y[j] * construct_jth_Lagrange_basis_function(j, x)(w) for j in range(len(x)))\n",
        "\n",
        "    return Lagrange_polynomial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cf57845b",
      "metadata": {
        "id": "cf57845b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "65a1ba5d",
      "metadata": {
        "id": "65a1ba5d"
      },
      "outputs": [],
      "source": [
        "# Cell for scratch work\n",
        "\n",
        "# You are welcome to add cells into your notebook but\n",
        "# just don't runtime errors anywhere in your notebook\n",
        "# as cells are run sequentially for automated testing\n",
        "\n",
        "# Automated testing is looking for cells (`cell ids`)\n",
        "# where you're asked to enter answers or complete code\n",
        "# but all other cells like this one or cells you add\n",
        "# are safe to delete if you want a \"cleaner\" notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4af7f9e5",
      "metadata": {
        "id": "4af7f9e5"
      },
      "outputs": [],
      "source": [
        "# Cell for scratch work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9509ca21",
      "metadata": {
        "id": "9509ca21"
      },
      "outputs": [],
      "source": [
        "def construct_Lagrange_piecewise_polynomial(x, y, order):\n",
        "\n",
        "    '''\n",
        "    `x`     : [np.array] sorted smallest to largest and of length n\n",
        "    `y`     : [np.array] paired with `x` and of length n\n",
        "\n",
        "    `order` : [int] each piecewise interpolation uses `order+1` data\n",
        "              points so for example for `order=2` and len(x)=5` this\n",
        "              would be two piecewise Lagrange polynomials of `order`\n",
        "              2 made from `x[:3]` and `x[2:]` which overlap at `x[2]`\n",
        "    '''\n",
        "\n",
        "    if not all(x[i] <= x[i+1] for i in range(len(x)-1)):\n",
        "        raise ValueError(\"x must be sorted in ascending order\")\n",
        "\n",
        "    if len(x) != len(y):\n",
        "        raise ValueError(f\"Lengths do not match: len(x)={len(x)}, len(y)={len(y)}\")\n",
        "\n",
        "    if not isinstance(order, int) or order <= 0:\n",
        "        raise ValueError(f\"Expected a positive integer, but got {order}\")\n",
        "\n",
        "    if len(x)%order != 1 and order != 1:\n",
        "        raise ValueError(f\"Length and order are not compatible:\\n each group adds `order` points to the first point in the group\")\n",
        "\n",
        "    @np.vectorize\n",
        "    def Lagrange_piecewise_polynomial(w):\n",
        "        # Find the segment where `w` belongs\n",
        "        for i in range(len(x) - order):\n",
        "            if x[i] <= w <= x[i + order]:  # `w` is within this segment\n",
        "                x_segment = x[i:i + order + 1]\n",
        "                y_segment = y[i:i + order + 1]\n",
        "                local_Lagrange = construct_Lagrange_polynomial(x_segment, y_segment)\n",
        "                return local_Lagrange(w)\n",
        "\n",
        "        # If `w` is out of bounds, extrapolate with the nearest segment\n",
        "        if w < x[0]:\n",
        "            local_Lagrange = construct_Lagrange_polynomial(x[:order + 1], y[:order + 1])\n",
        "            return local_Lagrange(w)\n",
        "        elif w > x[-1]:\n",
        "            local_Lagrange = construct_Lagrange_polynomial(x[-(order + 1):], y[-(order + 1):])\n",
        "            return local_Lagrange(w)\n",
        "\n",
        "    return Lagrange_piecewise_polynomial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fb4a3142",
      "metadata": {
        "id": "fb4a3142"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a7779e88",
      "metadata": {
        "id": "a7779e88"
      },
      "outputs": [],
      "source": [
        "# Cell for scratch work\n",
        "\n",
        "# You are welcome to add cells into your notebook but\n",
        "# just don't runtime errors anywhere in your notebook\n",
        "# as cells are run sequentially for automated testing\n",
        "\n",
        "# Automated testing is looking for cells (`cell ids`)\n",
        "# where you're asked to enter answers or complete code\n",
        "# but all other cells like this one or cells you add\n",
        "# are safe to delete if you want a \"cleaner\" notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1f15fc4c",
      "metadata": {
        "id": "1f15fc4c"
      },
      "outputs": [],
      "source": [
        "# Cell for scratch work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4d5cd522",
      "metadata": {
        "id": "4d5cd522"
      },
      "outputs": [],
      "source": [
        "# Your `construct_jth_Lagrange_basis_function`\n",
        "#      `construct_Lagrange_polynomial` and\n",
        "#      `construct_Lagrange_piecewise_polynomial` functions\n",
        "# will be tested for correctness for 15 points\n",
        "\n",
        "p2q16 = \"Order 2 Lagrange piecewise polynomials C\"\n",
        "# A: have discontinuities where the pieces connect\n",
        "# B: are continuous and differentiable everywhere\n",
        "# C: will not always alternate between convex and concave pieces\n",
        "# D: are good for trend fitting and data smoothing\n",
        "\n",
        "p2q17 = \"If an estimated data smoothing model predicting $\\hat y \\approx E[y|x]$ \"+\\\n",
        "        \"is an order k polynomial (k+1<n=m*k) then the $\\hat y$ curve C\"\n",
        "# A: will be the same as the Lagrange polynomial at the observed data (x,y)\n",
        "# B: will interpolate the same values as the Lagrange polynomial\n",
        "# C: the $\\hat y$ curve can be defined as an order-k piecewise Lagrange polynomial\n",
        "# D: none of the above\n",
        "\n",
        "p2q18 = 'If an \"approximation\" is when a truncated series is used to provide '+\\\n",
        "        'a reduced representation of an object, then C will provide '+\\\n",
        "        'an approximation of an order-k Lagrange piecewise polynomial'\n",
        "# A: dropping some piecewise segments g (giving a piecewise polynomial with gaps)\n",
        "# B: dropping some data points gk+j (making some piecewise polynomial sub order-k)\n",
        "# C: both of the above\n",
        "# D: none of the above\n",
        "\n",
        "p2q19 = \"A is when a family of functional forms is chosen to \"+\\\n",
        "        \"parsimoniously represent key characteristics of $E[y|x]$ \"+\\\n",
        "        \"while C is the process of choosing the parameters \"+\\\n",
        "        \"which index a family of functional forms so the resulting \"+\\\n",
        "        \"functional from resembles the observed data\"\n",
        "# A: Approximation\n",
        "# B: Data smoothing\n",
        "# C: Estimation\n",
        "# D: Interpolation\n",
        "\n",
        "p2q20 = \"Replacing y_i with some sort of local average y-bar_i of y's around y_i \"+\\\n",
        "        \"and then constructing an order-k Lagrange piecewise polynomial using \"+\\\n",
        "        \"y-bar_i instead of y_i is B\"\n",
        "# Same options as above\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "92aa8cb6",
      "metadata": {
        "id": "92aa8cb6"
      },
      "outputs": [],
      "source": [
        "# Cell for scratch work\n",
        "\n",
        "# You are welcome to add cells into your notebook but\n",
        "# just don't runtime errors anywhere in your notebook\n",
        "# as cells are run sequentially for automated testing\n",
        "\n",
        "# Automated testing is looking for cells (`cell ids`)\n",
        "# where you're asked to enter answers or complete code\n",
        "# but all other cells like this one or cells you add\n",
        "# are safe to delete if you want a \"cleaner\" notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6afe0591",
      "metadata": {
        "id": "6afe0591"
      },
      "outputs": [],
      "source": [
        "# Cell for scratch work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "972b300d",
      "metadata": {
        "id": "972b300d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d71eb88f",
      "metadata": {
        "id": "d71eb88f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}