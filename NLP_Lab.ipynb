{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javmencia/COBWEBfiles/blob/main/NLP_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui1KpY6XyxFj"
      },
      "source": [
        "# A walkthrough of text analysis and TF-IDF\n",
        "#### Material from Google Colab Tutorials\n",
        "#### Edited by Nakul Upadhya\n",
        "We'll start by using scikit-learn to count words, then come across some of the issues with simple word count analysis. Most of these problems can be tackled with TF-IDF - a single word might mean less in a longer text, and common words may contribute less to meaning than more rare ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKBwGQKxTvRE",
        "outputId": "2054c236-35cf-4f4c-a8bd-3903ec0e3793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DHYgbsWsyxFk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "pd.options.display.max_columns = 30\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeFIPNJuyxFk"
      },
      "source": [
        "## Text analysis refresher\n",
        "\n",
        "Text analysis has a few parts. We are going to use **bag of words** analysis, which just treats a sentence like a bag of words - no particular order or anything. It's simple but it usually gets the job done adequately.\n",
        "\n",
        "Here is our text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "UfFydiXKyxFl"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"Penny bought bright blue fishes.\",\n",
        "    \"Penny bought bright blue and orange fish.\",\n",
        "    \"The cat ate a fish at the store.\",\n",
        "    \"Penny went to the store. Penny ate a bug. Penny saw a fish.\",\n",
        "    \"It meowed once at the bug, it is still meowing at the bug and the fish\",\n",
        "    \"The cat is at the fish store. The cat is orange. The cat is meowing at the fish.\",\n",
        "    \"Penny is a fish\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSWnar66yxFl"
      },
      "source": [
        "When you process text, you have a nice long series of steps, but let's say you're interested in three things:\n",
        "\n",
        "1. **Tokenizing** converts all of the sentences/phrases/etc into a series of words, and then it might also include converting it into a series of numbers - math stuff only works with numbers, not words. So maybe 'cat' is 2 and 'rug' is 4 and stuff like that.\n",
        "2. **Counting** takes those words and sees how many there are (obviously) - how many times does `meow` appear?\n",
        "3. **Normalizing** takes the count and makes new numbers - maybe it's how many times `meow` appears vs. how many total words there are, or maybe you're seeing how often `meow` comes up to see whether it's important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyIkXrXKyxFl",
        "outputId": "866526a0-377e-4559-c3ec-1d03ae7cfa56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Penny', 'bought', 'bright', 'blue', 'fishes']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\"Penny bought bright blue fishes\".split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIXY1vc3yxFl"
      },
      "source": [
        "      Penny bought bright blue fishes.\n",
        "\n",
        "If we **tokenize** that sentence, we're just lowercasing it, removing the punctuation and splitting on spaces - `penny bought bright blue fishes`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at0TTwbvyxFm"
      },
      "source": [
        "The `scikit-learn` package does a **ton of stuff**, some of which includes the above. We're going to start by playing with the `CountVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "aEk_MabYyxFm"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "30vkcpeNyxFm"
      },
      "outputs": [],
      "source": [
        "# .fit_transfer TOKENIZES and COUNTS\n",
        "X = count_vectorizer.fit_transform(texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1zXFdkryxFm"
      },
      "source": [
        "Let's take a look at what it found out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkOXEZf5yxFm",
        "outputId": "9e5eb8ec-e1ea-4a7c-c795-147a33564e7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
              "\twith 49 stored elements and shape (7, 23)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK05x0uwyxFm"
      },
      "source": [
        "Okay, that looks like trash and garbage. What's a \"sparse array\"??????"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km_wjecmyxFm",
        "outputId": "e6d41649-eb62-4f09-83e0-76003efdfa80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0],\n",
              "       [1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0],\n",
              "       [0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0,\n",
              "        0],\n",
              "       [0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 1, 1, 1,\n",
              "        1],\n",
              "       [1, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1, 2, 1, 1, 1, 0, 0, 0, 1, 0, 3, 0,\n",
              "        0],\n",
              "       [0, 2, 0, 0, 0, 0, 0, 3, 2, 0, 3, 0, 0, 1, 0, 1, 0, 0, 0, 1, 5, 0,\n",
              "        0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "X.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vj7Nmz1yxFn"
      },
      "source": [
        "If we put on our **Computer Goggles** we see that the first sentence has the first word 3 times, the second word 1 time, the third word 1 time, etc... But we can't *read* it, really. It would look nicer as a dataframe and with the words labeled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "2DXuAUtLyxFn",
        "outputId": "76e13e75-83c9-4294-f946-49d90aa61334"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   and  at  ate  blue  bought  bright  bug  cat  fish  fishes  is  it  meowed  \\\n",
              "0    0   0    0     1       1       1    0    0     0       1   0   0       0   \n",
              "1    1   0    0     1       1       1    0    0     1       0   0   0       0   \n",
              "2    0   1    1     0       0       0    0    1     1       0   0   0       0   \n",
              "3    0   0    1     0       0       0    1    0     1       0   0   0       0   \n",
              "4    1   2    0     0       0       0    2    0     1       0   1   2       1   \n",
              "5    0   2    0     0       0       0    0    3     2       0   3   0       0   \n",
              "6    0   0    0     0       0       0    0    0     1       0   1   0       0   \n",
              "\n",
              "   meowing  once  orange  penny  saw  still  store  the  to  went  \n",
              "0        0     0       0      1    0      0      0    0   0     0  \n",
              "1        0     0       1      1    0      0      0    0   0     0  \n",
              "2        0     0       0      0    0      0      1    2   0     0  \n",
              "3        0     0       0      3    1      0      1    1   1     1  \n",
              "4        1     1       0      0    0      1      0    3   0     0  \n",
              "5        1     0       1      0    0      0      1    5   0     0  \n",
              "6        0     0       0      1    0      0      0    0   0     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87807559-de63-4d89-b78e-cd7e55821ee1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>at</th>\n",
              "      <th>ate</th>\n",
              "      <th>blue</th>\n",
              "      <th>bought</th>\n",
              "      <th>bright</th>\n",
              "      <th>bug</th>\n",
              "      <th>cat</th>\n",
              "      <th>fish</th>\n",
              "      <th>fishes</th>\n",
              "      <th>is</th>\n",
              "      <th>it</th>\n",
              "      <th>meowed</th>\n",
              "      <th>meowing</th>\n",
              "      <th>once</th>\n",
              "      <th>orange</th>\n",
              "      <th>penny</th>\n",
              "      <th>saw</th>\n",
              "      <th>still</th>\n",
              "      <th>store</th>\n",
              "      <th>the</th>\n",
              "      <th>to</th>\n",
              "      <th>went</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87807559-de63-4d89-b78e-cd7e55821ee1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87807559-de63-4d89-b78e-cd7e55821ee1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87807559-de63-4d89-b78e-cd7e55821ee1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d5e5309b-b055-40f4-9dfa-6d12380dfabf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5e5309b-b055-40f4-9dfa-6d12380dfabf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d5e5309b-b055-40f4-9dfa-6d12380dfabf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "pd.DataFrame(X.toarray(), columns=count_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV-ozKZeyxFn"
      },
      "source": [
        "If we examine the resultant matrix, we can see that there are many words which are relatively redundant and may not be useful when it comes to distinguishing meaning of the sentence (ex. and, at, it, etc.). We call these **stopwords** and we can remove the stopwords from the matrix when we vectorize our points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8ZUfx_wyxFn",
        "outputId": "a573c119-9ac4-4eaa-e3b6-231019795f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ate' 'blue' 'bought' 'bright' 'bug' 'cat' 'fish' 'fishes' 'meowed'\n",
            " 'meowing' 'orange' 'penny' 'saw' 'store' 'went']\n"
          ]
        }
      ],
      "source": [
        "# We'll make a new vectorizer\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "#count_vectorizer = CountVectorizer(stop_words=['the', 'and'])\n",
        "# .fit_transfer TOKENIZES and COUNTS\n",
        "X = count_vectorizer.fit_transform(texts)\n",
        "print(count_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH1kDo7myxFn"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(X.toarray(), columns=count_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKYAsUv5yxFn"
      },
      "source": [
        "I still see `meowed` and `meowing` and `fish` and `fishes` - they seem the same, so let's lemmatize/stem them.\n",
        "\n",
        "You can specify a `preprocessor` or a `tokenizer` when you're creating your `CountVectorizer` to do custom *stuff* on your words. Maybe we want to get rid of punctuation, lowercase things and split them on spaces (this is basically the default). `preprocessor` is supposed to return a string, so it's a little easier to work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_CIWseVyxFn"
      },
      "outputs": [],
      "source": [
        "# This is what our normal tokenizer looks like\n",
        "def boring_tokenizer(str_input):\n",
        "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
        "    return words\n",
        "\n",
        "count_vectorizer = CountVectorizer(stop_words='english', tokenizer=boring_tokenizer)\n",
        "X = count_vectorizer.fit_transform(texts)\n",
        "print(count_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzOy8bT-yxFo"
      },
      "source": [
        "We're going to use one that features a **stemmer** - something that strips the endings off of words (or tries to, at least). This one is from `nltk`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LkJTSiIyxFo"
      },
      "outputs": [],
      "source": [
        "# https://tartarus.org/martin/PorterStemmer/def.txt\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "print(porter_stemmer.stem('fishes'))\n",
        "print(porter_stemmer.stem('meowed'))\n",
        "print(porter_stemmer.stem('oranges'))\n",
        "print(porter_stemmer.stem('meowing'))\n",
        "print(porter_stemmer.stem('orange'))\n",
        "print(porter_stemmer.stem('go'))\n",
        "print(porter_stemmer.stem('went'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FijAd-2eyxFo"
      },
      "outputs": [],
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "def stemming_tokenizer(str_input):\n",
        "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
        "    words = [porter_stemmer.stem(word) for word in words]\n",
        "    return words\n",
        "\n",
        "count_vectorizer = CountVectorizer(stop_words='english', tokenizer=stemming_tokenizer)\n",
        "X = count_vectorizer.fit_transform(texts)\n",
        "print(count_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xocWpyAoyxFo"
      },
      "source": [
        "Now lets look at the new version of that dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFHE-px2yxFo"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(X.toarray(), columns=count_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QKy9VR3yxFo"
      },
      "source": [
        "    \"Penny bought bright blue fishes.\",\n",
        "    \"Penny bought bright blue and orange fish.\",\n",
        "    \"The cat ate a fish at the store.\",\n",
        "    \"Penny went to the store. Penny ate a bug. Penny saw a fish.\",\n",
        "    \"It meowed once at the bug, it is still meowing at the bug and the fish\",\n",
        "    \"The cat is at the fish store. The cat is orange. The cat is meowing at the fish.\",\n",
        "    \"Penny is a fish\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB-xHn3MyxFo"
      },
      "source": [
        "## TF-IDF\n",
        "\n",
        "### Part One: Term Frequency\n",
        "\n",
        "TF-IDF? What? It means **term frequency inverse document frequency!** It's the most important thing. Let's look at our list of phrases\n",
        "\n",
        "1. Penny bought bright blue fishes.\n",
        "2. Penny bought bright blue and orange fish.\n",
        "3. The cat ate a fish at the store.\n",
        "4. Penny went to the store. Penny ate a bug. Penny saw a fish.\n",
        "5. It meowed once at the fish, it is still meowing at the fish. It meowed at the bug and the fish.\n",
        "6. The cat is fat. The cat is orange. The cat is meowing at the fish.\n",
        "7. Penny is a fish\n",
        "\n",
        "If we are training a classifier to identify sentences about aquatic life, which is the most helpful phrase?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CirrVc6XyxFo"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(X.toarray(), columns=count_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm_dnfynyxFo"
      },
      "source": [
        "Probably the one where `fish` appears two times.\n",
        "\n",
        "    It meowed once at the fish, it is still meowing at the fish. It meowed at the bug and the fish.\n",
        "    \n",
        "But are all the others the same?\n",
        "\n",
        "    Penny is a fish.\n",
        "\n",
        "    Penny went to the store. Penny ate a bug. Penny saw a fish.\n",
        "\n",
        "In the second one we spend less time talking about the fish. Think about a huge long document where they say your name once, versus a tweet where they say your name once. Which one are you more important in? Probably the tweet, since you take up a larger percentage of the text.\n",
        "\n",
        "This is **term frequency** - taking into account how often a term shows up. We're going to take this into account by using the `TfidfVectorizer` in the same way we used the `CountVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9-MjwrIZyxFo"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvyJRG1LyxFo"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, use_idf=False, norm='l1')\n",
        "X = tfidf_vectorizer.fit_transform(texts)\n",
        "pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAzgb4bcyxFp"
      },
      "source": [
        "Now our numbers have shifted a little bit. Instead of just being a count, it's *the percentage of the words*.\n",
        "\n",
        "    value = (number of times word appears in sentence) / (number of words in sentence)\n",
        "\n",
        "After we remove the stopwords, the term `fish` is 50% of the words in `Penny is a fish` vs. 37.5% in `It meowed once at the fish, it is still meowing at the fish. It meowed at the bug and the fish.`.\n",
        "\n",
        "> **Note:** We made it be the percentage of the words by passing in `norm=\"l1\"` - by default it's normally an L2 (Euclidean) norm, which is actually better, but I thought it would make more sense using the L1 - a.k.a. terms divided by words -norm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgp-u42RyxFp"
      },
      "source": [
        "So now when we train a classifier, it will be able to identify the important words easier because our pre-processing takes into account whether half of our words are `fish` or 1% of millions upon millions of words is `fish`. But we aren't done yet!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ9lHo-TyxFp"
      },
      "source": [
        "### Part Two: Inverse document frequency\n",
        "\n",
        "In addition to its importance to a given sentence, we also want to give information on how prevelant a given token is in the dataset as a whole. A token that is mentioned a lot in every dataset will probably be less important than a token that appears infrequently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-9NUlWByxFx"
      },
      "source": [
        "This is **inverse document frequency** - the more often a term shows up across *all* documents, the less important it is in our matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jaVRIPUyxFx"
      },
      "outputs": [],
      "source": [
        "# use_idf=True is default, but I'll leave it in\n",
        "idf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, use_idf=True, norm='l1')\n",
        "X = idf_vectorizer.fit_transform(texts)\n",
        "idf_df = pd.DataFrame(X.toarray(), columns=idf_vectorizer.get_feature_names_out())\n",
        "idf_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiiieSOAyxFy"
      },
      "source": [
        "Notice how 'meow' increased in value because it's an infrequent term, and `fish` dropped in value because it's so frequent.\n",
        "\n",
        "That meowing one (index 4) has gone from `0.50` to `0.43`, while `Penny is a fish` (index 6) has dropped to `0.40`. Now hooray, the meowing one is going to show up earlier when searching for \"fish meow\" because *fish shows up all of the time, so we want to ignore it a lil' bit*.\n",
        "\n",
        "Let's try changing it to `norm='l2'` (or just removing `norm` completely) to see how this might change our matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xz9TbzxyyxFy"
      },
      "outputs": [],
      "source": [
        "# use_idf=True is default, but I'll leave it in\n",
        "l2_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, use_idf=True)\n",
        "X = l2_vectorizer.fit_transform(texts)\n",
        "l2_df = pd.DataFrame(X.toarray(), columns=l2_vectorizer.get_feature_names_out())\n",
        "l2_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6d0s3sMyxFy"
      },
      "source": [
        "## Real Life Example\n",
        "\n",
        "Lets take what we learned and apply it to a real life classification task. AG is a collection of more than 1 million news articles organized into four different topics: Business, Tech, Sports, and World News.\n",
        "Your task is to:\n",
        "1. Apply the text pre-processing you learnt above to get a clean dataset.\n",
        "2. Train a classifier on your processed data.\n",
        "3. Report the accuracy, precision, recall, and F1 (there are multiple classes so think about which F1 to report)\n",
        "\n",
        "Code to download and sample the data is already provided.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUk0RtMW6akn"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfjZOGZF9RUV"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"ag_news\", cache_dir='data/datasets/text/ag_news')\n",
        "train = dataset['train']\n",
        "test = dataset['test']\n",
        "# convert to pandas\n",
        "train = pd.DataFrame(train).head(2000)\n",
        "test = pd.DataFrame(test).head(500)\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdtRBJKi_ay-"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "l2_vectorizer = TfidfVectorizer(stop_words='english',\n",
        "                                tokenizer=stemming_tokenizer,\n",
        "                                use_idf=True,\n",
        "                                max_df = 0.99,\n",
        "                                min_df = 0.01)\n",
        "X_train = l2_vectorizer.fit_transform(train['text'])\n",
        "X_test = l2_vectorizer.transform(test['text'])\n",
        "y_train = train['label']\n",
        "y_test = test['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ5RQKhZf70j"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score\n",
        "clf = XGBClassifier() # First we define our model without passing in parameters\n",
        "hyperparameter_search = { # Then we decide the possible parameter combinations\n",
        "    'max_depth': [2,6], ## FILL THIS IN\n",
        "    'lambda': [0,0, 1e-3],\n",
        "    'alpha': [0,0,1e-3] ## FILL THIS IN\n",
        "}\n",
        "evaluation_metric = make_scorer(accuracy_score, # GridSearchCV requires us to wrap our metric function in a \"scorer\"\n",
        "                                greater_is_better = True)\n",
        "\n",
        "grid_search_cv = GridSearchCV(estimator = clf,\n",
        "                              param_grid = hyperparameter_search,\n",
        "                              scoring = evaluation_metric,\n",
        "                              cv = 5) # Set up search algorithm\n",
        "grid_search_cv.fit(X_train, y_train) # Run the search. NOTE: This may take a while\n",
        "\n",
        "print(\"Best Parameters: \", grid_search_cv.best_params_) # Print the parameters\n",
        "print (\"Best CV Accuracy: \", grid_search_cv.best_score_ * 100, \"%\")\n",
        "\n",
        "clf = grid_search_cv.best_estimator_ # Get the best model from the GridSearch\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(f\"f1 = {f1_score(y_test, y_pred, average = 'macro')}\")\n",
        "print(f\"precision_score = {precision_score(y_test, y_pred, average = 'macro')}\")\n",
        "print(f\"recall_score = {recall_score(y_test, y_pred, average = 'macro')}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "IncepTree",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}