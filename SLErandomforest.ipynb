{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBc1ZGAyFrfKBh2a9oi0EI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javmencia/COBWEBfiles/blob/main/SLErandomforest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wWyzxsTV0TL",
        "outputId": "c1117107-8b82-4d8d-f928-2da5128da602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-414565143.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  data['sdi_change_rate'] = data.groupby('PTNO', group_keys=False).apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Val Accuracy: 0.0585\n",
            "RF Val Balanced Accuracy: 0.3384\n",
            "\n",
            "=== Fold 2/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Val Accuracy: 0.0732\n",
            "RF Val Balanced Accuracy: 0.3968\n",
            "\n",
            "=== Fold 3/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Val Accuracy: 0.0634\n",
            "RF Val Balanced Accuracy: 0.3709\n",
            "\n",
            "=== Fold 4/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Val Accuracy: 0.0683\n",
            "RF Val Balanced Accuracy: 0.3714\n",
            "\n",
            "=== Fold 5/5 ===\n",
            "RF Val Accuracy: 0.0634\n",
            "RF Val Balanced Accuracy: 0.3714\n",
            "\n",
            "=== Final Cross-Validation Results ===\n",
            "\n",
            "RF Metrics:\n",
            "Mean Accuracy: 0.0654 (±0.0050)\n",
            "Mean Balanced Accuracy: 0.3698 (±0.0186)\n",
            "\n",
            "RF Per-Class Metrics (Averaged):\n",
            "Class Disability Benefit - Precision: 0.0000, Recall: 0.0000\n",
            "Class Early Retirement - Precision: 0.1459, Recall: 0.7133\n",
            "Class Economically Inactive - Precision: 0.0903, Recall: 0.5143\n",
            "Class Employed - Precision: 0.0000, Recall: 0.0000\n",
            "Class Employed (Died) - Precision: 0.0375, Recall: 0.8133\n",
            "Class Unemployed - Precision: 0.0684, Recall: 0.1778\n",
            "\n",
            "Top 10 RF Features (from last fold):\n",
            "                  Feature  Importance\n",
            "6           age_at_record    0.181443\n",
            "8        time_since_first    0.161861\n",
            "9               visit_num    0.105316\n",
            "7         time_since_last    0.074712\n",
            "11                    AMS    0.069115\n",
            "3                STERDOSE    0.059887\n",
            "5                  AMDOSE    0.043923\n",
            "28    SLEDAI_Neurological    0.031156\n",
            "2            total_flares    0.030759\n",
            "33  sdi_flare_interaction    0.027761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                            balanced_accuracy_score, cohen_kappa_score,\n",
        "                            precision_score, recall_score, accuracy_score)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "import random\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(1927)\n",
        "np.random.seed(1927)\n",
        "\n",
        "# --- Data Loading & Preprocessing ---\n",
        "data = pd.read_csv('sledatacut.csv', parse_dates=['ASSDT'], low_memory=False)\n",
        "dataorig = pd.read_csv('sledatacut.csv', parse_dates=['ASSDT'], low_memory=False)\n",
        "data = data.sort_values(['PTNO', 'ASSDT'])\n",
        "\n",
        "# Calculate time differences\n",
        "data['time_since_first'] = data.groupby('PTNO')['ASSDT'].transform(\n",
        "    lambda x: (x - x.min()).dt.days\n",
        ")\n",
        "data['time_since_last'] = data.groupby('PTNO')['ASSDT'].transform(\n",
        "    lambda x: x.diff().dt.days.fillna(0)\n",
        ")\n",
        "\n",
        "# Convert categorical EMPf to numerical\n",
        "emp_mapping = {v: k for k, v in enumerate(data['EMPf'].unique())}\n",
        "data['EMP_numeric'] = data['EMPf'].map(emp_mapping)\n",
        "\n",
        "# Encode the target (end_state)\n",
        "label_encoder = LabelEncoder()\n",
        "data['end_state_encoded'] = label_encoder.fit_transform(data['end_state'])\n",
        "\n",
        "# Encode steroid categories (Low/Medium/High)\n",
        "steroid_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "data['STEROID_CAT_numeric'] = data['STEROID_CAT'].map(steroid_mapping)\n",
        "\n",
        "# Features to use - including SDI (score_n) along with flares and steroid categories\n",
        "features = ['severe_flare', 'mild_flare', 'total_flares',\n",
        "            'STERDOSE', 'INCEPT', 'AMDOSE',\n",
        "            'age_at_record', 'time_since_last', 'time_since_first',\n",
        "            'visit_num', 'score_n', \"AMS\",  \"SDI_Ocular\", \"SDI_Neuropsychiatric\", \"SDI_Renal\",\n",
        "            \"SDI_Pulmonary\", \"SDI_Cardiovascular\", \"SDI_PeripheralVascular\", \"SDI_Gastrointestinal\",\n",
        "            \"SDI_Musculoskeletal\", \"SDI_Dermatologic\",\"SDI_Endocrine\", \"SDI_Malignancy\", \"SLEDAI_Constitutional\",\n",
        "            \"SLEDAI_Cutaneous\", \"SLEDAI_Musculoskeletal\", \"SLEDAI_Serositis\", \"SLEDAI_Renal\", \"SLEDAI_Neurological\",\n",
        "            \"SLEDAI_Hematological\", \"SLEDAI_Immunological\", \"SLEDAI_Vascular\", \"SLEDAI_Other\"\n",
        "            ]\n",
        "\n",
        "# Add interaction terms between important features\n",
        "data['sdi_flare_interaction'] = data['score_n'] * data['total_flares']\n",
        "\n",
        "# Add temporal features\n",
        "data['flares_per_month'] = data['total_flares'] / (data['time_since_first']/30 + 1)  # +1 to avoid division by zero\n",
        "\n",
        "# Correct SDI change rate calculation - using time_since_last instead of index\n",
        "data['sdi_change_rate'] = data.groupby('PTNO', group_keys=False).apply(\n",
        "    lambda x: x['score_n'].diff().fillna(0) / (x['time_since_last']/30 + 1e-6)  # Small constant to avoid division by zero\n",
        ")\n",
        "\n",
        "# Update features list\n",
        "features += ['sdi_flare_interaction', 'sdi_change_rate']\n",
        "\n",
        "# Identify categorical columns (non-numeric)\n",
        "categorical_cols = data[features].select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Label encode categorical columns\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col].astype(str))\n",
        "\n",
        "# Fill NA values - for flares and SDI we'll assume 0 if missing\n",
        "flare_cols = ['severe_flares', 'mild_flares']\n",
        "data[flare_cols] = data[flare_cols].fillna(0)\n",
        "data['score_n'] = data['score_n'].fillna(0)  # SDI\n",
        "data[features] = data[features].fillna(0)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "data[features] = scaler.fit_transform(data[features])\n",
        "\n",
        "# Create a custom aggregation dictionary\n",
        "agg_dict = {feature: 'max' for feature in features}\n",
        "\n",
        "# For temporal features, use last observation instead of max\n",
        "temporal_features = ['time_since_first', 'time_since_last', 'visit_num']\n",
        "for feature in temporal_features:\n",
        "    if feature in agg_dict:\n",
        "        agg_dict[feature] = 'last'\n",
        "\n",
        "# Aggregate features\n",
        "max_observations = data.groupby('PTNO').agg(agg_dict)\n",
        "\n",
        "# Get the last observation for the target variable\n",
        "last_target = data.groupby('PTNO')['end_state_encoded'].last()\n",
        "\n",
        "X = max_observations.values\n",
        "y = last_target.values\n",
        "\n",
        "# --- Initialize Cross-Validation ---\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "cv_results = {\n",
        "    'rf_val_accuracy': [],\n",
        "    'rf_val_balanced_accuracy': [],\n",
        "    'rf_val_precision_per_class': [],\n",
        "    'rf_val_recall_per_class': [],\n",
        "    'rf_models': []\n",
        "}\n",
        "\n",
        "# --- Cross-Validation Loop ---\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    print(f\"\\n=== Fold {fold + 1}/{n_splits} ===\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    # Class weights\n",
        "    classes = np.unique(y_train)\n",
        "    class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    # --- Random Forest Training ---\n",
        "    rf = BalancedRandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        sampling_strategy='all',\n",
        "        replacement=True,\n",
        "        random_state=42,\n",
        "        class_weight='balanced',\n",
        "        max_depth=10,\n",
        "        min_samples_leaf=5\n",
        "    )\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    # RF Validation Predictions\n",
        "    y_val_pred_rf = rf.predict(X_val)\n",
        "    y_val_pred_rf_proba = rf.predict_proba(X_val)\n",
        "\n",
        "    # Store RF metrics\n",
        "    cv_results['rf_val_accuracy'].append(accuracy_score(y_val, y_val_pred_rf))\n",
        "    cv_results['rf_val_balanced_accuracy'].append(balanced_accuracy_score(y_val, y_val_pred_rf))\n",
        "    cv_results['rf_val_precision_per_class'].append(precision_score(y_val, y_val_pred_rf, average=None))\n",
        "    cv_results['rf_val_recall_per_class'].append(recall_score(y_val, y_val_pred_rf, average=None))\n",
        "    cv_results['rf_models'].append(rf)\n",
        "\n",
        "    # --- Fold Summary ---\n",
        "    print(f\"RF Val Accuracy: {cv_results['rf_val_accuracy'][-1]:.4f}\")\n",
        "    print(f\"RF Val Balanced Accuracy: {cv_results['rf_val_balanced_accuracy'][-1]:.4f}\")\n",
        "\n",
        "# --- Final Cross-Validation Report ---\n",
        "print(\"\\n=== Final Cross-Validation Results ===\")\n",
        "\n",
        "# RF Performance\n",
        "print(\"\\nRF Metrics:\")\n",
        "print(f\"Mean Accuracy: {np.mean(cv_results['rf_val_accuracy']):.4f} (±{np.std(cv_results['rf_val_accuracy']):.4f})\")\n",
        "print(f\"Mean Balanced Accuracy: {np.mean(cv_results['rf_val_balanced_accuracy']):.4f} (±{np.std(cv_results['rf_val_balanced_accuracy']):.4f})\")\n",
        "\n",
        "# Per-class metrics (averaged across folds)\n",
        "print(\"\\nRF Per-Class Metrics (Averaged):\")\n",
        "avg_precision = np.mean(cv_results['rf_val_precision_per_class'], axis=0)\n",
        "avg_recall = np.mean(cv_results['rf_val_recall_per_class'], axis=0)\n",
        "for i, (prec, rec) in enumerate(zip(avg_precision, avg_recall)):\n",
        "    print(f\"Class {label_encoder.classes_[i]} - Precision: {prec:.4f}, Recall: {rec:.4f}\")\n",
        "\n",
        "# Feature Importance (from last RF fold)\n",
        "print(\"\\nTop 10 RF Features (from last fold):\")\n",
        "importances = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': cv_results['rf_models'][-1].feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "print(importances.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                            balanced_accuracy_score, cohen_kappa_score,\n",
        "                            precision_score, recall_score, accuracy_score)\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "import random\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(1927)\n",
        "np.random.seed(1927)\n",
        "\n",
        "# --- Data Loading & Preprocessing ---\n",
        "data = pd.read_csv('sledatacut.csv', parse_dates=['ASSDT'], low_memory=False)\n",
        "dataorig = pd.read_csv('sledatacut.csv', parse_dates=['ASSDT'], low_memory=False)\n",
        "data = data.sort_values(['PTNO', 'ASSDT'])\n",
        "\n",
        "# Calculate time differences\n",
        "data['time_since_first'] = data.groupby('PTNO')['ASSDT'].transform(\n",
        "    lambda x: (x - x.min()).dt.days\n",
        ")\n",
        "data['time_since_last'] = data.groupby('PTNO')['ASSDT'].transform(\n",
        "    lambda x: x.diff().dt.days.fillna(0)\n",
        ")\n",
        "\n",
        "# Convert categorical EMPf to numerical\n",
        "emp_mapping = {v: k for k, v in enumerate(data['EMPf'].unique())}\n",
        "data['EMP_numeric'] = data['EMPf'].map(emp_mapping)\n",
        "\n",
        "# Encode the target (end_state)\n",
        "label_encoder = LabelEncoder()\n",
        "data['end_state_encoded'] = label_encoder.fit_transform(data['end_state'])\n",
        "\n",
        "# Encode steroid categories (Low/Medium/High)\n",
        "steroid_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "data['STEROID_CAT_numeric'] = data['STEROID_CAT'].map(steroid_mapping)\n",
        "\n",
        "# Features to use - including SDI (score_n) along with flares and steroid categories\n",
        "features = ['severe_flare', 'mild_flare', 'total_flares',\n",
        "            'STERDOSE', 'INCEPT', 'AMDOSE',\n",
        "            'age_at_record', 'time_since_last', 'time_since_first',\n",
        "            'visit_num', 'score_n', \"AMS\",  \"SDI_Ocular\", \"SDI_Neuropsychiatric\", \"SDI_Renal\",\n",
        "            \"SDI_Pulmonary\", \"SDI_Cardiovascular\", \"SDI_PeripheralVascular\", \"SDI_Gastrointestinal\",\n",
        "            \"SDI_Musculoskeletal\", \"SDI_Dermatologic\",\"SDI_Endocrine\", \"SDI_Malignancy\", \"SLEDAI_Constitutional\",\n",
        "            \"SLEDAI_Cutaneous\", \"SLEDAI_Musculoskeletal\", \"SLEDAI_Serositis\", \"SLEDAI_Renal\", \"SLEDAI_Neurological\",\n",
        "            \"SLEDAI_Hematological\", \"SLEDAI_Immunological\", \"SLEDAI_Vascular\", \"SLEDAI_Other\"\n",
        "            ]\n",
        "\n",
        "# Add interaction terms between important features\n",
        "data['sdi_flare_interaction'] = data['score_n'] * data['total_flares']\n",
        "\n",
        "# Add temporal features\n",
        "data['flares_per_month'] = data['total_flares'] / (data['time_since_first']/30 + 1)  # +1 to avoid division by zero\n",
        "\n",
        "# Correct SDI change rate calculation - using time_since_last instead of index\n",
        "data['sdi_change_rate'] = data.groupby('PTNO', group_keys=False).apply(\n",
        "    lambda x: x['score_n'].diff().fillna(0) / (x['time_since_last']/30 + 1e-6)  # Small constant to avoid division by zero\n",
        ")\n",
        "\n",
        "# Update features list\n",
        "features += ['sdi_flare_interaction', 'sdi_change_rate']\n",
        "\n",
        "# Identify categorical columns (non-numeric)\n",
        "categorical_cols = data[features].select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Label encode categorical columns\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col].astype(str))\n",
        "\n",
        "# Fill NA values - for flares and SDI we'll assume 0 if missing\n",
        "flare_cols = ['severe_flares', 'mild_flares']\n",
        "data[flare_cols] = data[flare_cols].fillna(0)\n",
        "data['score_n'] = data['score_n'].fillna(0)  # SDI\n",
        "data[features] = data[features].fillna(0)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "data[features] = scaler.fit_transform(data[features])\n",
        "\n",
        "# Create a custom aggregation dictionary\n",
        "agg_dict = {feature: 'max' for feature in features}\n",
        "\n",
        "# For temporal features, use last observation instead of max\n",
        "temporal_features = ['time_since_first', 'time_since_last', 'visit_num']\n",
        "for feature in temporal_features:\n",
        "    if feature in agg_dict:\n",
        "        agg_dict[feature] = 'last'\n",
        "\n",
        "# Aggregate features\n",
        "max_observations = data.groupby('PTNO').agg(agg_dict)\n",
        "\n",
        "# Get the last observation for the target variable\n",
        "last_target = data.groupby('PTNO')['end_state_encoded'].last()\n",
        "\n",
        "X = max_observations.values\n",
        "y = last_target.values\n",
        "\n",
        "# --- Initialize Cross-Validation ---\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "cv_results = {\n",
        "    'xgb_val_accuracy': [],\n",
        "    'xgb_val_balanced_accuracy': [],\n",
        "    'xgb_val_precision_per_class': [],\n",
        "    'xgb_val_recall_per_class': [],\n",
        "    'xgb_models': []\n",
        "}\n",
        "\n",
        "# --- Cross-Validation Loop ---\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    print(f\"\\n=== Fold {fold + 1}/{n_splits} ===\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    # Class weights\n",
        "    classes = np.unique(y_train)\n",
        "    class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    # --- XGBoost Training ---\n",
        "    xgb = XGBClassifier(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=6,\n",
        "        min_child_weight=3,\n",
        "        gamma=0,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        objective='multi:softprob',\n",
        "        num_class=len(np.unique(y)),\n",
        "        random_state=42,\n",
        "        scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]) if len(np.unique(y)) == 2 else None,\n",
        "        early_stopping_rounds=20,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "\n",
        "    xgb.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # XGBoost Validation Predictions\n",
        "    y_val_pred_xgb = xgb.predict(X_val)\n",
        "    y_val_pred_xgb_proba = xgb.predict_proba(X_val)\n",
        "\n",
        "    # Store XGBoost metrics\n",
        "    cv_results['xgb_val_accuracy'].append(accuracy_score(y_val, y_val_pred_xgb))\n",
        "    cv_results['xgb_val_balanced_accuracy'].append(balanced_accuracy_score(y_val, y_val_pred_xgb))\n",
        "    cv_results['xgb_val_precision_per_class'].append(precision_score(y_val, y_val_pred_xgb, average=None))\n",
        "    cv_results['xgb_val_recall_per_class'].append(recall_score(y_val, y_val_pred_xgb, average=None))\n",
        "    cv_results['xgb_models'].append(xgb)\n",
        "\n",
        "    # --- Fold Summary ---\n",
        "    print(f\"XGB Val Accuracy: {cv_results['xgb_val_accuracy'][-1]:.4f}\")\n",
        "    print(f\"XGB Val Balanced Accuracy: {cv_results['xgb_val_balanced_accuracy'][-1]:.4f}\")\n",
        "\n",
        "# --- Final Cross-Validation Report ---\n",
        "print(\"\\n=== Final Cross-Validation Results ===\")\n",
        "\n",
        "# XGBoost Performance\n",
        "print(\"\\nXGBoost Metrics:\")\n",
        "print(f\"Mean Accuracy: {np.mean(cv_results['xgb_val_accuracy']):.4f} (±{np.std(cv_results['xgb_val_accuracy']):.4f})\")\n",
        "print(f\"Mean Balanced Accuracy: {np.mean(cv_results['xgb_val_balanced_accuracy']):.4f} (±{np.std(cv_results['xgb_val_balanced_accuracy']):.4f})\")\n",
        "\n",
        "# Per-class metrics (averaged across folds)\n",
        "print(\"\\nXGBoost Per-Class Metrics (Averaged):\")\n",
        "avg_precision = np.mean(cv_results['xgb_val_precision_per_class'], axis=0)\n",
        "avg_recall = np.mean(cv_results['xgb_val_recall_per_class'], axis=0)\n",
        "for i, (prec, rec) in enumerate(zip(avg_precision, avg_recall)):\n",
        "    print(f\"Class {label_encoder.classes_[i]} - Precision: {prec:.4f}, Recall: {rec:.4f}\")\n",
        "\n",
        "# Feature Importance (from last XGBoost fold)\n",
        "print(\"\\nTop 10 XGBoost Features (from last fold):\")\n",
        "importances = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': cv_results['xgb_models'][-1].feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "print(importances.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvQuml9XY6FP",
        "outputId": "120ba645-e7eb-43d7-c9e6-359a74a07bf4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-1875949777.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  data['sdi_change_rate'] = data.groupby('PTNO', group_keys=False).apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGB Val Accuracy: 0.7854\n",
            "XGB Val Balanced Accuracy: 0.2776\n",
            "\n",
            "=== Fold 2/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGB Val Accuracy: 0.8049\n",
            "XGB Val Balanced Accuracy: 0.2795\n",
            "\n",
            "=== Fold 3/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGB Val Accuracy: 0.8049\n",
            "XGB Val Balanced Accuracy: 0.3493\n",
            "\n",
            "=== Fold 4/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGB Val Accuracy: 0.7951\n",
            "XGB Val Balanced Accuracy: 0.3484\n",
            "\n",
            "=== Fold 5/5 ===\n",
            "XGB Val Accuracy: 0.8146\n",
            "XGB Val Balanced Accuracy: 0.3004\n",
            "\n",
            "=== Final Cross-Validation Results ===\n",
            "\n",
            "XGBoost Metrics:\n",
            "Mean Accuracy: 0.8010 (±0.0099)\n",
            "Mean Balanced Accuracy: 0.3111 (±0.0319)\n",
            "\n",
            "XGBoost Per-Class Metrics (Averaged):\n",
            "Class Disability Benefit - Precision: 0.5536, Recall: 0.5508\n",
            "Class Early Retirement - Precision: 0.4333, Recall: 0.1933\n",
            "Class Economically Inactive - Precision: 0.2000, Recall: 0.0857\n",
            "Class Employed - Precision: 0.8600, Recall: 0.9699\n",
            "Class Employed (Died) - Precision: 0.0000, Recall: 0.0000\n",
            "Class Unemployed - Precision: 0.1400, Recall: 0.0667\n",
            "\n",
            "Top 10 XGBoost Features (from last fold):\n",
            "                Feature  Importance\n",
            "8      time_since_first    0.069420\n",
            "9             visit_num    0.056362\n",
            "27         SLEDAI_Renal    0.046867\n",
            "3              STERDOSE    0.046167\n",
            "6         age_at_record    0.044019\n",
            "0          severe_flare    0.043402\n",
            "28  SLEDAI_Neurological    0.038246\n",
            "34      sdi_change_rate    0.036906\n",
            "12           SDI_Ocular    0.036530\n",
            "7       time_since_last    0.033538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                            balanced_accuracy_score, cohen_kappa_score,\n",
        "                            precision_score, recall_score, accuracy_score)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import random\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(1927)\n",
        "np.random.seed(1927)\n",
        "\n",
        "# --- Data Loading & Preprocessing ---\n",
        "data = pd.read_csv('sledatacut.csv', parse_dates=['ASSDT'], low_memory=False)\n",
        "data = data.sort_values(['PTNO', 'ASSDT'])\n",
        "\n",
        "# Time difference features\n",
        "data['time_since_first'] = data.groupby('PTNO')['ASSDT'].transform(\n",
        "    lambda x: (x - x.min()).dt.days\n",
        ")\n",
        "data['time_since_last'] = data.groupby('PTNO')['ASSDT'].transform(\n",
        "    lambda x: x.diff().dt.days.fillna(0)\n",
        ")\n",
        "\n",
        "# Feature engineering\n",
        "data['flares_per_month'] = data['total_flares'] / (data['time_since_first']/30 + 1)\n",
        "data['steroid_flare_interaction'] = data['STERDOSE'] * data['total_flares']\n",
        "data['sdi_flare_interaction'] = data['score_n'] * data['total_flares']\n",
        "\n",
        "# Handle rare classes\n",
        "class_counts = data['end_state'].value_counts()\n",
        "rare_classes = class_counts[class_counts < 10].index\n",
        "data['end_state'] = data['end_state'].replace(rare_classes, 'Other')\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "data['end_state_encoded'] = label_encoder.fit_transform(data['end_state'])\n",
        "\n",
        "# Features\n",
        "features = [\n",
        "    'severe_flare', 'mild_flare', 'total_flares',\n",
        "    'STERDOSE', 'INCEPT', 'AMDOSE',\n",
        "    'age_at_record', 'time_since_last', 'time_since_first',\n",
        "    'visit_num', 'score_n', \"AMS\",\n",
        "    'flares_per_month', 'steroid_flare_interaction', 'sdi_flare_interaction'\n",
        "]\n",
        "\n",
        "# Handle missing data\n",
        "for col in features:\n",
        "    if data[col].dtype in ['float64', 'int64']:\n",
        "        data[col] = data[col].fillna(data[col].median())\n",
        "    else:\n",
        "        data[col] = data[col].fillna('missing')\n",
        "\n",
        "# Scaling\n",
        "scaler = MinMaxScaler()\n",
        "data[features] = scaler.fit_transform(data[features])\n",
        "\n",
        "# Aggregate to patient-level\n",
        "agg_dict = {feature: 'last' for feature in features}\n",
        "agg_dict.update({\n",
        "    'total_flares': 'sum',\n",
        "    'severe_flare': 'sum',\n",
        "    'mild_flare': 'sum',\n",
        "    'score_n': 'max'\n",
        "})\n",
        "\n",
        "max_observations = data.groupby('PTNO').agg(agg_dict)\n",
        "last_target = data.groupby('PTNO')['end_state_encoded'].last()\n",
        "\n",
        "X = max_observations.values\n",
        "y = last_target.values\n",
        "\n",
        "# --- Model Definitions ---\n",
        "def get_xgb_model():\n",
        "    return Pipeline([\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('classifier', XGBClassifier(\n",
        "            n_estimators=300,\n",
        "            max_depth=6,\n",
        "            learning_rate=0.1,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            random_state=42,\n",
        "            scale_pos_weight=len(y[y==0])/len(y[y==1]) if len(np.unique(y)) == 2 else None,\n",
        "            eval_metric='mlogloss',\n",
        "            n_jobs=-1\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "def get_svm_model():\n",
        "    return Pipeline([\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('classifier', SVC(\n",
        "            C=1.0,\n",
        "            kernel='rbf',\n",
        "            gamma='scale',\n",
        "            class_weight='balanced',\n",
        "            probability=True,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "def get_easy_ensemble_model():\n",
        "    return EasyEnsembleClassifier(\n",
        "        n_estimators=10,\n",
        "        base_estimator=RandomForestClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=10,\n",
        "            class_weight='balanced',\n",
        "            random_state=42\n",
        "        ),\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "def get_rf_model():\n",
        "    return BalancedRandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=10,\n",
        "        min_samples_leaf=3,\n",
        "        class_weight='balanced_subsample',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "# --- Parallel Cross-Validation ---\n",
        "def run_cv(model_fn, model_name):\n",
        "    print(f\"\\n=== Running {model_name} ===\")\n",
        "    n_splits = 5\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    results = {\n",
        "        'accuracy': [],\n",
        "        'balanced_accuracy': [],\n",
        "        'precision': [],\n",
        "        'recall': [],\n",
        "        'f1': []\n",
        "    }\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        model = model_fn()\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "\n",
        "        results['accuracy'].append(accuracy_score(y_val, y_pred))\n",
        "        results['balanced_accuracy'].append(balanced_accuracy_score(y_val, y_pred))\n",
        "        results['precision'].append(precision_score(y_val, y_pred, average='weighted', zero_division=0))\n",
        "        results['recall'].append(recall_score(y_val, y_pred, average='weighted'))\n",
        "        results['f1'].append(f1_score(y_val, y_pred, average='weighted'))\n",
        "\n",
        "        print(f\"{model_name} Fold {fold+1}: Balanced Acc = {results['balanced_accuracy'][-1]:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'model_name': model_name,\n",
        "        'mean_accuracy': np.mean(results['accuracy']),\n",
        "        'mean_balanced_accuracy': np.mean(results['balanced_accuracy']),\n",
        "        'std_balanced_accuracy': np.std(results['balanced_accuracy']),\n",
        "        'mean_precision': np.mean(results['precision']),\n",
        "        'mean_recall': np.mean(results['recall']),\n",
        "        'mean_f1': np.mean(results['f1'])\n",
        "    }\n",
        "\n",
        "# Run all models in parallel\n",
        "models = [\n",
        "    (get_xgb_model, \"XGBoost\"),\n",
        "    (get_svm_model, \"SVM\"),\n",
        "    (get_easy_ensemble_model, \"EasyEnsemble\"),\n",
        "    (get_rf_model, \"RandomForest\")\n",
        "]\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    results = list(executor.map(lambda x: run_cv(x[0], x[1]), models))\n",
        "\n",
        "# --- Results Summary ---\n",
        "print(\"\\n=== Final Model Comparison ===\")\n",
        "for res in results:\n",
        "    print(f\"\\n{res['model_name']}:\")\n",
        "    print(f\"Accuracy: {res['mean_accuracy']:.4f}\")\n",
        "    print(f\"Balanced Accuracy: {res['mean_balanced_accuracy']:.4f} (±{res['std_balanced_accuracy']:.4f})\")\n",
        "    print(f\"Precision: {res['mean_precision']:.4f}\")\n",
        "    print(f\"Recall: {res['mean_recall']:.4f}\")\n",
        "    print(f\"F1: {res['mean_f1']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "aNkjpw3FZh1w",
        "outputId": "433622ce-c298-4ea6-f051-9c2983a8202b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Running XGBoost ===\n",
            "\n",
            "=== Running SVM ===\n",
            "\n",
            "=== Running EasyEnsemble ===\n",
            "\n",
            "=== Running RandomForest ===\n",
            "RandomForest Fold 1: Balanced Acc = 0.3677\n",
            "RandomForest Fold 2: Balanced Acc = 0.4001\n",
            "RandomForest Fold 3: Balanced Acc = 0.3949\n",
            "XGBoost Fold 1: Balanced Acc = 0.3048\n",
            "RandomForest Fold 4: Balanced Acc = 0.4282\n",
            "RandomForest Fold 5: Balanced Acc = 0.3829\n",
            "SVM Fold 1: Balanced Acc = 0.2925\n",
            "XGBoost Fold 2: Balanced Acc = 0.3512\n",
            "SVM Fold 2: Balanced Acc = 0.3638\n",
            "XGBoost Fold 3: Balanced Acc = 0.4082\n",
            "XGBoost Fold 4: Balanced Acc = 0.4104\n",
            "SVM Fold 3: Balanced Acc = 0.3018\n",
            "XGBoost Fold 5: Balanced Acc = 0.3681\n",
            "SVM Fold 4: Balanced Acc = 0.3506\n",
            "SVM Fold 5: Balanced Acc = 0.2481\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "EasyEnsembleClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-1716518005.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;31m# --- Results Summary ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    617\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0m_result_or_cancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0m_result_or_cancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-13-1716518005.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;31m# --- Results Summary ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-13-1716518005.py\u001b[0m in \u001b[0;36mrun_cv\u001b[0;34m(model_fn, model_name)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-13-1716518005.py\u001b[0m in \u001b[0;36mget_easy_ensemble_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_easy_ensemble_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     return EasyEnsembleClassifier(\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         base_estimator=RandomForestClassifier(\n",
            "\u001b[0;31mTypeError\u001b[0m: EasyEnsembleClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import balanced_accuracy_score, make_scorer, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import random\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(1927)\n",
        "np.random.seed(1927)\n",
        "\n",
        "# --- Data Loading & Preprocessing ---\n",
        "data = pd.read_csv('sledatacut.csv', parse_dates=['ASSDT'], low_memory=False)\n",
        "data = data.sort_values(['PTNO', 'ASSDT'])\n",
        "\n",
        "# --- Enhanced Feature Engineering ---\n",
        "# Time-based features\n",
        "data['time_since_first'] = data.groupby('PTNO')['ASSDT'].transform(\n",
        "    lambda x: (x - x.min()).dt.days\n",
        ")\n",
        "data['time_since_last'] = data.groupby('PTNO')['ASSDT'].transform(\n",
        "    lambda x: x.diff().dt.days.fillna(0)\n",
        ")\n",
        "\n",
        "# Interaction terms\n",
        "data['steroid_flare_interaction'] = data['STERDOSE'] * data['total_flares']\n",
        "data['sdi_age_interaction'] = data['score_n'] * data['age_at_record']\n",
        "\n",
        "# Rolling statistics\n",
        "data['sdi_rolling_mean'] = data.groupby('PTNO')['score_n'].transform(\n",
        "    lambda x: x.rolling(window=3, min_periods=1).mean()\n",
        ")\n",
        "data['flares_rolling_sum'] = data.groupby('PTNO')['total_flares'].transform(\n",
        "    lambda x: x.rolling(window=3, min_periods=1).sum()\n",
        ")\n",
        "\n",
        "# Target encoding with rare class handling\n",
        "class_counts = data['end_state'].value_counts()\n",
        "rare_classes = class_counts[class_counts < 10].index\n",
        "data['end_state'] = data['end_state'].replace(rare_classes, 'Other')\n",
        "label_encoder = LabelEncoder()\n",
        "data['end_state_encoded'] = label_encoder.fit_transform(data['end_state'])\n",
        "\n",
        "# --- Automatic Feature Selection from Numeric Variables ---\n",
        "# Select all numeric columns excluding dates and identifiers\n",
        "numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
        "numeric_cols = [col for col in numeric_cols if col not in ['PTNO', 'end_state_encoded']]\n",
        "\n",
        "# Add engineered features to the numeric columns list\n",
        "engineered_features = [\n",
        "    'time_since_first', 'time_since_last',\n",
        "    'steroid_flare_interaction', 'sdi_age_interaction',\n",
        "    'sdi_rolling_mean', 'flares_rolling_sum'\n",
        "]\n",
        "numeric_cols = list(set(numeric_cols).union(set(engineered_features)))\n",
        "\n",
        "# --- Handle Missing and Infinite Values ---\n",
        "# Fill NA with 0 for all numeric columns\n",
        "data[numeric_cols] = data[numeric_cols].fillna(0)\n",
        "\n",
        "# Replace infinite values with large finite numbers\n",
        "data[numeric_cols] = data[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
        "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].max())\n",
        "\n",
        "# Feature scaling\n",
        "scaler = MinMaxScaler()\n",
        "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
        "\n",
        "# --- Patient-level Aggregation ---\n",
        "agg_dict = {\n",
        "    **{col: 'last' for col in numeric_cols},  # Most recent observation\n",
        "    'total_flares': 'sum',                   # Total flares over time\n",
        "    'severe_flare': 'sum',                   # Total severe flares\n",
        "    'score_n': 'max',                        # Worst SDI score\n",
        "    'SLEDAI_Constitutional': 'max',          # Worst constitutional symptoms\n",
        "    'STERDOSE': 'mean'                       # Average steroid dose\n",
        "}\n",
        "\n",
        "X = data.groupby('PTNO').agg(agg_dict)\n",
        "y = data.groupby('PTNO')['end_state_encoded'].last()\n",
        "\n",
        "# --- Hyperparameter Tuning Setup ---\n",
        "# Define the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('smote', SMOTE(sampling_strategy='auto', random_state=42)),\n",
        "    ('feature_selection', SelectFromModel(\n",
        "        BalancedRandomForestClassifier(n_estimators=100, random_state=42))\n",
        "    ),\n",
        "    ('classifier', BalancedRandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Define parameter distributions for randomized search\n",
        "param_dist = {\n",
        "    'feature_selection__max_features': [0.5, 0.7, 0.9, None],\n",
        "    'feature_selection__threshold': ['median', 'mean', 0.01, 0.05],\n",
        "    'classifier__n_estimators': randint(200, 600),\n",
        "    'classifier__max_depth': randint(5, 20),\n",
        "    'classifier__min_samples_split': randint(2, 10),\n",
        "    'classifier__min_samples_leaf': randint(1, 5),\n",
        "    'classifier__max_features': ['sqrt', 'log2', 0.5, 0.7],\n",
        "    'classifier__class_weight': ['balanced', 'balanced_subsample']\n",
        "}\n",
        "\n",
        "# Scoring metric\n",
        "scorer = make_scorer(balanced_accuracy_score)\n",
        "\n",
        "# --- Cross-Validated Hyperparameter Tuning ---\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,  # Number of parameter settings sampled\n",
        "    cv=skf,\n",
        "    scoring=scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "search.fit(X, y)\n",
        "\n",
        "# --- Best Model Evaluation ---\n",
        "print(\"\\n=== Best Parameters ===\")\n",
        "print(search.best_params_)\n",
        "\n",
        "best_model = search.best_estimator_\n",
        "\n",
        "# Feature importance from best model\n",
        "feature_selector = best_model.named_steps['feature_selection']\n",
        "selected_features = feature_selector.get_support()\n",
        "selected_feature_names = X.columns[selected_features]\n",
        "\n",
        "print(\"\\n=== Selected Features ===\")\n",
        "print(selected_feature_names)\n",
        "\n",
        "# Get feature importances from the final classifier\n",
        "importances = best_model.named_steps['classifier'].feature_importances_\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': selected_feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\n=== Feature Importances ===\")\n",
        "print(feature_importance_df.head(20))\n",
        "\n",
        "# --- Cross-Validation with Best Model ---\n",
        "cv_results = {\n",
        "    'balanced_accuracy': [],\n",
        "    'accuracy': [],\n",
        "    'precision': [],\n",
        "    'recall': [],\n",
        "    'f1': []\n",
        "}\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    best_model.fit(X_train, y_train)\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    cv_results['balanced_accuracy'].append(balanced_accuracy_score(y_test, y_pred))\n",
        "    cv_results['accuracy'].append(accuracy_score(y_test, y_pred))\n",
        "    cv_results['precision'].append(precision_score(y_test, y_pred, average='weighted'))\n",
        "    cv_results['recall'].append(recall_score(y_test, y_pred, average='weighted'))\n",
        "    cv_results['f1'].append(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "    print(f\"\\nFold {fold + 1} Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# --- Final Results ---\n",
        "print(\"\\n=== Final Performance ===\")\n",
        "print(f\"Mean Balanced Accuracy: {np.mean(cv_results['balanced_accuracy']):.4f} (±{np.std(cv_results['balanced_accuracy']):.4f})\")\n",
        "print(f\"Mean Accuracy: {np.mean(cv_results['accuracy']):.4f}\")\n",
        "print(f\"Mean Precision: {np.mean(cv_results['precision']):.4f}\")\n",
        "print(f\"Mean Recall: {np.mean(cv_results['recall']):.4f}\")\n",
        "print(f\"Mean F1: {np.mean(cv_results['f1']):.4f}\")\n",
        "\n",
        "# Save the best model\n",
        "import joblib\n",
        "joblib.dump(best_model, 'best_sle_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq_SKBwPae6o",
        "outputId": "758b387d-b7ad-457e-d545-de04e52c399d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "\n",
            "=== Best Parameters ===\n",
            "{'classifier__class_weight': 'balanced', 'classifier__max_depth': 6, 'classifier__max_features': 0.5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 6, 'classifier__n_estimators': 312, 'feature_selection__max_features': None, 'feature_selection__threshold': 'median'}\n",
            "\n",
            "=== Selected Features ===\n",
            "Index(['SLED11_I', 'time_first_last', 'AGE_DX', 'cum_time', 'SDI_Ocular',\n",
            "       'AVASCNEC', 'SLEDAI_Hematological', 'STERAVER', 'SLED17_I', 'SLED15_I',\n",
            "       'SEIZURX6', 'sick_leave_spell', 'mild_flare', 'SLED13_I',\n",
            "       'SLEDAI_Other', 'SLED24_I', 'AMDOSE', 'SDI_Dermatologic', 'PROT24',\n",
            "       'ACATARACT', 'mild_flares', 'SLEDAI2_I', 'SLED21_I',\n",
            "       'sick_leave_duration', 'SDI_Musculoskeletal', 'total_visits',\n",
            "       'SLEDAI_Neurological', 'ISAVER', 'ISDOSE', 'SDI_Neuropsychiatric',\n",
            "       'ISMETH', 'SLED12_I', 'STERDUR', 'EMP_numeric', 'high_dose',\n",
            "       'SDI_Endocrine', 'sdi_age_interaction', 'SDI_Renal', 'early_retirement',\n",
            "       'total_visits96', 'SLED9_I', 'mycophenolate_ind', 'time_interval',\n",
            "       'AMS_alt', 'time_between', 'methotrexate_dose', 'MAXSTEROIDDOSE',\n",
            "       'severe_flares', 'score_n', 'severe_flare', 'time_first_last96',\n",
            "       'age_at_retirement', 'visit_num96', 'sdi_rolling_mean',\n",
            "       'methotrexate_ind', 'sledai_change', 'any_flare', 'SLED20_I', 'GFR50',\n",
            "       'ID', 'SDI_Cardiovascular', 'steroid_flare_interaction',\n",
            "       'time_to_first_change', 'total_flares', 'AMS', 'SLED23_I', 'COGNIMP',\n",
            "       'area', 'SDI_Malignancy', 'cyclosporin_dose', 'previous_sledai',\n",
            "       'SLEDAI_Renal', 'visit_num', 'MALIGNAN', 'lupus_primary_death',\n",
            "       'SLEDAI_Vascular', 'time_since_first', 'cum_area', 'SLED16_I', 'AMNAME',\n",
            "       'DEARTHRIT', 'days_since_last_visit', 'lupus_secondary_death',\n",
            "       'time_since_last', 'STERDOSE', 'imuran_ind', 'mycophenolate_dose',\n",
            "       'imuran_dose', 'time_since_dx', 'age_at_record', 'flares_rolling_sum',\n",
            "       'time_between96', 'INCEPT', 'ISTYPE', 'STERUSE'],\n",
            "      dtype='object')\n",
            "\n",
            "=== Feature Importances ===\n",
            "                Feature  Importance\n",
            "33          EMP_numeric    0.239501\n",
            "38     early_retirement    0.182488\n",
            "52          visit_num96    0.118930\n",
            "51    age_at_retirement    0.070816\n",
            "11     sick_leave_spell    0.065746\n",
            "23  sick_leave_duration    0.028470\n",
            "94              STERUSE    0.022593\n",
            "7              STERAVER    0.021209\n",
            "48              score_n    0.016615\n",
            "53     sdi_rolling_mean    0.016119\n",
            "36  sdi_age_interaction    0.013237\n",
            "76     time_since_first    0.012653\n",
            "47        severe_flares    0.011953\n",
            "67                 area    0.011750\n",
            "49         severe_flare    0.010527\n",
            "50    time_first_last96    0.010399\n",
            "37            SDI_Renal    0.008405\n",
            "3              cum_time    0.008261\n",
            "89        age_at_record    0.008002\n",
            "84             STERDOSE    0.006137\n",
            "\n",
            "Fold 1 Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "   Disability Benefit       0.95      0.77      0.85        26\n",
            "     Early Retirement       1.00      1.00      1.00         6\n",
            "Economically Inactive       0.75      0.86      0.80         7\n",
            "             Employed       0.96      0.89      0.93       152\n",
            "      Employed (Died)       0.00      0.00      0.00         5\n",
            "           Unemployed       0.35      0.78      0.48         9\n",
            "\n",
            "             accuracy                           0.85       205\n",
            "            macro avg       0.67      0.72      0.68       205\n",
            "         weighted avg       0.90      0.85      0.87       205\n",
            "\n",
            "\n",
            "Fold 2 Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "   Disability Benefit       0.92      0.85      0.88        26\n",
            "     Early Retirement       1.00      1.00      1.00         6\n",
            "Economically Inactive       0.83      0.71      0.77         7\n",
            "             Employed       0.98      0.87      0.92       152\n",
            "      Employed (Died)       0.12      0.40      0.18         5\n",
            "           Unemployed       0.53      1.00      0.69         9\n",
            "\n",
            "             accuracy                           0.86       205\n",
            "            macro avg       0.73      0.80      0.74       205\n",
            "         weighted avg       0.93      0.86      0.88       205\n",
            "\n",
            "\n",
            "Fold 3 Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "   Disability Benefit       0.79      0.85      0.81        26\n",
            "     Early Retirement       1.00      1.00      1.00         5\n",
            "Economically Inactive       1.00      1.00      1.00         7\n",
            "             Employed       0.99      0.93      0.96       153\n",
            "      Employed (Died)       0.27      0.60      0.38         5\n",
            "           Unemployed       0.60      0.67      0.63         9\n",
            "\n",
            "             accuracy                           0.90       205\n",
            "            macro avg       0.77      0.84      0.80       205\n",
            "         weighted avg       0.93      0.90      0.91       205\n",
            "\n",
            "\n",
            "Fold 4 Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "   Disability Benefit       0.79      0.76      0.78        25\n",
            "     Early Retirement       1.00      1.00      1.00         5\n",
            "Economically Inactive       0.78      1.00      0.88         7\n",
            "             Employed       0.96      0.95      0.95       153\n",
            "      Employed (Died)       0.00      0.00      0.00         6\n",
            "           Unemployed       0.57      0.89      0.70         9\n",
            "\n",
            "             accuracy                           0.90       205\n",
            "            macro avg       0.68      0.77      0.72       205\n",
            "         weighted avg       0.89      0.90      0.89       205\n",
            "\n",
            "\n",
            "Fold 5 Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "   Disability Benefit       0.75      0.92      0.83        26\n",
            "     Early Retirement       1.00      1.00      1.00         5\n",
            "Economically Inactive       0.80      0.57      0.67         7\n",
            "             Employed       0.95      0.93      0.94       152\n",
            "      Employed (Died)       0.00      0.00      0.00         6\n",
            "           Unemployed       0.33      0.33      0.33         9\n",
            "\n",
            "             accuracy                           0.86       205\n",
            "            macro avg       0.64      0.63      0.63       205\n",
            "         weighted avg       0.87      0.86      0.86       205\n",
            "\n",
            "\n",
            "=== Final Performance ===\n",
            "Mean Balanced Accuracy: 0.7507 (±0.0747)\n",
            "Mean Accuracy: 0.8751\n",
            "Mean Precision: 0.9021\n",
            "Mean Recall: 0.8751\n",
            "Mean F1: 0.8846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best_sle_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}