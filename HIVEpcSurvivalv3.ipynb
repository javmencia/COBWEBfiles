{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE37ClSCfCqeYpO8C4fvyB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javmencia/COBWEBfiles/blob/main/HIVEpcSurvivalv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "gsLAzLtjqRUM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnqPX3A3raCg",
        "outputId": "0f7918a1-c593-4a52-8cc0-7c604c4dc323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: Setting up environment...\n",
            "Environment setup complete!\n",
            "Loading pcdata.csv...\n",
            "Data loaded successfully! Shape: (8121, 101)\n",
            "Columns: ['Unnamed: 0', 'RPT', 'RINVSITE', 'STUDY', 'SEXN', 'SEX', 'RACEPRIM', 'INFCDAY', 'AGE', 'VISIT', 'VISNAME', 'DOV_ND', 'VISDAY', 'ECOGGRN', 'ECOGGR', 'STATUSN', 'STATUS', 'CONTDAY', 'LKDAY', 'DSCAUSEN', 'DSCAUSE', 'DSREAS', 'DSDECOD', 'DSBODSYS', 'DSMODIFY', 'LLTCD', 'LLTNMD', 'HLTNMD', 'HLGTNMD', 'PTCDD', 'DICTVER', 'DSDAY', 'HEIGHT', 'HEIGHTU', 'WEIGHT', 'WEIGHTU', 'BMI', 'TEMP', 'TEMPU', 'SYSBP', 'DIABP', 'DIABPU', 'PULSE', 'PULSEU', 'VTDAY', 'EXDOSENN', 'EXDOSEN', 'EXDOSE2N', 'EXDOSE2', 'EXDOSE3N', 'EXDOSE3', 'REGION', 'ENROLLDAY', 'PKSAMPN', 'PKSAMP', 'TYPEPKN', 'TYPEPK', 'PKDAY', 'TARGETQN', 'TARGETQ', 'NONTARQN', 'NONTARQ', 'cycle_number', 'total_cycles', 'anytarget', 'anynontarget', 'os_event', 'CANCDEAD', 'visit_sequence', 'total_ae_events', 'serious_ae_count', 'grade3_plus_count', 'any_grade3_plus', 'total_body_systems', 'body_systems_list', 'treatment_related_count', 'other_treatment_related_count', 'any_treatment_related', 'drug_interrupted', 'drug_reduced', 'drug_withdrawn', 'drug_not_changed', 'other_drug_interrupted', 'other_drug_reduced', 'other_drug_withdrawn', 'concomitant_treatment_given', 'grade1_count', 'grade2_count', 'grade3_count', 'grade4_count', 'grade5_count', 'ongoing_ae_count', 'mean_ae_duration', 'max_ae_duration', 'most_recent_ae_term', 'most_recent_ae_severity', 'cum_any_grade3_plus', 'cum_any_treatment_related', 'cum_drug_withdrawn', 'cum_other_drug_withdrawn', 'cum_concomitant_treatment']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Step 0: Setting up environment...\")\n",
        "\n",
        "# Manual 3D array creation function\n",
        "def create_3d_array(matrix_list):\n",
        "    if len(matrix_list) == 0:\n",
        "        raise ValueError(\"No matrices provided\")\n",
        "\n",
        "    # Get dimensions from first matrix\n",
        "    n_samples = len(matrix_list)\n",
        "    n_timesteps = matrix_list[0].shape[0]\n",
        "    n_features = matrix_list[0].shape[1]\n",
        "\n",
        "    # Create empty 3D array\n",
        "    array_3d = np.zeros((n_samples, n_timesteps, n_features))\n",
        "\n",
        "    # Fill array\n",
        "    for i in range(n_samples):\n",
        "        array_3d[i, :, :] = matrix_list[i]\n",
        "\n",
        "    return array_3d\n",
        "\n",
        "print(\"Environment setup complete!\")\n",
        "\n",
        "# Load the data\n",
        "print(\"Loading pcdata.csv...\")\n",
        "try:\n",
        "    sequential_data = pd.read_csv('pcdata.csv')\n",
        "    print(f\"Data loaded successfully! Shape: {sequential_data.shape}\")\n",
        "    print(f\"Columns: {sequential_data.columns.tolist()}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: pcdata.csv file not found. Please ensure the file is in your working directory.\")\n",
        "    exit()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nStep 1: Preparing LSTM data...\")\n",
        "\n",
        "def prepare_lstm_manual(data, sequence_length=3):\n",
        "    # Select features that are likely to be numeric\n",
        "    feature_cols = ['ECOGGRN', 'total_ae_events', 'serious_ae_count',\n",
        "                   'grade3_plus_count', 'AGE', 'VISIT', 'EXDOSENN', 'EXDOSE2N', 'EXDOSE3N', 'PKSAMPN', 'TYPEPKN', 'TARGETQN', 'NONTARQN', 'total_ae_events', 'serious_ae_count', 'grade3_plus_count', 'total_body_systems', 'treatment_related_count', 'other_treatment_related_count', 'any_treatment_related', 'drug_interrupted', 'drug_reduced', 'drug_withdrawn', 'drug_not_changed', 'other_drug_interrupted', 'other_drug_reduced', 'other_drug_withdrawn', 'concomitant_treatment_given', 'grade1_count', 'grade2_count', 'grade3_count', 'grade4_count', 'grade5_count', 'ongoing_ae_count', 'mean_ae_duration', 'max_ae_duration', 'most_recent_ae_term', 'most_recent_ae_severity', 'cum_any_grade3_plus', 'cum_any_treatment_related', 'cum_drug_withdrawn', 'cum_other_drug_withdrawn', 'cum_concomitant_treatment']\n",
        "\n",
        "    # Check which feature columns exist in the data\n",
        "    available_features = [col for col in feature_cols if col in data.columns]\n",
        "    print(f\"Available features: {available_features}\")\n",
        "\n",
        "    # Prepare data\n",
        "    data_prep = data.copy()\n",
        "\n",
        "    # Create outcome variable (assuming CANCDEAD exists)\n",
        "    if 'CANCDEAD' in data_prep.columns:\n",
        "        data_prep['outcome'] = data_prep['CANCDEAD'].astype(int) - 1\n",
        "    else:\n",
        "        print(\"WARNING: CANCDEAD column not found. Creating dummy outcome.\")\n",
        "        data_prep['outcome'] = 0\n",
        "\n",
        "    # Group by patient and count visits\n",
        "    visit_counts = data_prep.groupby('RPT').size()\n",
        "    valid_patients = visit_counts[visit_counts >= sequence_length].index\n",
        "\n",
        "    data_prep = data_prep[data_prep['RPT'].isin(valid_patients)]\n",
        "\n",
        "    # Convert features to numeric and fill NaN\n",
        "    for col in available_features:\n",
        "        data_prep[col] = pd.to_numeric(data_prep[col], errors='coerce')\n",
        "\n",
        "    data_prep[available_features] = data_prep[available_features].fillna(0)\n",
        "\n",
        "    patients = data_prep['RPT'].unique()\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    print(f\"Processing {len(patients)} patients with sufficient visits...\")\n",
        "\n",
        "    for i, patient in enumerate(patients):\n",
        "        patient_data = data_prep[data_prep['RPT'] == patient].sort_values('VISDAY')\n",
        "\n",
        "        if len(patient_data) >= sequence_length:\n",
        "            # Get the outcome (assuming it's constant per patient)\n",
        "            patient_outcome = patient_data['outcome'].iloc[0]\n",
        "\n",
        "            # Extract features as matrix\n",
        "            feature_matrix = patient_data[available_features].values\n",
        "\n",
        "            # Use the last 'sequence_length' time points\n",
        "            sequence_data = feature_matrix[-sequence_length:, :]\n",
        "\n",
        "            sequences.append(sequence_data)\n",
        "            labels.append(patient_outcome)\n",
        "\n",
        "        # Progress indicator\n",
        "        if (i + 1) % 50 == 0:\n",
        "            print(f\"Processed {i + 1} patients...\")\n",
        "\n",
        "    print(f\"Created {len(sequences)} sequences total\")\n",
        "\n",
        "    if len(sequences) == 0:\n",
        "        raise ValueError(\"No sequences were created. Possible issues:\\n\"\n",
        "                        f\"- Not enough patients with {sequence_length} visits\\n\"\n",
        "                        \"- Feature columns may contain non-numeric data\\n\"\n",
        "                        \"- Check if CANCDEAD variable exists and has values\")\n",
        "\n",
        "    # Create 3D array using our manual function\n",
        "    sequences_array = create_3d_array(sequences)\n",
        "\n",
        "    return {\n",
        "        'sequences': sequences_array,\n",
        "        'labels': np.array(labels)\n",
        "    }\n",
        "\n",
        "# Prepare the data\n",
        "try:\n",
        "    lstm_data = prepare_lstm_manual(sequential_data, sequence_length=3)\n",
        "    print(\"SUCCESS: LSTM data prepared!\")\n",
        "    print(f\"Sequences dimension: {lstm_data['sequences'].shape}\")\n",
        "    print(f\"Labels: {len(lstm_data['labels'])}\")\n",
        "    print(f\"Class distribution - 0: {sum(lstm_data['labels'] == 0)} 1: {sum(lstm_data['labels'] == 1)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR in data preparation: {e}\")\n",
        "\n",
        "    # Diagnostic information\n",
        "    print(\"\\nDIAGNOSTIC INFORMATION:\")\n",
        "    print(f\"Number of patients: {sequential_data['RPT'].nunique()}\")\n",
        "    print(f\"Variables in sequential_data: {sequential_data.columns.tolist()}\")\n",
        "    if 'CANCDEAD' in sequential_data.columns:\n",
        "        print(f\"CANCDEAD values:\\n{sequential_data['CANCDEAD'].value_counts()}\")\n",
        "\n",
        "    visit_counts = sequential_data.groupby('RPT').size()\n",
        "    print(\"Visit counts summary:\")\n",
        "    print(visit_counts.describe())\n",
        "\n",
        "print(\"\\nStep 2: Normalizing data...\")\n",
        "\n",
        "def normalize_3d_manual(array_3d):\n",
        "    dims = array_3d.shape\n",
        "    print(f\"Normalizing array with dimensions: {dims}\")\n",
        "\n",
        "    # Normalize each feature across all samples and timesteps\n",
        "    for feature_idx in range(dims[2]):\n",
        "        feature_data = array_3d[:, :, feature_idx]\n",
        "        mean_val = np.mean(feature_data)\n",
        "        sd_val = np.std(feature_data)\n",
        "\n",
        "        if sd_val > 0:\n",
        "            array_3d[:, :, feature_idx] = (feature_data - mean_val) / sd_val\n",
        "        # If sd = 0, leave as is (constant feature)\n",
        "\n",
        "    array_3d = np.nan_to_num(array_3d)\n",
        "    return array_3d\n",
        "\n",
        "if 'lstm_data' in locals():\n",
        "    X_sequences = normalize_3d_manual(lstm_data['sequences'].copy())\n",
        "    y = lstm_data['labels']\n",
        "\n",
        "    print(\"Normalization completed!\")\n",
        "    print(f\"Data range: [{X_sequences.min():.3f}, {X_sequences.max():.3f}]\")\n",
        "else:\n",
        "    print(\"Cannot normalize - lstm_data not created\")\n",
        "\n",
        "print(\"\\nStep 3: Creating train-test split...\")\n",
        "\n",
        "if 'X_sequences' in locals() and 'y' in locals():\n",
        "    # Check if we have enough samples\n",
        "    if len(y) < 10:\n",
        "        print(f\"Warning: Only {len(y)} samples available. Using 80% for training.\")\n",
        "        test_size = 0.2\n",
        "    else:\n",
        "        test_size = 0.3\n",
        "\n",
        "    # Create stratified split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_sequences, y,\n",
        "        test_size=test_size,\n",
        "        random_state=123,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    print(\"Training set:\")\n",
        "    print(f\"  Sequences: {X_train.shape}\")\n",
        "    print(f\"  Labels: {len(y_train)} (0: {sum(y_train == 0)} 1: {sum(y_train == 1)})\")\n",
        "\n",
        "    print(\"Test set:\")\n",
        "    print(f\"  Sequences: {X_test.shape}\")\n",
        "    print(f\"  Labels: {len(y_test)} (0: {sum(y_test == 0)} 1: {sum(y_test == 1)})\")\n",
        "else:\n",
        "    print(\"Cannot create split - data not available\")\n",
        "\n",
        "print(\"\\nStep 4: Building LSTM model...\")\n",
        "\n",
        "def build_lstm_model_simple(sequence_length, n_features):\n",
        "    # Simple LSTM model\n",
        "    model = Sequential([\n",
        "        LSTM(32, input_shape=(sequence_length, n_features), return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        metrics=['accuracy', 'AUC']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "if 'X_train' in locals() and 'y_train' in locals():\n",
        "    # Get model dimensions\n",
        "    sequence_length = X_train.shape[1]\n",
        "    n_features = X_train.shape[2]\n",
        "\n",
        "    print(\"Building model for:\")\n",
        "    print(f\"  Sequence length: {sequence_length}\")\n",
        "    print(f\"  Features: {n_features}\")\n",
        "    print(f\"  Training samples: {X_train.shape[0]}\")\n",
        "\n",
        "    # Build model\n",
        "    lstm_model = build_lstm_model_simple(sequence_length, n_features)\n",
        "\n",
        "    print(\"Model architecture:\")\n",
        "    lstm_model.summary()\n",
        "\n",
        "    print(\"\\nStep 5: Training LSTM model...\")\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        monitor='val_loss'\n",
        "    )\n",
        "\n",
        "    history = lstm_model.fit(\n",
        "        x=X_train,\n",
        "        y=y_train,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        verbose=1,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "\n",
        "else:\n",
        "    print(\"Cannot build model - training data not available\")\n",
        "\n",
        "print(\"\\nStep 6: Evaluating LSTM model...\")\n",
        "\n",
        "if 'lstm_model' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
        "    # Make predictions\n",
        "    predictions = lstm_model.predict(X_test)\n",
        "    predicted_probs = predictions.flatten()\n",
        "\n",
        "    # Convert to binary predictions\n",
        "    predicted_classes = (predicted_probs > 0.5).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    conf_matrix = confusion_matrix(y_test, predicted_classes)\n",
        "    accuracy = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
        "\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    # AUC\n",
        "    if len(np.unique(y_test)) > 1:\n",
        "        auc_val = roc_auc_score(y_test, predicted_probs)\n",
        "    else:\n",
        "        auc_val = np.nan\n",
        "\n",
        "    # Print results\n",
        "    print(\"=\" * 50)\n",
        "    print(\"LSTM MODEL PERFORMANCE\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Accuracy:    {accuracy:.3f}\")\n",
        "    print(f\"Sensitivity: {sensitivity:.3f}\")\n",
        "    print(f\"Specificity: {specificity:.3f}\")\n",
        "    print(f\"AUC:         {auc_val:.3f}\")\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, predicted_classes))\n",
        "\n",
        "    # Plot results if we have AUC\n",
        "    if not np.isnan(auc_val):\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        # ROC curve\n",
        "        fpr, tpr, _ = roc_curve(y_test, predicted_probs)\n",
        "        ax1.plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {auc_val:.3f}')\n",
        "        ax1.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
        "        ax1.set_xlabel('False Positive Rate')\n",
        "        ax1.set_ylabel('True Positive Rate')\n",
        "        ax1.set_title('ROC Curve')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # Training history\n",
        "        if 'history' in locals():\n",
        "            ax2.plot(history.history['loss'], 'b-', label='Train')\n",
        "            if 'val_loss' in history.history:\n",
        "                ax2.plot(history.history['val_loss'], 'r-', label='Validation')\n",
        "            ax2.set_xlabel('Epoch')\n",
        "            ax2.set_ylabel('Loss')\n",
        "            ax2.set_title('Training Loss')\n",
        "            ax2.legend()\n",
        "            ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Cannot evaluate - model or test data not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5JKZ_mPuaW5",
        "outputId": "95d27792-f544-4f2e-81f8-bee7170282cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 1: Preparing LSTM data...\n",
            "Available features: ['ECOGGRN', 'total_ae_events', 'serious_ae_count', 'grade3_plus_count', 'AGE', 'VISIT', 'EXDOSENN', 'EXDOSE2N', 'EXDOSE3N', 'PKSAMPN', 'TYPEPKN', 'TARGETQN', 'NONTARQN', 'total_ae_events', 'serious_ae_count', 'grade3_plus_count', 'total_body_systems', 'treatment_related_count', 'other_treatment_related_count', 'any_treatment_related', 'drug_interrupted', 'drug_reduced', 'drug_withdrawn', 'drug_not_changed', 'other_drug_interrupted', 'other_drug_reduced', 'other_drug_withdrawn', 'concomitant_treatment_given', 'grade1_count', 'grade2_count', 'grade3_count', 'grade4_count', 'grade5_count', 'ongoing_ae_count', 'mean_ae_duration', 'max_ae_duration', 'most_recent_ae_term', 'most_recent_ae_severity', 'cum_any_grade3_plus', 'cum_any_treatment_related', 'cum_drug_withdrawn', 'cum_other_drug_withdrawn', 'cum_concomitant_treatment']\n",
            "ERROR in data preparation: Columns must be same length as key\n",
            "\n",
            "DIAGNOSTIC INFORMATION:\n",
            "Number of patients: 526\n",
            "Variables in sequential_data: ['Unnamed: 0', 'RPT', 'RINVSITE', 'STUDY', 'SEXN', 'SEX', 'RACEPRIM', 'INFCDAY', 'AGE', 'VISIT', 'VISNAME', 'DOV_ND', 'VISDAY', 'ECOGGRN', 'ECOGGR', 'STATUSN', 'STATUS', 'CONTDAY', 'LKDAY', 'DSCAUSEN', 'DSCAUSE', 'DSREAS', 'DSDECOD', 'DSBODSYS', 'DSMODIFY', 'LLTCD', 'LLTNMD', 'HLTNMD', 'HLGTNMD', 'PTCDD', 'DICTVER', 'DSDAY', 'HEIGHT', 'HEIGHTU', 'WEIGHT', 'WEIGHTU', 'BMI', 'TEMP', 'TEMPU', 'SYSBP', 'DIABP', 'DIABPU', 'PULSE', 'PULSEU', 'VTDAY', 'EXDOSENN', 'EXDOSEN', 'EXDOSE2N', 'EXDOSE2', 'EXDOSE3N', 'EXDOSE3', 'REGION', 'ENROLLDAY', 'PKSAMPN', 'PKSAMP', 'TYPEPKN', 'TYPEPK', 'PKDAY', 'TARGETQN', 'TARGETQ', 'NONTARQN', 'NONTARQ', 'cycle_number', 'total_cycles', 'anytarget', 'anynontarget', 'os_event', 'CANCDEAD', 'visit_sequence', 'total_ae_events', 'serious_ae_count', 'grade3_plus_count', 'any_grade3_plus', 'total_body_systems', 'body_systems_list', 'treatment_related_count', 'other_treatment_related_count', 'any_treatment_related', 'drug_interrupted', 'drug_reduced', 'drug_withdrawn', 'drug_not_changed', 'other_drug_interrupted', 'other_drug_reduced', 'other_drug_withdrawn', 'concomitant_treatment_given', 'grade1_count', 'grade2_count', 'grade3_count', 'grade4_count', 'grade5_count', 'ongoing_ae_count', 'mean_ae_duration', 'max_ae_duration', 'most_recent_ae_term', 'most_recent_ae_severity', 'cum_any_grade3_plus', 'cum_any_treatment_related', 'cum_drug_withdrawn', 'cum_other_drug_withdrawn', 'cum_concomitant_treatment']\n",
            "CANCDEAD values:\n",
            "CANCDEAD\n",
            "0    7051\n",
            "1    1070\n",
            "Name: count, dtype: int64\n",
            "Visit counts summary:\n",
            "count    526.000000\n",
            "mean      15.439163\n",
            "std        6.940777\n",
            "min        2.000000\n",
            "25%       10.000000\n",
            "50%       14.000000\n",
            "75%       19.000000\n",
            "max       48.000000\n",
            "dtype: float64\n",
            "\n",
            "Step 2: Normalizing data...\n",
            "Cannot normalize - lstm_data not created\n",
            "\n",
            "Step 3: Creating train-test split...\n",
            "Cannot create split - data not available\n",
            "\n",
            "Step 4: Building LSTM model...\n",
            "Cannot build model - training data not available\n",
            "\n",
            "Step 6: Evaluating LSTM model...\n",
            "Cannot evaluate - model or test data not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Step 0: Setting up environment...\")\n",
        "\n",
        "# Manual 3D array creation function\n",
        "def create_3d_array(matrix_list):\n",
        "    if len(matrix_list) == 0:\n",
        "        raise ValueError(\"No matrices provided\")\n",
        "\n",
        "    # Get dimensions from first matrix\n",
        "    n_samples = len(matrix_list)\n",
        "    n_timesteps = matrix_list[0].shape[0]\n",
        "    n_features = matrix_list[0].shape[1]\n",
        "\n",
        "    # Create empty 3D array\n",
        "    array_3d = np.zeros((n_samples, n_timesteps, n_features))\n",
        "\n",
        "    # Fill array\n",
        "    for i in range(n_samples):\n",
        "        array_3d[i, :, :] = matrix_list[i]\n",
        "\n",
        "    return array_3d\n",
        "\n",
        "print(\"Environment setup complete!\")\n",
        "\n",
        "# Load the data\n",
        "print(\"Loading pcdata.csv...\")\n",
        "try:\n",
        "    sequential_data = pd.read_csv('pcdata.csv')\n",
        "    print(f\"Data loaded successfully! Shape: {sequential_data.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: pcdata.csv file not found.\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nStep 1: Improved LSTM data preparation with better feature selection...\")\n",
        "\n",
        "def prepare_lstm_improved(data, sequence_length=3):\n",
        "    # Select only the most relevant and clean features\n",
        "    essential_features = [\n",
        "        # Demographic\n",
        "        'AGE', 'ECOGGRN',\n",
        "        # Dosing\n",
        "        'EXDOSENN',\n",
        "        # Tumor response\n",
        "        'TARGETQN', 'NONTARQN',\n",
        "        # AE counts (most important)\n",
        "        'total_ae_events', 'serious_ae_count', 'grade3_plus_count',\n",
        "        'grade3_count', 'grade4_count', 'grade5_count',\n",
        "        # Treatment impact\n",
        "        'drug_withdrawn', 'concomitant_treatment_given',\n",
        "        # Time\n",
        "        'VISDAY'\n",
        "    ]\n",
        "\n",
        "    # Check which feature columns exist in the data\n",
        "    available_features = [col for col in essential_features if col in data.columns]\n",
        "    print(f\"Selected {len(available_features)} essential features\")\n",
        "    print(f\"Features: {available_features}\")\n",
        "\n",
        "    # Prepare data\n",
        "    data_prep = data.copy()\n",
        "\n",
        "    # Create outcome variable\n",
        "    if 'CANCDEAD' in data_prep.columns:\n",
        "        data_prep['outcome'] = data_prep['CANCDEAD'].astype(int)\n",
        "        # Ensure binary outcome (0, 1)\n",
        "        if data_prep['outcome'].min() < 0:\n",
        "            data_prep['outcome'] = (data_prep['outcome'] > 0).astype(int)\n",
        "        print(f\"Outcome distribution: {data_prep['outcome'].value_counts().to_dict()}\")\n",
        "    else:\n",
        "        print(\"WARNING: CANCDEAD column not found.\")\n",
        "        return None\n",
        "\n",
        "    # Remove patients with insufficient visits\n",
        "    visit_counts = data_prep.groupby('RPT').size()\n",
        "    valid_patients = visit_counts[visit_counts >= sequence_length].index\n",
        "    data_prep = data_prep[data_prep['RPT'].isin(valid_patients)]\n",
        "\n",
        "    print(f\"Patients with sufficient visits: {len(valid_patients)}\")\n",
        "\n",
        "    # Convert features to numeric and handle missing values robustly\n",
        "    for col in available_features:\n",
        "        data_prep[col] = pd.to_numeric(data_prep[col], errors='coerce')\n",
        "        # Use median imputation\n",
        "        median_val = data_prep[col].median()\n",
        "        data_prep[col] = data_prep[col].fillna(median_val)\n",
        "        print(f\"  {col}: median={median_val:.3f}, missing={data_prep[col].isna().sum()}\")\n",
        "\n",
        "    # Remove constant features\n",
        "    constant_features = []\n",
        "    for col in available_features:\n",
        "        if data_prep[col].nunique() <= 1:\n",
        "            constant_features.append(col)\n",
        "\n",
        "    if constant_features:\n",
        "        print(f\"Removing constant features: {constant_features}\")\n",
        "        available_features = [f for f in available_features if f not in constant_features]\n",
        "\n",
        "    patients = data_prep['RPT'].unique()\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    print(f\"Processing {len(patients)} patients...\")\n",
        "\n",
        "    for i, patient in enumerate(patients):\n",
        "        patient_data = data_prep[data_prep['RPT'] == patient].sort_values('VISDAY')\n",
        "\n",
        "        if len(patient_data) >= sequence_length:\n",
        "            patient_outcome = patient_data['outcome'].iloc[0]\n",
        "            feature_matrix = patient_data[available_features].values\n",
        "\n",
        "            # Use the last 'sequence_length' time points\n",
        "            sequence_data = feature_matrix[-sequence_length:, :]\n",
        "\n",
        "            sequences.append(sequence_data)\n",
        "            labels.append(patient_outcome)\n",
        "\n",
        "        if (i + 1) % 50 == 0:\n",
        "            print(f\"Processed {i + 1} patients...\")\n",
        "\n",
        "    print(f\"Created {len(sequences)} sequences\")\n",
        "\n",
        "    if len(sequences) == 0:\n",
        "        raise ValueError(\"No sequences created\")\n",
        "\n",
        "    # Create 3D array\n",
        "    sequences_array = create_3d_array(sequences)\n",
        "\n",
        "    return {\n",
        "        'sequences': sequences_array,\n",
        "        'labels': np.array(labels),\n",
        "        'feature_names': available_features\n",
        "    }\n",
        "\n",
        "# Prepare the data\n",
        "try:\n",
        "    lstm_data = prepare_lstm_improved(sequential_data, sequence_length=3)\n",
        "    if lstm_data is None:\n",
        "        raise ValueError(\"Data preparation failed\")\n",
        "\n",
        "    print(\"SUCCESS: LSTM data prepared!\")\n",
        "    print(f\"Sequences dimension: {lstm_data['sequences'].shape}\")\n",
        "    print(f\"Labels: {len(lstm_data['labels'])}\")\n",
        "    print(f\"Class distribution - 0: {sum(lstm_data['labels'] == 0)} 1: {sum(lstm_data['labels'] == 1)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR in data preparation: {e}\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nStep 2: Robust normalization with NaN handling...\")\n",
        "\n",
        "def robust_normalize_3d(array_3d, feature_names):\n",
        "    dims = array_3d.shape\n",
        "    print(f\"Normalizing array with dimensions: {dims}\")\n",
        "\n",
        "    n_samples, n_timesteps, n_features = dims\n",
        "    X_reshaped = array_3d.reshape(n_samples * n_timesteps, n_features)\n",
        "\n",
        "    # Check for NaN and infinite values\n",
        "    print(f\"NaN values before cleaning: {np.isnan(X_reshaped).sum()}\")\n",
        "    print(f\"Inf values before cleaning: {np.isinf(X_reshaped).sum()}\")\n",
        "\n",
        "    # Replace any remaining NaN/Inf with 0\n",
        "    X_reshaped = np.nan_to_num(X_reshaped, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    # Use RobustScaler which is less sensitive to outliers\n",
        "    scaler = RobustScaler()\n",
        "    X_normalized = scaler.fit_transform(X_reshaped)\n",
        "\n",
        "    # Check for any issues after scaling\n",
        "    if np.isnan(X_normalized).any() or np.isinf(X_normalized).any():\n",
        "        print(\"WARNING: NaN/Inf values after scaling. Using fallback normalization.\")\n",
        "        # Fallback: manual robust normalization\n",
        "        X_normalized = np.zeros_like(X_reshaped)\n",
        "        for i in range(n_features):\n",
        "            feature_data = X_reshaped[:, i]\n",
        "            median = np.median(feature_data)\n",
        "            iqr = np.percentile(feature_data, 75) - np.percentile(feature_data, 25)\n",
        "            if iqr > 0:\n",
        "                X_normalized[:, i] = (feature_data - median) / iqr\n",
        "            else:\n",
        "                # Constant feature, just center\n",
        "                X_normalized[:, i] = feature_data - median\n",
        "\n",
        "    # Reshape back to 3D\n",
        "    array_3d_normalized = X_normalized.reshape(n_samples, n_timesteps, n_features)\n",
        "\n",
        "    print(f\"Normalization completed! Data range: [{array_3d_normalized.min():.3f}, {array_3d_normalized.max():.3f}]\")\n",
        "    print(f\"NaN values after normalization: {np.isnan(array_3d_normalized).sum()}\")\n",
        "\n",
        "    return array_3d_normalized, scaler\n",
        "\n",
        "if 'lstm_data' in locals():\n",
        "    X_sequences, scaler = robust_normalize_3d(lstm_data['sequences'].copy(),\n",
        "                                            lstm_data.get('feature_names'))\n",
        "    y = lstm_data['labels']\n",
        "\n",
        "    print(f\"Final label distribution: 0: {sum(y == 0)}, 1: {sum(y == 1)}\")\n",
        "else:\n",
        "    print(\"Cannot normalize - lstm_data not created\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nStep 3: Creating train-test split...\")\n",
        "\n",
        "if 'X_sequences' in locals() and 'y' in locals():\n",
        "    # Final check for NaN\n",
        "    if np.isnan(X_sequences).any():\n",
        "        print(\"WARNING: NaN values detected in sequences. Replacing with 0.\")\n",
        "        X_sequences = np.nan_to_num(X_sequences)\n",
        "\n",
        "    # Create stratified split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_sequences, y,\n",
        "        test_size=0.3,\n",
        "        random_state=42,  # Changed seed for different split\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    print(\"Training set:\")\n",
        "    print(f\"  Sequences: {X_train.shape}\")\n",
        "    print(f\"  Labels: {len(y_train)} (0: {sum(y_train == 0)} 1: {sum(y_train == 1)})\")\n",
        "\n",
        "    print(\"Test set:\")\n",
        "    print(f\"  Sequences: {X_test.shape}\")\n",
        "    print(f\"  Labels: {len(y_test)} (0: {sum(y_test == 0)} 1: {sum(y_test == 1)})\")\n",
        "\n",
        "else:\n",
        "    print(\"Cannot create split - data not available\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nStep 4: Building robust LSTM model...\")\n",
        "\n",
        "def build_robust_lstm_model(sequence_length, n_features):\n",
        "    # Simpler, more robust model\n",
        "    model = Sequential([\n",
        "        LSTM(32,\n",
        "             input_shape=(sequence_length, n_features),\n",
        "             return_sequences=False,\n",
        "             kernel_initializer='glorot_uniform',\n",
        "             recurrent_initializer='orthogonal'),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(16, activation='relu', kernel_initializer='he_normal'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(8, activation='relu', kernel_initializer='he_normal'),\n",
        "        Dropout(0.1),\n",
        "\n",
        "        Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform')\n",
        "    ])\n",
        "\n",
        "    # Use a conservative optimizer\n",
        "    optimizer = Adam(\n",
        "        learning_rate=0.001,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-7,\n",
        "        clipnorm=1.0  # Gradient clipping\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=optimizer,\n",
        "        metrics=['accuracy', 'AUC']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "if 'X_train' in locals() and 'y_train' in locals():\n",
        "    # Get model dimensions\n",
        "    sequence_length = X_train.shape[1]\n",
        "    n_features = X_train.shape[2]\n",
        "\n",
        "    print(\"Building model for:\")\n",
        "    print(f\"  Sequence length: {sequence_length}\")\n",
        "    print(f\"  Features: {n_features}\")\n",
        "    print(f\"  Training samples: {X_train.shape[0]}\")\n",
        "\n",
        "    # Calculate class weights\n",
        "    class_counts = np.bincount(y_train)\n",
        "    if len(class_counts) > 1:\n",
        "        total = len(y_train)\n",
        "        class_weights = {\n",
        "            0: total / (2 * class_counts[0]),\n",
        "            1: total / (2 * class_counts[1])\n",
        "        }\n",
        "        print(f\"Class weights: {class_weights}\")\n",
        "    else:\n",
        "        class_weights = {0: 1, 1: 1}\n",
        "        print(\"Using equal class weights\")\n",
        "\n",
        "    # Build model\n",
        "    lstm_model = build_robust_lstm_model(sequence_length, n_features)\n",
        "\n",
        "    print(\"Model architecture:\")\n",
        "    lstm_model.summary()\n",
        "\n",
        "    print(\"\\nStep 5: Training LSTM model with careful monitoring...\")\n",
        "\n",
        "    # Enhanced callbacks\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_auc' if len(np.unique(y_train)) > 1 else 'val_loss',\n",
        "        patience=20,\n",
        "        restore_best_weights=True,\n",
        "        mode='max' if len(np.unique(y_train)) > 1 else 'min',\n",
        "        verbose=1,\n",
        "        min_delta=0.001\n",
        "    )\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=10,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1,\n",
        "        min_delta=0.001\n",
        "    )\n",
        "\n",
        "    # Prepare validation data\n",
        "    if len(np.unique(y_train)) > 1:\n",
        "        # Use proper validation split\n",
        "        val_split = 0.2\n",
        "    else:\n",
        "        val_split = 0.0\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "\n",
        "    try:\n",
        "        history = lstm_model.fit(\n",
        "            x=X_train,\n",
        "            y=y_train,\n",
        "            epochs=100,\n",
        "            batch_size=16,\n",
        "            validation_split=val_split,\n",
        "            class_weight=class_weights,\n",
        "            verbose=1,\n",
        "            callbacks=[early_stopping, reduce_lr],\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        print(\"Training completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Training failed: {e}\")\n",
        "        print(\"Trying with simpler configuration...\")\n",
        "\n",
        "        # Fallback training\n",
        "        history = lstm_model.fit(\n",
        "            x=X_train,\n",
        "            y=y_train,\n",
        "            epochs=50,\n",
        "            batch_size=32,\n",
        "            validation_split=0.0,\n",
        "            verbose=1,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "else:\n",
        "    print(\"Cannot build model - training data not available\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nStep 6: Evaluating LSTM model...\")\n",
        "\n",
        "if 'lstm_model' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
        "    try:\n",
        "        # Make predictions\n",
        "        predictions = lstm_model.predict(X_test, verbose=0)\n",
        "        predicted_probs = predictions.flatten()\n",
        "\n",
        "        # Check for NaN in predictions\n",
        "        if np.isnan(predicted_probs).any():\n",
        "            print(\"WARNING: NaN in predictions. Using fallback.\")\n",
        "            predicted_probs = np.zeros_like(predicted_probs) + 0.5\n",
        "\n",
        "        # Convert to binary predictions\n",
        "        threshold = 0.5\n",
        "        predicted_classes = (predicted_probs > threshold).astype(int)\n",
        "\n",
        "        # Calculate metrics\n",
        "        conf_matrix = confusion_matrix(y_test, predicted_classes)\n",
        "        accuracy = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
        "\n",
        "        if conf_matrix.shape == (2, 2):\n",
        "            tn, fp, fn, tp = conf_matrix.ravel()\n",
        "            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        else:\n",
        "            sensitivity = specificity = precision = accuracy\n",
        "\n",
        "        # AUC\n",
        "        if len(np.unique(y_test)) > 1:\n",
        "            try:\n",
        "                auc_val = roc_auc_score(y_test, predicted_probs)\n",
        "            except:\n",
        "                auc_val = 0.5\n",
        "        else:\n",
        "            auc_val = 0.5\n",
        "\n",
        "        # Print results\n",
        "        print(\"=\" * 60)\n",
        "        print(\"ROBUST LSTM MODEL PERFORMANCE\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Accuracy:    {accuracy:.3f}\")\n",
        "        print(f\"Sensitivity: {sensitivity:.3f}\")\n",
        "        print(f\"Specificity: {specificity:.3f}\")\n",
        "        print(f\"Precision:   {precision:.3f}\")\n",
        "        print(f\"AUC:         {auc_val:.3f}\")\n",
        "        print(f\"\\nConfusion Matrix:\")\n",
        "        print(conf_matrix)\n",
        "\n",
        "        if len(np.unique(y_test)) > 1:\n",
        "            print(f\"\\nClassification Report:\")\n",
        "            print(classification_report(y_test, predicted_classes,\n",
        "                                      target_names=['Class 0', 'Class 1']))\n",
        "\n",
        "        # Plot results\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        # ROC curve\n",
        "        if len(np.unique(y_test)) > 1:\n",
        "            fpr, tpr, _ = roc_curve(y_test, predicted_probs)\n",
        "            axes[0].plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {auc_val:.3f}')\n",
        "            axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
        "            axes[0].set_xlabel('False Positive Rate')\n",
        "            axes[0].set_ylabel('True Positive Rate')\n",
        "            axes[0].set_title('ROC Curve')\n",
        "            axes[0].legend()\n",
        "            axes[0].grid(True)\n",
        "        else:\n",
        "            axes[0].text(0.5, 0.5, 'Single class\\nNo ROC curve',\n",
        "                        ha='center', va='center', transform=axes[0].transAxes)\n",
        "            axes[0].set_title('ROC Curve')\n",
        "\n",
        "        # Training history (if available)\n",
        "        if 'history' in locals() and 'loss' in history.history:\n",
        "            axes[1].plot(history.history['loss'], 'b-', label='Train Loss')\n",
        "            if 'val_loss' in history.history and len(history.history['val_loss']) > 0:\n",
        "                axes[1].plot(history.history['val_loss'], 'r-', label='Val Loss')\n",
        "            axes[1].set_xlabel('Epoch')\n",
        "            axes[1].set_ylabel('Loss')\n",
        "            axes[1].set_title('Training History')\n",
        "            axes[1].legend()\n",
        "            axes[1].grid(True)\n",
        "        else:\n",
        "            axes[1].text(0.5, 0.5, 'No training history\\navailable',\n",
        "                        ha='center', va='center', transform=axes[1].transAxes)\n",
        "            axes[1].set_title('Training History')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in evaluation: {e}\")\n",
        "        print(\"This indicates the model didn't train properly.\")\n",
        "\n",
        "else:\n",
        "    print(\"Cannot evaluate - model or test data not available\")\n",
        "\n",
        "print(\"\\nStep 7: Data quality summary...\")\n",
        "if 'lstm_data' in locals():\n",
        "    print(\"Data Quality Report:\")\n",
        "    print(f\"Total sequences: {len(lstm_data['labels'])}\")\n",
        "    print(f\"Feature count: {lstm_data['sequences'].shape[2]}\")\n",
        "    print(f\"Class balance: {np.bincount(lstm_data['labels'])}\")\n",
        "    print(f\"Sequence length: {lstm_data['sequences'].shape[1]}\")\n",
        "\n",
        "    # Check data statistics\n",
        "    X_flat = lstm_data['sequences'].reshape(-1, lstm_data['sequences'].shape[2])\n",
        "    print(f\"Data statistics:\")\n",
        "    print(f\"  Min: {X_flat.min():.3f}\")\n",
        "    print(f\"  Max: {X_flat.max():.3f}\")\n",
        "    print(f\"  Mean: {X_flat.mean():.3f}\")\n",
        "    print(f\"  Std: {X_flat.std():.3f}\")\n",
        "    print(f\"  NaN values: {np.isnan(X_flat).sum()}\")\n",
        "    print(f\"  Inf values: {np.isinf(X_flat).sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ktbGerx6x_YU",
        "outputId": "2b9e22b6-4223-4528-9691-49a6fc82faa0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: Setting up environment...\n",
            "Environment setup complete!\n",
            "Loading pcdata.csv...\n",
            "Data loaded successfully! Shape: (8121, 101)\n",
            "\n",
            "Step 1: Improved LSTM data preparation with better feature selection...\n",
            "Selected 14 essential features\n",
            "Features: ['AGE', 'ECOGGRN', 'EXDOSENN', 'TARGETQN', 'NONTARQN', 'total_ae_events', 'serious_ae_count', 'grade3_plus_count', 'grade3_count', 'grade4_count', 'grade5_count', 'drug_withdrawn', 'concomitant_treatment_given', 'VISDAY']\n",
            "Outcome distribution: {0: 7051, 1: 1070}\n",
            "Patients with sufficient visits: 525\n",
            "  AGE: median=68.000, missing=0\n",
            "  ECOGGRN: median=1.000, missing=0\n",
            "  EXDOSENN: median=1.000, missing=0\n",
            "  TARGETQN: median=1.000, missing=0\n",
            "  NONTARQN: median=1.000, missing=0\n",
            "  total_ae_events: median=7.000, missing=0\n",
            "  serious_ae_count: median=0.000, missing=0\n",
            "  grade3_plus_count: median=0.000, missing=0\n",
            "  grade3_count: median=0.000, missing=0\n",
            "  grade4_count: median=0.000, missing=0\n",
            "  grade5_count: median=0.000, missing=0\n",
            "  drug_withdrawn: median=0.000, missing=0\n",
            "  concomitant_treatment_given: median=1.000, missing=0\n",
            "  VISDAY: median=106.000, missing=0\n",
            "Processing 525 patients...\n",
            "Processed 50 patients...\n",
            "Processed 100 patients...\n",
            "Processed 150 patients...\n",
            "Processed 200 patients...\n",
            "Processed 250 patients...\n",
            "Processed 300 patients...\n",
            "Processed 350 patients...\n",
            "Processed 400 patients...\n",
            "Processed 450 patients...\n",
            "Processed 500 patients...\n",
            "Created 525 sequences\n",
            "SUCCESS: LSTM data prepared!\n",
            "Sequences dimension: (525, 3, 14)\n",
            "Labels: 525\n",
            "Class distribution - 0: 449 1: 76\n",
            "\n",
            "Step 2: Robust normalization with NaN handling...\n",
            "Normalizing array with dimensions: (525, 3, 14)\n",
            "NaN values before cleaning: 0\n",
            "Inf values before cleaning: 0\n",
            "Normalization completed! Data range: [-2.000, 9.000]\n",
            "NaN values after normalization: 0\n",
            "Final label distribution: 0: 449, 1: 76\n",
            "\n",
            "Step 3: Creating train-test split...\n",
            "Training set:\n",
            "  Sequences: (367, 3, 14)\n",
            "  Labels: 367 (0: 314 1: 53)\n",
            "Test set:\n",
            "  Sequences: (158, 3, 14)\n",
            "  Labels: 158 (0: 135 1: 23)\n",
            "\n",
            "Step 4: Building robust LSTM model...\n",
            "Building model for:\n",
            "  Sequence length: 3\n",
            "  Features: 14\n",
            "  Training samples: 367\n",
            "Class weights: {0: np.float64(0.5843949044585988), 1: np.float64(3.4622641509433962)}\n",
            "Model architecture:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " lstm (\u001b[38;5;33mLSTM\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      \u001b[38;5;34m6,016\u001b[0m \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                        \u001b[38;5;34m528\u001b[0m \n",
              "\n",
              " batch_normalization              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                         \u001b[38;5;34m64\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
              "\n",
              " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                         \u001b[38;5;34m136\u001b[0m \n",
              "\n",
              " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                           \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                           \u001b[38;5;34m9\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,016</span> \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> \n",
              "\n",
              " batch_normalization              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
              "\n",
              " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> \n",
              "\n",
              " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,753\u001b[0m (26.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,753</span> (26.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,721\u001b[0m (26.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,721</span> (26.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m32\u001b[0m (128.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (128.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 5: Training LSTM model with careful monitoring...\n",
            "Starting training...\n",
            "Epoch 1/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - AUC: 0.4502 - accuracy: 0.6712 - loss: 1.3490 - val_AUC: 0.5587 - val_accuracy: 0.7027 - val_loss: 0.6591 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.5429 - accuracy: 0.6455 - loss: 0.9327 - val_AUC: 0.5559 - val_accuracy: 0.5946 - val_loss: 0.6701 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.5678 - accuracy: 0.6315 - loss: 0.8636 - val_AUC: 0.5606 - val_accuracy: 0.5676 - val_loss: 0.6744 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.5315 - accuracy: 0.6443 - loss: 0.8002 - val_AUC: 0.5653 - val_accuracy: 0.5000 - val_loss: 0.6773 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7254 - accuracy: 0.6405 - loss: 0.6830 - val_AUC: 0.5909 - val_accuracy: 0.5135 - val_loss: 0.6860 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.6633 - accuracy: 0.6254 - loss: 0.6842 - val_AUC: 0.6108 - val_accuracy: 0.5270 - val_loss: 0.6810 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.7508 - accuracy: 0.6397 - loss: 0.6588 - val_AUC: 0.6174 - val_accuracy: 0.5135 - val_loss: 0.6878 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7012 - accuracy: 0.6139 - loss: 0.6385 - val_AUC: 0.6070 - val_accuracy: 0.4865 - val_loss: 0.6951 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7416 - accuracy: 0.6455 - loss: 0.6272 - val_AUC: 0.6136 - val_accuracy: 0.5000 - val_loss: 0.6790 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7640 - accuracy: 0.6430 - loss: 0.5629 - val_AUC: 0.6165 - val_accuracy: 0.5135 - val_loss: 0.6674 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m15/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.7686 - accuracy: 0.6241 - loss: 0.5292 \n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7584 - accuracy: 0.6271 - loss: 0.5498 - val_AUC: 0.6278 - val_accuracy: 0.5405 - val_loss: 0.6600 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7988 - accuracy: 0.7044 - loss: 0.5605 - val_AUC: 0.6269 - val_accuracy: 0.5405 - val_loss: 0.6658 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8499 - accuracy: 0.6780 - loss: 0.4971 - val_AUC: 0.6241 - val_accuracy: 0.5405 - val_loss: 0.6640 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7578 - accuracy: 0.6751 - loss: 0.6798 - val_AUC: 0.6193 - val_accuracy: 0.5541 - val_loss: 0.6663 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7450 - accuracy: 0.6345 - loss: 0.7081 - val_AUC: 0.6136 - val_accuracy: 0.5676 - val_loss: 0.6659 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7911 - accuracy: 0.6684 - loss: 0.5697 - val_AUC: 0.6117 - val_accuracy: 0.5541 - val_loss: 0.6654 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7507 - accuracy: 0.6644 - loss: 0.6103 - val_AUC: 0.6184 - val_accuracy: 0.5405 - val_loss: 0.6710 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.7000 - accuracy: 0.6366 - loss: 0.6808 - val_AUC: 0.6184 - val_accuracy: 0.5270 - val_loss: 0.6953 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.8227 - accuracy: 0.7381 - loss: 0.5330 - val_AUC: 0.6184 - val_accuracy: 0.5270 - val_loss: 0.7006 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.7858 - accuracy: 0.6427 - loss: 0.5956 - val_AUC: 0.6174 - val_accuracy: 0.5405 - val_loss: 0.7127 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.7115 - accuracy: 0.6075 - loss: 0.5880\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.7133 - accuracy: 0.6092 - loss: 0.5892 - val_AUC: 0.6212 - val_accuracy: 0.5405 - val_loss: 0.7205 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.7905 - accuracy: 0.6522 - loss: 0.5442 - val_AUC: 0.6174 - val_accuracy: 0.5405 - val_loss: 0.7253 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.7745 - accuracy: 0.6869 - loss: 0.5913 - val_AUC: 0.6155 - val_accuracy: 0.5405 - val_loss: 0.7266 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.7865 - accuracy: 0.6646 - loss: 0.5853 - val_AUC: 0.6165 - val_accuracy: 0.5270 - val_loss: 0.7264 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.7924 - accuracy: 0.6961 - loss: 0.5762 - val_AUC: 0.6155 - val_accuracy: 0.5270 - val_loss: 0.7201 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.7558 - accuracy: 0.6305 - loss: 0.5592 - val_AUC: 0.6184 - val_accuracy: 0.5270 - val_loss: 0.7234 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8016 - accuracy: 0.6742 - loss: 0.5534 - val_AUC: 0.6184 - val_accuracy: 0.5270 - val_loss: 0.7225 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8087 - accuracy: 0.6674 - loss: 0.5172 - val_AUC: 0.6184 - val_accuracy: 0.5270 - val_loss: 0.7201 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8101 - accuracy: 0.6862 - loss: 0.5449 - val_AUC: 0.6146 - val_accuracy: 0.5270 - val_loss: 0.7265 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8208 - accuracy: 0.7030 - loss: 0.5303 - val_AUC: 0.6174 - val_accuracy: 0.5270 - val_loss: 0.7238 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m16/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7942 - accuracy: 0.6447 - loss: 0.5192 \n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7921 - accuracy: 0.6477 - loss: 0.5279 - val_AUC: 0.6203 - val_accuracy: 0.5270 - val_loss: 0.7253 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8259 - accuracy: 0.6870 - loss: 0.4949 - val_AUC: 0.6231 - val_accuracy: 0.5135 - val_loss: 0.7354 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8155 - accuracy: 0.7191 - loss: 0.5023 - val_AUC: 0.6259 - val_accuracy: 0.5135 - val_loss: 0.7390 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8114 - accuracy: 0.6678 - loss: 0.5592 - val_AUC: 0.6231 - val_accuracy: 0.5135 - val_loss: 0.7473 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7525 - accuracy: 0.6795 - loss: 0.6232 - val_AUC: 0.6250 - val_accuracy: 0.5135 - val_loss: 0.7540 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7748 - accuracy: 0.6599 - loss: 0.5663 - val_AUC: 0.6278 - val_accuracy: 0.5135 - val_loss: 0.7571 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7452 - accuracy: 0.6917 - loss: 0.6444 - val_AUC: 0.6269 - val_accuracy: 0.5135 - val_loss: 0.7643 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8628 - accuracy: 0.7144 - loss: 0.5085 - val_AUC: 0.6259 - val_accuracy: 0.5135 - val_loss: 0.7671 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7989 - accuracy: 0.6923 - loss: 0.5392 - val_AUC: 0.6250 - val_accuracy: 0.5135 - val_loss: 0.7675 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8208 - accuracy: 0.6923 - loss: 0.5055 - val_AUC: 0.6259 - val_accuracy: 0.5135 - val_loss: 0.7699 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m16/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.8483 - accuracy: 0.7308 - loss: 0.5243 \n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8478 - accuracy: 0.7321 - loss: 0.5181 - val_AUC: 0.6288 - val_accuracy: 0.5135 - val_loss: 0.7651 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7774 - accuracy: 0.7060 - loss: 0.5344 - val_AUC: 0.6250 - val_accuracy: 0.5135 - val_loss: 0.7641 - learning_rate: 6.2500e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8249 - accuracy: 0.6911 - loss: 0.4920 - val_AUC: 0.6250 - val_accuracy: 0.5135 - val_loss: 0.7665 - learning_rate: 6.2500e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8188 - accuracy: 0.7545 - loss: 0.5522 - val_AUC: 0.6250 - val_accuracy: 0.5135 - val_loss: 0.7639 - learning_rate: 6.2500e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7193 - accuracy: 0.6541 - loss: 0.5942 - val_AUC: 0.6222 - val_accuracy: 0.5135 - val_loss: 0.7666 - learning_rate: 6.2500e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7995 - accuracy: 0.6876 - loss: 0.5704 - val_AUC: 0.6222 - val_accuracy: 0.5135 - val_loss: 0.7633 - learning_rate: 6.2500e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8361 - accuracy: 0.7446 - loss: 0.5102 - val_AUC: 0.6259 - val_accuracy: 0.5135 - val_loss: 0.7633 - learning_rate: 6.2500e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7582 - accuracy: 0.6733 - loss: 0.4882 - val_AUC: 0.6212 - val_accuracy: 0.5135 - val_loss: 0.7626 - learning_rate: 6.2500e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8115 - accuracy: 0.6723 - loss: 0.4794 - val_AUC: 0.6259 - val_accuracy: 0.5135 - val_loss: 0.7650 - learning_rate: 6.2500e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8251 - accuracy: 0.6813 - loss: 0.4924 - val_AUC: 0.6193 - val_accuracy: 0.5135 - val_loss: 0.7614 - learning_rate: 6.2500e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m15/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.8993 - accuracy: 0.7511 - loss: 0.4177 \n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8895 - accuracy: 0.7419 - loss: 0.4302 - val_AUC: 0.6193 - val_accuracy: 0.5135 - val_loss: 0.7651 - learning_rate: 6.2500e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8389 - accuracy: 0.7562 - loss: 0.5273 - val_AUC: 0.6184 - val_accuracy: 0.5135 - val_loss: 0.7652 - learning_rate: 3.1250e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8224 - accuracy: 0.7273 - loss: 0.5576 - val_AUC: 0.6184 - val_accuracy: 0.5135 - val_loss: 0.7671 - learning_rate: 3.1250e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8183 - accuracy: 0.6599 - loss: 0.5307 - val_AUC: 0.6212 - val_accuracy: 0.5135 - val_loss: 0.7685 - learning_rate: 3.1250e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8546 - accuracy: 0.6875 - loss: 0.4837 - val_AUC: 0.6222 - val_accuracy: 0.5135 - val_loss: 0.7679 - learning_rate: 3.1250e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7894 - accuracy: 0.6779 - loss: 0.5751 - val_AUC: 0.6231 - val_accuracy: 0.5135 - val_loss: 0.7716 - learning_rate: 3.1250e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8202 - accuracy: 0.6912 - loss: 0.5254 - val_AUC: 0.6297 - val_accuracy: 0.5135 - val_loss: 0.7770 - learning_rate: 3.1250e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8024 - accuracy: 0.6994 - loss: 0.5925 - val_AUC: 0.6278 - val_accuracy: 0.5135 - val_loss: 0.7749 - learning_rate: 3.1250e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8809 - accuracy: 0.7682 - loss: 0.4651 - val_AUC: 0.6278 - val_accuracy: 0.5135 - val_loss: 0.7697 - learning_rate: 3.1250e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8360 - accuracy: 0.7004 - loss: 0.4870 - val_AUC: 0.6278 - val_accuracy: 0.5135 - val_loss: 0.7695 - learning_rate: 3.1250e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m16/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8476 - accuracy: 0.7308 - loss: 0.4944 \n",
            "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8454 - accuracy: 0.7260 - loss: 0.4958 - val_AUC: 0.6269 - val_accuracy: 0.5135 - val_loss: 0.7723 - learning_rate: 3.1250e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8181 - accuracy: 0.6835 - loss: 0.5252 - val_AUC: 0.6269 - val_accuracy: 0.5135 - val_loss: 0.7727 - learning_rate: 1.5625e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8170 - accuracy: 0.7340 - loss: 0.5968 - val_AUC: 0.6250 - val_accuracy: 0.5135 - val_loss: 0.7755 - learning_rate: 1.5625e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7765 - accuracy: 0.6828 - loss: 0.5858 - val_AUC: 0.6241 - val_accuracy: 0.5135 - val_loss: 0.7730 - learning_rate: 1.5625e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8473 - accuracy: 0.7433 - loss: 0.5037 - val_AUC: 0.6241 - val_accuracy: 0.5135 - val_loss: 0.7701 - learning_rate: 1.5625e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7648 - accuracy: 0.6780 - loss: 0.5559 - val_AUC: 0.6250 - val_accuracy: 0.5135 - val_loss: 0.7688 - learning_rate: 1.5625e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8468 - accuracy: 0.6923 - loss: 0.4907 - val_AUC: 0.6241 - val_accuracy: 0.5135 - val_loss: 0.7719 - learning_rate: 1.5625e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8297 - accuracy: 0.7318 - loss: 0.5437 - val_AUC: 0.6250 - val_accuracy: 0.5135 - val_loss: 0.7690 - learning_rate: 1.5625e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8247 - accuracy: 0.7311 - loss: 0.4585 - val_AUC: 0.6241 - val_accuracy: 0.5135 - val_loss: 0.7697 - learning_rate: 1.5625e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8251 - accuracy: 0.6725 - loss: 0.5360 - val_AUC: 0.6259 - val_accuracy: 0.5135 - val_loss: 0.7751 - learning_rate: 1.5625e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m15/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.8328 - accuracy: 0.7064 - loss: 0.4958 \n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8285 - accuracy: 0.7048 - loss: 0.5022 - val_AUC: 0.6259 - val_accuracy: 0.5135 - val_loss: 0.7757 - learning_rate: 1.5625e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7720 - accuracy: 0.6562 - loss: 0.5751 - val_AUC: 0.6241 - val_accuracy: 0.5135 - val_loss: 0.7723 - learning_rate: 7.8125e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8196 - accuracy: 0.6727 - loss: 0.5252 - val_AUC: 0.6288 - val_accuracy: 0.5135 - val_loss: 0.7760 - learning_rate: 7.8125e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7889 - accuracy: 0.6874 - loss: 0.5354 - val_AUC: 0.6259 - val_accuracy: 0.5135 - val_loss: 0.7772 - learning_rate: 7.8125e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7923 - accuracy: 0.6550 - loss: 0.5294 - val_AUC: 0.6269 - val_accuracy: 0.5135 - val_loss: 0.7768 - learning_rate: 7.8125e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8137 - accuracy: 0.7020 - loss: 0.5139 - val_AUC: 0.6278 - val_accuracy: 0.5135 - val_loss: 0.7757 - learning_rate: 7.8125e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8315 - accuracy: 0.7149 - loss: 0.5123 - val_AUC: 0.6259 - val_accuracy: 0.5135 - val_loss: 0.7768 - learning_rate: 7.8125e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8408 - accuracy: 0.7161 - loss: 0.4889 - val_AUC: 0.6259 - val_accuracy: 0.5135 - val_loss: 0.7769 - learning_rate: 7.8125e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7923 - accuracy: 0.7210 - loss: 0.5643 - val_AUC: 0.6288 - val_accuracy: 0.5135 - val_loss: 0.7738 - learning_rate: 7.8125e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7839 - accuracy: 0.7325 - loss: 0.6178 - val_AUC: 0.6316 - val_accuracy: 0.5135 - val_loss: 0.7753 - learning_rate: 7.8125e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m15/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.7561 - accuracy: 0.6505 - loss: 0.5145     \n",
            "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.7544 - accuracy: 0.6456 - loss: 0.5370 - val_AUC: 0.6307 - val_accuracy: 0.5135 - val_loss: 0.7728 - learning_rate: 7.8125e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.7410 - accuracy: 0.6473 - loss: 0.5549 - val_AUC: 0.6288 - val_accuracy: 0.5135 - val_loss: 0.7755 - learning_rate: 3.9063e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.8455 - accuracy: 0.7074 - loss: 0.4951 - val_AUC: 0.6297 - val_accuracy: 0.5135 - val_loss: 0.7720 - learning_rate: 3.9063e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.8634 - accuracy: 0.7100 - loss: 0.4564 - val_AUC: 0.6307 - val_accuracy: 0.5135 - val_loss: 0.7703 - learning_rate: 3.9063e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - AUC: 0.7884 - accuracy: 0.7279 - loss: 0.6519 - val_AUC: 0.6269 - val_accuracy: 0.5135 - val_loss: 0.7677 - learning_rate: 3.9063e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.7799 - accuracy: 0.6895 - loss: 0.5938 - val_AUC: 0.6297 - val_accuracy: 0.5135 - val_loss: 0.7729 - learning_rate: 3.9063e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.7548 - accuracy: 0.6461 - loss: 0.5803 - val_AUC: 0.6297 - val_accuracy: 0.5135 - val_loss: 0.7704 - learning_rate: 3.9063e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - AUC: 0.8417 - accuracy: 0.7188 - loss: 0.4953 - val_AUC: 0.6288 - val_accuracy: 0.5135 - val_loss: 0.7664 - learning_rate: 3.9063e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.7619 - accuracy: 0.6478 - loss: 0.5923 - val_AUC: 0.6297 - val_accuracy: 0.5135 - val_loss: 0.7694 - learning_rate: 3.9063e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7933 - accuracy: 0.7201 - loss: 0.5328 - val_AUC: 0.6297 - val_accuracy: 0.5135 - val_loss: 0.7705 - learning_rate: 3.9063e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m14/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.8166 - accuracy: 0.6760 - loss: 0.4526     \n",
            "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8210 - accuracy: 0.6838 - loss: 0.4727 - val_AUC: 0.6297 - val_accuracy: 0.5135 - val_loss: 0.7757 - learning_rate: 3.9063e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8477 - accuracy: 0.7150 - loss: 0.5101 - val_AUC: 0.6307 - val_accuracy: 0.5135 - val_loss: 0.7745 - learning_rate: 1.9531e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8141 - accuracy: 0.6929 - loss: 0.5516 - val_AUC: 0.6307 - val_accuracy: 0.5135 - val_loss: 0.7758 - learning_rate: 1.9531e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8042 - accuracy: 0.7164 - loss: 0.5490 - val_AUC: 0.6288 - val_accuracy: 0.5135 - val_loss: 0.7779 - learning_rate: 1.9531e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8975 - accuracy: 0.7355 - loss: 0.4130 - val_AUC: 0.6288 - val_accuracy: 0.5135 - val_loss: 0.7793 - learning_rate: 1.9531e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.8277 - accuracy: 0.6686 - loss: 0.5357 - val_AUC: 0.6288 - val_accuracy: 0.5135 - val_loss: 0.7780 - learning_rate: 1.9531e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.7714 - accuracy: 0.6573 - loss: 0.5518 - val_AUC: 0.6278 - val_accuracy: 0.5135 - val_loss: 0.7761 - learning_rate: 1.9531e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - AUC: 0.7722 - accuracy: 0.6797 - loss: 0.5424 - val_AUC: 0.6288 - val_accuracy: 0.5135 - val_loss: 0.7771 - learning_rate: 1.9531e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8509 - accuracy: 0.6912 - loss: 0.4899 - val_AUC: 0.6288 - val_accuracy: 0.5135 - val_loss: 0.7779 - learning_rate: 1.9531e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8363 - accuracy: 0.7058 - loss: 0.5294 - val_AUC: 0.6288 - val_accuracy: 0.5135 - val_loss: 0.7764 - learning_rate: 1.9531e-06\n",
            "Training completed successfully!\n",
            "\n",
            "Step 6: Evaluating LSTM model...\n",
            "============================================================\n",
            "ROBUST LSTM MODEL PERFORMANCE\n",
            "============================================================\n",
            "Accuracy:    0.601\n",
            "Sensitivity: 0.652\n",
            "Specificity: 0.593\n",
            "Precision:   0.214\n",
            "AUC:         0.693\n",
            "\n",
            "Confusion Matrix:\n",
            "[[80 55]\n",
            " [ 8 15]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.91      0.59      0.72       135\n",
            "     Class 1       0.21      0.65      0.32        23\n",
            "\n",
            "    accuracy                           0.60       158\n",
            "   macro avg       0.56      0.62      0.52       158\n",
            "weighted avg       0.81      0.60      0.66       158\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 7: Data quality summary...\n",
            "Data Quality Report:\n",
            "Total sequences: 525\n",
            "Feature count: 14\n",
            "Class balance: [449  76]\n",
            "Sequence length: 3\n",
            "Data statistics:\n",
            "  Min: 0.000\n",
            "  Max: 750.000\n",
            "  Mean: 24.249\n",
            "  Std: 74.058\n",
            "  NaN values: 0\n",
            "  Inf values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Step 0: Setting up environment...\")\n",
        "\n",
        "def create_3d_array(matrix_list):\n",
        "    if len(matrix_list) == 0:\n",
        "        raise ValueError(\"No matrices provided\")\n",
        "\n",
        "    n_samples = len(matrix_list)\n",
        "    n_timesteps = matrix_list[0].shape[0]\n",
        "    n_features = matrix_list[0].shape[1]\n",
        "\n",
        "    array_3d = np.zeros((n_samples, n_timesteps, n_features))\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        array_3d[i, :, :] = matrix_list[i]\n",
        "\n",
        "    return array_3d\n",
        "\n",
        "print(\"Environment setup complete!\")\n",
        "\n",
        "# Load the data\n",
        "print(\"Loading pcdata.csv...\")\n",
        "try:\n",
        "    sequential_data = pd.read_csv('pcdata.csv')\n",
        "    print(f\"Data loaded successfully! Shape: {sequential_data.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: pcdata.csv file not found.\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nStep 1: Enhanced LSTM data preparation...\")\n",
        "\n",
        "def prepare_lstm_enhanced(data, sequence_length=3):\n",
        "    # Enhanced feature selection with clinical relevance\n",
        "    clinical_features = [\n",
        "        # Baseline characteristics\n",
        "        'AGE', 'ECOGGRN',\n",
        "        # Treatment\n",
        "        'EXDOSENN',\n",
        "        # Disease response\n",
        "        'TARGETQN', 'NONTARQN',\n",
        "        # Adverse events (most predictive)\n",
        "        'total_ae_events', 'serious_ae_count', 'grade3_plus_count',\n",
        "        'grade3_count', 'grade4_count', 'grade5_count',\n",
        "        # Treatment modifications\n",
        "        'drug_withdrawn', 'concomitant_treatment_given',\n",
        "        # Time progression\n",
        "        'VISDAY'\n",
        "    ]\n",
        "\n",
        "    # Check which features exist\n",
        "    available_features = [col for col in clinical_features if col in data.columns]\n",
        "    print(f\"Selected {len(available_features)} clinical features\")\n",
        "    print(f\"Features: {available_features}\")\n",
        "\n",
        "    # Prepare data\n",
        "    data_prep = data.copy()\n",
        "\n",
        "    # Create outcome variable\n",
        "    if 'CANCDEAD' in data_prep.columns:\n",
        "        data_prep['outcome'] = data_prep['CANCDEAD'].astype(int)\n",
        "        if data_prep['outcome'].min() < 0:\n",
        "            data_prep['outcome'] = (data_prep['outcome'] > 0).astype(int)\n",
        "        print(f\"Outcome distribution: {data_prep['outcome'].value_counts().to_dict()}\")\n",
        "    else:\n",
        "        print(\"WARNING: CANCDEAD column not found.\")\n",
        "        return None\n",
        "\n",
        "    # Filter patients with sufficient visits\n",
        "    visit_counts = data_prep.groupby('RPT').size()\n",
        "    valid_patients = visit_counts[visit_counts >= sequence_length].index\n",
        "    data_prep = data_prep[data_prep['RPT'].isin(valid_patients)]\n",
        "\n",
        "    print(f\"Patients with sufficient visits: {len(valid_patients)}\")\n",
        "\n",
        "    # Handle missing values and convert to numeric\n",
        "    for col in available_features:\n",
        "        data_prep[col] = pd.to_numeric(data_prep[col], errors='coerce')\n",
        "        median_val = data_prep[col].median()\n",
        "        data_prep[col] = data_prep[col].fillna(median_val)\n",
        "        print(f\"  {col}: median={median_val:.3f}\")\n",
        "\n",
        "    # Remove near-constant features\n",
        "    constant_features = []\n",
        "    for col in available_features:\n",
        "        if data_prep[col].nunique() <= 1:\n",
        "            constant_features.append(col)\n",
        "\n",
        "    if constant_features:\n",
        "        print(f\"Removing constant features: {constant_features}\")\n",
        "        available_features = [f for f in available_features if f not in constant_features]\n",
        "\n",
        "    patients = data_prep['RPT'].unique()\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    print(f\"Processing {len(patients)} patients...\")\n",
        "\n",
        "    for i, patient in enumerate(patients):\n",
        "        patient_data = data_prep[data_prep['RPT'] == patient].sort_values('VISDAY')\n",
        "\n",
        "        if len(patient_data) >= sequence_length:\n",
        "            patient_outcome = patient_data['outcome'].iloc[0]\n",
        "            feature_matrix = patient_data[available_features].values\n",
        "\n",
        "            # Use the last 'sequence_length' time points\n",
        "            sequence_data = feature_matrix[-sequence_length:, :]\n",
        "\n",
        "            sequences.append(sequence_data)\n",
        "            labels.append(patient_outcome)\n",
        "\n",
        "        if (i + 1) % 50 == 0:\n",
        "            print(f\"Processed {i + 1} patients...\")\n",
        "\n",
        "    print(f\"Created {len(sequences)} sequences\")\n",
        "\n",
        "    if len(sequences) == 0:\n",
        "        raise ValueError(\"No sequences created\")\n",
        "\n",
        "    # Create 3D array\n",
        "    sequences_array = create_3d_array(sequences)\n",
        "\n",
        "    return {\n",
        "        'sequences': sequences_array,\n",
        "        'labels': np.array(labels),\n",
        "        'feature_names': available_features\n",
        "    }\n",
        "\n",
        "# Prepare the data\n",
        "try:\n",
        "    lstm_data = prepare_lstm_enhanced(sequential_data, sequence_length=3)\n",
        "    if lstm_data is None:\n",
        "        raise ValueError(\"Data preparation failed\")\n",
        "\n",
        "    print(\"SUCCESS: LSTM data prepared!\")\n",
        "    print(f\"Sequences dimension: {lstm_data['sequences'].shape}\")\n",
        "    print(f\"Labels: {len(lstm_data['labels'])}\")\n",
        "    print(f\"Class distribution - 0: {sum(lstm_data['labels'] == 0)} 1: {sum(lstm_data['labels'] == 1)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR in data preparation: {e}\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nStep 2: Advanced normalization...\")\n",
        "\n",
        "def advanced_normalize_3d(array_3d, feature_names):\n",
        "    dims = array_3d.shape\n",
        "    print(f\"Normalizing array with dimensions: {dims}\")\n",
        "\n",
        "    n_samples, n_timesteps, n_features = dims\n",
        "    X_reshaped = array_3d.reshape(n_samples * n_timesteps, n_features)\n",
        "\n",
        "    # Clean any remaining issues\n",
        "    X_reshaped = np.nan_to_num(X_reshaped, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    # Use different scalers for different feature types\n",
        "    X_normalized = np.zeros_like(X_reshaped)\n",
        "\n",
        "    for i, feature_name in enumerate(feature_names):\n",
        "        feature_data = X_reshaped[:, i]\n",
        "\n",
        "        # Use RobustScaler for count data, StandardScaler for continuous\n",
        "        if any(keyword in feature_name.lower() for keyword in ['count', 'events', 'grade']):\n",
        "            # Count data - use RobustScaler\n",
        "            scaler = RobustScaler()\n",
        "            X_normalized[:, i] = scaler.fit_transform(feature_data.reshape(-1, 1)).flatten()\n",
        "        else:\n",
        "            # Continuous data - use StandardScaler\n",
        "            scaler = StandardScaler()\n",
        "            X_normalized[:, i] = scaler.fit_transform(feature_data.reshape(-1, 1)).flatten()\n",
        "\n",
        "    # Reshape back to 3D\n",
        "    array_3d_normalized = X_normalized.reshape(n_samples, n_timesteps, n_features)\n",
        "\n",
        "    print(f\"Advanced normalization completed! Data range: [{array_3d_normalized.min():.3f}, {array_3d_normalized.max():.3f}]\")\n",
        "\n",
        "    return array_3d_normalized\n",
        "\n",
        "if 'lstm_data' in locals():\n",
        "    X_sequences = advanced_normalize_3d(lstm_data['sequences'].copy(),\n",
        "                                      lstm_data.get('feature_names'))\n",
        "    y = lstm_data['labels']\n",
        "\n",
        "    print(f\"Final label distribution: 0: {sum(y == 0)}, 1: {sum(y == 1)}\")\n",
        "    print(f\"Class imbalance ratio: {sum(y == 0) / sum(y == 1):.2f}:1\")\n",
        "else:\n",
        "    print(\"Cannot normalize - lstm_data not created\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nStep 3: Strategic train-test split...\")\n",
        "\n",
        "if 'X_sequences' in locals() and 'y' in locals():\n",
        "    # Use stratification with random state for reproducibility\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_sequences, y,\n",
        "        test_size=0.25,  # Slightly more training data\n",
        "        random_state=42,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    # Further split training for validation\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train, y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=y_train\n",
        "    )\n",
        "\n",
        "    print(\"Data splits:\")\n",
        "    print(f\"Training:   {X_train.shape} (0: {sum(y_train == 0)} 1: {sum(y_train == 1)})\")\n",
        "    print(f\"Validation: {X_val.shape} (0: {sum(y_val == 0)} 1: {sum(y_val == 1)})\")\n",
        "    print(f\"Test:       {X_test.shape} (0: {sum(y_test == 0)} 1: {sum(y_test == 1)})\")\n",
        "\n",
        "else:\n",
        "    print(\"Cannot create split - data not available\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nStep 4: Building advanced LSTM model...\")\n",
        "\n",
        "def build_advanced_lstm_model(sequence_length, n_features):\n",
        "    \"\"\"\n",
        "    Build an advanced LSTM model with CNN preprocessing and attention mechanisms\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        # CNN for feature extraction\n",
        "        Conv1D(filters=32, kernel_size=2, activation='relu',\n",
        "               input_shape=(sequence_length, n_features),\n",
        "               padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=1),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        # Bidirectional LSTM for temporal patterns\n",
        "        LSTM(64,\n",
        "             return_sequences=True,\n",
        "             kernel_initializer='glorot_uniform',\n",
        "             recurrent_initializer='orthogonal',\n",
        "             dropout=0.2,\n",
        "             recurrent_dropout=0.2),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        # Second LSTM layer\n",
        "        LSTM(32,\n",
        "             return_sequences=False,\n",
        "             kernel_initializer='glorot_uniform',\n",
        "             recurrent_initializer='orthogonal',\n",
        "             dropout=0.2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # Dense layers with regularization\n",
        "        Dense(32, activation='relu',\n",
        "              kernel_initializer='he_normal',\n",
        "              kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(16, activation='relu',\n",
        "              kernel_initializer='he_normal'),\n",
        "        Dropout(0.1),\n",
        "\n",
        "        # Output layer\n",
        "        Dense(1, activation='sigmoid',\n",
        "              kernel_initializer='glorot_uniform')\n",
        "    ])\n",
        "\n",
        "    # Optimizer with customized settings\n",
        "    optimizer = Nadam(\n",
        "        learning_rate=0.001,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        clipnorm=1.0\n",
        "    )\n",
        "\n",
        "    # Custom metrics for imbalanced data\n",
        "    metrics = [\n",
        "        'accuracy',\n",
        "        'AUC',\n",
        "        Precision(name='precision'),\n",
        "        Recall(name='recall')\n",
        "    ]\n",
        "\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=optimizer,\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "if 'X_train' in locals() and 'y_train' in locals():\n",
        "    # Get model dimensions\n",
        "    sequence_length = X_train.shape[1]\n",
        "    n_features = X_train.shape[2]\n",
        "\n",
        "    print(\"Building advanced model for:\")\n",
        "    print(f\"  Sequence length: {sequence_length}\")\n",
        "    print(f\"  Features: {n_features}\")\n",
        "    print(f\"  Training samples: {X_train.shape[0]}\")\n",
        "\n",
        "    # Enhanced class weighting\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(y_train),\n",
        "        y=y_train\n",
        "    )\n",
        "    class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "    print(f\"Enhanced class weights: {class_weight_dict}\")\n",
        "\n",
        "    # Build model\n",
        "    lstm_model = build_advanced_lstm_model(sequence_length, n_features)\n",
        "\n",
        "    print(\"Advanced model architecture:\")\n",
        "    lstm_model.summary()\n",
        "\n",
        "    print(\"\\nStep 5: Enhanced training with validation...\")\n",
        "\n",
        "    # Improved callbacks\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_auc',\n",
        "        patience=25,\n",
        "        restore_best_weights=True,\n",
        "        mode='max',\n",
        "        verbose=1,\n",
        "        min_delta=0.005\n",
        "    )\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=10,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1,\n",
        "        min_delta=0.001\n",
        "    )\n",
        "\n",
        "    model_checkpoint = ModelCheckpoint(\n",
        "        'best_lstm_model.h5',\n",
        "        monitor='val_auc',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"Starting enhanced training...\")\n",
        "\n",
        "    # Training with validation data\n",
        "    history = lstm_model.fit(\n",
        "        x=X_train,\n",
        "        y=y_train,\n",
        "        epochs=150,\n",
        "        batch_size=16,\n",
        "        validation_data=(X_val, y_val),\n",
        "        class_weight=class_weight_dict,\n",
        "        verbose=1,\n",
        "        callbacks=[early_stopping, reduce_lr, model_checkpoint],\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    print(\"Enhanced training completed successfully!\")\n",
        "\n",
        "    # Load best model\n",
        "    lstm_model.load_weights('best_lstm_model.h5')\n",
        "    print(\"Loaded best model weights from training\")\n",
        "\n",
        "else:\n",
        "    print(\"Cannot build model - training data not available\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nStep 6: Comprehensive model evaluation...\")\n",
        "\n",
        "if 'lstm_model' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
        "    try:\n",
        "        # Make predictions\n",
        "        predictions = lstm_model.predict(X_test, verbose=0)\n",
        "        predicted_probs = predictions.flatten()\n",
        "\n",
        "        # Find optimal threshold using validation set\n",
        "        val_predictions = lstm_model.predict(X_val, verbose=0).flatten()\n",
        "        val_precisions, val_recalls, val_thresholds = precision_recall_curve(y_val, val_predictions)\n",
        "        val_f1_scores = 2 * (val_precisions[:-1] * val_recalls[:-1]) / (val_precisions[:-1] + val_recalls[:-1] + 1e-8)\n",
        "        optimal_idx = np.argmax(val_f1_scores)\n",
        "        optimal_threshold = val_thresholds[optimal_idx]\n",
        "\n",
        "        print(f\"Optimal threshold from validation: {optimal_threshold:.3f}\")\n",
        "\n",
        "        # Use optimal threshold for test set\n",
        "        predicted_classes = (predicted_probs > optimal_threshold).astype(int)\n",
        "\n",
        "        # Comprehensive metrics\n",
        "        conf_matrix = confusion_matrix(y_test, predicted_classes)\n",
        "        accuracy = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
        "\n",
        "        tn, fp, fn, tp = conf_matrix.ravel()\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        f1_score = 2 * (precision * sensitivity) / (precision + sensitivity + 1e-8)\n",
        "\n",
        "        # AUC and PR AUC\n",
        "        auc_val = roc_auc_score(y_test, predicted_probs)\n",
        "        precision_curve, recall_curve, _ = precision_recall_curve(y_test, predicted_probs)\n",
        "        pr_auc = np.trapz(recall_curve, precision_curve)\n",
        "\n",
        "        # Print comprehensive results\n",
        "        print(\"=\" * 70)\n",
        "        print(\"ADVANCED LSTM MODEL PERFORMANCE\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Accuracy:          {accuracy:.3f}\")\n",
        "        print(f\"Sensitivity:       {sensitivity:.3f}\")\n",
        "        print(f\"Specificity:       {specificity:.3f}\")\n",
        "        print(f\"Precision:         {precision:.3f}\")\n",
        "        print(f\"F1-Score:          {f1_score:.3f}\")\n",
        "        print(f\"AUC-ROC:           {auc_val:.3f}\")\n",
        "        print(f\"AUC-PR:            {pr_auc:.3f}\")\n",
        "        print(f\"Optimal Threshold: {optimal_threshold:.3f}\")\n",
        "        print(f\"\\nConfusion Matrix:\")\n",
        "        print(conf_matrix)\n",
        "        print(f\"\\nDetailed Classification Report:\")\n",
        "        print(classification_report(y_test, predicted_classes,\n",
        "                                  target_names=['Class 0 (Alive)', 'Class 1 (Deceased)']))\n",
        "\n",
        "        # Enhanced visualization\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "        # ROC Curve\n",
        "        fpr, tpr, _ = roc_curve(y_test, predicted_probs)\n",
        "        axes[0, 0].plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {auc_val:.3f}')\n",
        "        axes[0, 0].plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
        "        axes[0, 0].set_xlabel('False Positive Rate')\n",
        "        axes[0, 0].set_ylabel('True Positive Rate')\n",
        "        axes[0, 0].set_title('ROC Curve')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True)\n",
        "\n",
        "        # Precision-Recall Curve\n",
        "        axes[0, 1].plot(recall_curve, precision_curve, 'r-', linewidth=2, label=f'PR AUC = {pr_auc:.3f}')\n",
        "        axes[0, 1].set_xlabel('Recall')\n",
        "        axes[0, 1].set_ylabel('Precision')\n",
        "        axes[0, 1].set_title('Precision-Recall Curve')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True)\n",
        "\n",
        "        # Training history - Loss\n",
        "        axes[0, 2].plot(history.history['loss'], 'b-', label='Train Loss')\n",
        "        axes[0, 2].plot(history.history['val_loss'], 'r-', label='Val Loss')\n",
        "        axes[0, 2].set_xlabel('Epoch')\n",
        "        axes[0, 2].set_ylabel('Loss')\n",
        "        axes[0, 2].set_title('Training History - Loss')\n",
        "        axes[0, 2].legend()\n",
        "        axes[0, 2].grid(True)\n",
        "\n",
        "        # Training history - AUC\n",
        "        axes[1, 0].plot(history.history['auc'], 'b-', label='Train AUC')\n",
        "        axes[1, 0].plot(history.history['val_auc'], 'r-', label='Val AUC')\n",
        "        axes[1, 0].set_xlabel('Epoch')\n",
        "        axes[1, 0].set_ylabel('AUC')\n",
        "        axes[1, 0].set_title('Training History - AUC')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True)\n",
        "\n",
        "        # Probability distribution\n",
        "        axes[1, 1].hist([predicted_probs[y_test == 0], predicted_probs[y_test == 1]],\n",
        "                       bins=20, alpha=0.7, label=['Class 0', 'Class 1'],\n",
        "                       color=['blue', 'red'])\n",
        "        axes[1, 1].axvline(optimal_threshold, color='black', linestyle='--',\n",
        "                          label=f'Threshold = {optimal_threshold:.2f}')\n",
        "        axes[1, 1].set_xlabel('Predicted Probability')\n",
        "        axes[1, 1].set_ylabel('Count')\n",
        "        axes[1, 1].set_title('Prediction Distribution')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True)\n",
        "\n",
        "        # Confusion Matrix Heatmap\n",
        "        im = axes[1, 2].imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
        "        axes[1, 2].set_xticks([0, 1])\n",
        "        axes[1, 2].set_yticks([0, 1])\n",
        "        axes[1, 2].set_xticklabels(['Pred 0', 'Pred 1'])\n",
        "        axes[1, 2].set_yticklabels(['True 0', 'True 1'])\n",
        "        axes[1, 2].set_title('Confusion Matrix')\n",
        "\n",
        "        # Add text annotations\n",
        "        for i in range(2):\n",
        "            for j in range(2):\n",
        "                axes[1, 2].text(j, i, f'{conf_matrix[i, j]}',\n",
        "                               ha='center', va='center',\n",
        "                               color='white' if conf_matrix[i, j] > conf_matrix.max()/2 else 'black')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Feature importance analysis\n",
        "        print(\"\\nStep 7: Feature Importance Analysis...\")\n",
        "        analyze_feature_importance(lstm_model, X_train, lstm_data['feature_names'])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in evaluation: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"Cannot evaluate - model or test data not available\")\n",
        "\n",
        "def analyze_feature_importance(model, X_data, feature_names):\n",
        "    \"\"\"Analyze feature importance using permutation importance\"\"\"\n",
        "    print(\"Feature Importance Analysis:\")\n",
        "\n",
        "    # Get baseline performance\n",
        "    baseline_predictions = model.predict(X_data, verbose=0)\n",
        "    baseline_probs = baseline_predictions.flatten()\n",
        "    baseline_auc = roc_auc_score(y_train, baseline_probs) if len(np.unique(y_train)) > 1 else 0.5\n",
        "\n",
        "    importance_scores = []\n",
        "\n",
        "    # Permutation importance for each feature\n",
        "    for feature_idx in range(X_data.shape[2]):\n",
        "        X_permuted = X_data.copy()\n",
        "\n",
        "        # Permute the feature across all samples and timesteps\n",
        "        original_feature = X_permuted[:, :, feature_idx].copy()\n",
        "        permuted_feature = original_feature.reshape(-1)\n",
        "        np.random.shuffle(permuted_feature)\n",
        "        X_permuted[:, :, feature_idx] = permuted_feature.reshape(X_permuted[:, :, feature_idx].shape)\n",
        "\n",
        "        # Calculate performance with permuted feature\n",
        "        permuted_predictions = model.predict(X_permuted, verbose=0)\n",
        "        permuted_probs = permuted_predictions.flatten()\n",
        "        permuted_auc = roc_auc_score(y_train, permuted_probs) if len(np.unique(y_train)) > 1 else 0.5\n",
        "\n",
        "        # Importance score is the drop in performance\n",
        "        importance = baseline_auc - permuted_auc\n",
        "        importance_scores.append((feature_idx, importance))\n",
        "\n",
        "    # Sort by importance\n",
        "    importance_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    print(\"\\nTop 10 Most Important Features:\")\n",
        "    for i, (feature_idx, importance) in enumerate(importance_scores[:10]):\n",
        "        feature_name = feature_names[feature_idx]\n",
        "        print(f\"  {i+1:2d}. {feature_name}: {importance:.4f}\")\n",
        "\n",
        "    return importance_scores\n",
        "\n",
        "print(\"\\nStep 8: Model Interpretation and Clinical Insights...\")\n",
        "print(\"=\" * 50)\n",
        "print(\"CLINICAL INSIGHTS:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"1. The model predicts mortality risk based on sequential patient data\")\n",
        "print(\"2. Key predictive features include adverse events and treatment patterns\")\n",
        "print(\"3. Model performance indicates good discriminative ability (AUC > 0.7)\")\n",
        "print(\"4. Optimal threshold balancing sensitivity and specificity\")\n",
        "print(\"5. Can be used for early identification of high-risk patients\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ETgQYZf5o1eL",
        "outputId": "be70b2fe-9c59-4f73-e8bb-0eed4593c47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: Setting up environment...\n",
            "Environment setup complete!\n",
            "Loading pcdata.csv...\n",
            "Data loaded successfully! Shape: (8121, 101)\n",
            "\n",
            "Step 1: Enhanced LSTM data preparation...\n",
            "Selected 14 clinical features\n",
            "Features: ['AGE', 'ECOGGRN', 'EXDOSENN', 'TARGETQN', 'NONTARQN', 'total_ae_events', 'serious_ae_count', 'grade3_plus_count', 'grade3_count', 'grade4_count', 'grade5_count', 'drug_withdrawn', 'concomitant_treatment_given', 'VISDAY']\n",
            "Outcome distribution: {0: 7051, 1: 1070}\n",
            "Patients with sufficient visits: 525\n",
            "  AGE: median=68.000\n",
            "  ECOGGRN: median=1.000\n",
            "  EXDOSENN: median=1.000\n",
            "  TARGETQN: median=1.000\n",
            "  NONTARQN: median=1.000\n",
            "  total_ae_events: median=7.000\n",
            "  serious_ae_count: median=0.000\n",
            "  grade3_plus_count: median=0.000\n",
            "  grade3_count: median=0.000\n",
            "  grade4_count: median=0.000\n",
            "  grade5_count: median=0.000\n",
            "  drug_withdrawn: median=0.000\n",
            "  concomitant_treatment_given: median=1.000\n",
            "  VISDAY: median=106.000\n",
            "Processing 525 patients...\n",
            "Processed 50 patients...\n",
            "Processed 100 patients...\n",
            "Processed 150 patients...\n",
            "Processed 200 patients...\n",
            "Processed 250 patients...\n",
            "Processed 300 patients...\n",
            "Processed 350 patients...\n",
            "Processed 400 patients...\n",
            "Processed 450 patients...\n",
            "Processed 500 patients...\n",
            "Created 525 sequences\n",
            "SUCCESS: LSTM data prepared!\n",
            "Sequences dimension: (525, 3, 14)\n",
            "Labels: 525\n",
            "Class distribution - 0: 449 1: 76\n",
            "\n",
            "Step 2: Advanced normalization...\n",
            "Normalizing array with dimensions: (525, 3, 14)\n",
            "Advanced normalization completed! Data range: [-2.802, 9.000]\n",
            "Final label distribution: 0: 449, 1: 76\n",
            "Class imbalance ratio: 5.91:1\n",
            "\n",
            "Step 3: Strategic train-test split...\n",
            "Data splits:\n",
            "Training:   (314, 3, 14) (0: 268 1: 46)\n",
            "Validation: (79, 3, 14) (0: 68 1: 11)\n",
            "Test:       (132, 3, 14) (0: 113 1: 19)\n",
            "\n",
            "Step 4: Building advanced LSTM model...\n",
            "Building advanced model for:\n",
            "  Sequence length: 3\n",
            "  Features: 14\n",
            "  Training samples: 314\n",
            "Enhanced class weights: {0: np.float64(0.585820895522388), 1: np.float64(3.4130434782608696)}\n",
            "Advanced model architecture:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d (\u001b[38;5;33mConv1D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m928\u001b[0m \n",
              "\n",
              " batch_normalization_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m128\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
              "\n",
              " max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_3 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m24,832\u001b[0m \n",
              "\n",
              " batch_normalization_2            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m256\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
              "\n",
              " lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m12,416\u001b[0m \n",
              "\n",
              " batch_normalization_3            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                        \u001b[38;5;34m128\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
              "\n",
              " dropout_4 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_3 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      \u001b[38;5;34m1,056\u001b[0m \n",
              "\n",
              " batch_normalization_4            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                        \u001b[38;5;34m128\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
              "\n",
              " dropout_5 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_4 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                        \u001b[38;5;34m528\u001b[0m \n",
              "\n",
              " dropout_6 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_5 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m17\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">928</span> \n",
              "\n",
              " batch_normalization_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
              "\n",
              " max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> \n",
              "\n",
              " batch_normalization_2            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
              "\n",
              " lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> \n",
              "\n",
              " batch_normalization_3            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
              "\n",
              " dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> \n",
              "\n",
              " batch_normalization_4            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
              "\n",
              " dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> \n",
              "\n",
              " dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,417\u001b[0m (157.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,417</span> (157.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,097\u001b[0m (156.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,097</span> (156.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m320\u001b[0m (1.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> (1.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 5: Enhanced training with validation...\n",
            "Starting enhanced training...\n",
            "Epoch 1/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.5346 - accuracy: 0.7657 - loss: 0.8973 - precision: 0.0302 - recall: 0.0177"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - AUC: 0.5296 - accuracy: 0.7665 - loss: 0.9045 - precision: 0.0308 - recall: 0.0181 - val_AUC: 0.4338 - val_accuracy: 0.8608 - val_loss: 0.6921 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 2/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.4402 - accuracy: 0.8188 - loss: 0.9563 - precision: 0.1389 - recall: 0.0742"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.4418 - accuracy: 0.8163 - loss: 0.9578 - precision: 0.1398 - recall: 0.0755 - val_AUC: 0.4599 - val_accuracy: 0.8608 - val_loss: 0.6861 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 3/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.5209 - accuracy: 0.7941 - loss: 0.8334 - precision: 0.1558 - recall: 0.1117"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.5287 - accuracy: 0.7934 - loss: 0.8283 - precision: 0.1616 - recall: 0.1177 - val_AUC: 0.5882 - val_accuracy: 0.8481 - val_loss: 0.6796 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 4/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.6036 - accuracy: 0.7845 - loss: 0.7822 - precision: 0.2919 - recall: 0.2622"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.6032 - accuracy: 0.7835 - loss: 0.7802 - precision: 0.2890 - recall: 0.2621 - val_AUC: 0.6557 - val_accuracy: 0.8228 - val_loss: 0.6739 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 5/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.5892 - accuracy: 0.7265 - loss: 0.7478 - precision: 0.2152 - recall: 0.3577"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.5872 - accuracy: 0.7253 - loss: 0.7503 - precision: 0.2124 - recall: 0.3506 - val_AUC: 0.6925 - val_accuracy: 0.8228 - val_loss: 0.6624 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 6/150\n",
            "\u001b[1m18/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.6072 - accuracy: 0.6800 - loss: 0.6588 - precision: 0.1818 - recall: 0.4327 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.6079 - accuracy: 0.6802 - loss: 0.6709 - precision: 0.1842 - recall: 0.4266 - val_AUC: 0.7005 - val_accuracy: 0.8228 - val_loss: 0.6567 - val_precision: 0.2857 - val_recall: 0.1818 - learning_rate: 0.0010\n",
            "Epoch 7/150\n",
            "\u001b[1m16/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.5395 - accuracy: 0.7018 - loss: 0.7012 - precision: 0.1228 - recall: 0.2445"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.5461 - accuracy: 0.6920 - loss: 0.7182 - precision: 0.1323 - recall: 0.2614 - val_AUC: 0.7152 - val_accuracy: 0.7848 - val_loss: 0.6562 - val_precision: 0.2500 - val_recall: 0.2727 - learning_rate: 0.0010\n",
            "Epoch 8/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.5688 - accuracy: 0.6323 - loss: 0.7354 - precision: 0.1954 - recall: 0.4706"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.5714 - accuracy: 0.6349 - loss: 0.7342 - precision: 0.1962 - recall: 0.4692 - val_AUC: 0.7360 - val_accuracy: 0.7468 - val_loss: 0.6563 - val_precision: 0.2857 - val_recall: 0.5455 - learning_rate: 0.0010\n",
            "Epoch 9/150\n",
            "\u001b[1m16/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.7123 - accuracy: 0.6963 - loss: 0.6298 - precision: 0.2530 - recall: 0.6347"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.6992 - accuracy: 0.6941 - loss: 0.6393 - precision: 0.2489 - recall: 0.6085 - val_AUC: 0.7313 - val_accuracy: 0.6582 - val_loss: 0.6606 - val_precision: 0.2500 - val_recall: 0.7273 - learning_rate: 0.0010\n",
            "Epoch 10/150\n",
            "\u001b[1m17/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.7747 - accuracy: 0.7051 - loss: 0.6077 - precision: 0.3138 - recall: 0.6359"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.7599 - accuracy: 0.6974 - loss: 0.6143 - precision: 0.2985 - recall: 0.6228 - val_AUC: 0.7460 - val_accuracy: 0.6456 - val_loss: 0.6538 - val_precision: 0.2571 - val_recall: 0.8182 - learning_rate: 0.0010\n",
            "Epoch 11/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.7213 - accuracy: 0.6494 - loss: 0.6477 - precision: 0.2602 - recall: 0.6511"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.7185 - accuracy: 0.6488 - loss: 0.6473 - precision: 0.2569 - recall: 0.6450 - val_AUC: 0.7507 - val_accuracy: 0.6203 - val_loss: 0.6507 - val_precision: 0.2432 - val_recall: 0.8182 - learning_rate: 0.0010\n",
            "Epoch 12/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.7448 - accuracy: 0.6833 - loss: 0.6300 - precision: 0.2912 - recall: 0.6804"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.7409 - accuracy: 0.6804 - loss: 0.6300 - precision: 0.2863 - recall: 0.6756 - val_AUC: 0.7326 - val_accuracy: 0.5949 - val_loss: 0.6504 - val_precision: 0.2308 - val_recall: 0.8182 - learning_rate: 0.0010\n",
            "Epoch 13/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8405 - accuracy: 0.7128 - loss: 0.5201 - precision: 0.3028 - recall: 0.8203"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.8334 - accuracy: 0.7077 - loss: 0.5266 - precision: 0.2987 - recall: 0.8105 - val_AUC: 0.7346 - val_accuracy: 0.5443 - val_loss: 0.6437 - val_precision: 0.2093 - val_recall: 0.8182 - learning_rate: 0.0010\n",
            "Epoch 14/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.6447 - accuracy: 0.6369 - loss: 0.6098 - precision: 0.2038 - recall: 0.5588"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - AUC: 0.6525 - accuracy: 0.6381 - loss: 0.6097 - precision: 0.2074 - recall: 0.5677 - val_AUC: 0.7353 - val_accuracy: 0.5570 - val_loss: 0.6323 - val_precision: 0.2143 - val_recall: 0.8182 - learning_rate: 0.0010\n",
            "Epoch 15/150\n",
            "\u001b[1m17/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.6782 - accuracy: 0.6258 - loss: 0.7089 - precision: 0.2664 - recall: 0.6884"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - AUC: 0.6851 - accuracy: 0.6298 - loss: 0.6902 - precision: 0.2651 - recall: 0.7048 - val_AUC: 0.7139 - val_accuracy: 0.6076 - val_loss: 0.6277 - val_precision: 0.2368 - val_recall: 0.8182 - learning_rate: 0.0010\n",
            "Epoch 16/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.8123 - accuracy: 0.7146 - loss: 0.5221 - precision: 0.2847 - recall: 0.8455"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - AUC: 0.8112 - accuracy: 0.7136 - loss: 0.5247 - precision: 0.2852 - recall: 0.8425 - val_AUC: 0.6945 - val_accuracy: 0.6076 - val_loss: 0.6195 - val_precision: 0.2222 - val_recall: 0.7273 - learning_rate: 0.0010\n",
            "Epoch 17/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.7068 - accuracy: 0.6218 - loss: 0.6391 - precision: 0.2432 - recall: 0.6794"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - AUC: 0.7087 - accuracy: 0.6228 - loss: 0.6366 - precision: 0.2437 - recall: 0.6823 - val_AUC: 0.7199 - val_accuracy: 0.6203 - val_loss: 0.5935 - val_precision: 0.2286 - val_recall: 0.7273 - learning_rate: 0.0010\n",
            "Epoch 18/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.7163 - accuracy: 0.6811 - loss: 0.6137 - precision: 0.2559 - recall: 0.7092"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - AUC: 0.7174 - accuracy: 0.6803 - loss: 0.6131 - precision: 0.2565 - recall: 0.7106 - val_AUC: 0.7326 - val_accuracy: 0.6076 - val_loss: 0.5763 - val_precision: 0.2222 - val_recall: 0.7273 - learning_rate: 0.0010\n",
            "Epoch 19/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.7097 - accuracy: 0.6592 - loss: 0.5430 - precision: 0.2063 - recall: 0.6364"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.7144 - accuracy: 0.6586 - loss: 0.5470 - precision: 0.2107 - recall: 0.6420 - val_AUC: 0.7373 - val_accuracy: 0.5949 - val_loss: 0.5791 - val_precision: 0.2308 - val_recall: 0.8182 - learning_rate: 0.0010\n",
            "Epoch 20/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.7524 - accuracy: 0.6413 - loss: 0.5435 - precision: 0.2364 - recall: 0.7927"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - AUC: 0.7532 - accuracy: 0.6433 - loss: 0.5460 - precision: 0.2399 - recall: 0.7917 - val_AUC: 0.7480 - val_accuracy: 0.6329 - val_loss: 0.5785 - val_precision: 0.2500 - val_recall: 0.8182 - learning_rate: 0.0010\n",
            "Epoch 21/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - AUC: 0.8163 - accuracy: 0.6575 - loss: 0.5242 - precision: 0.2724 - recall: 0.8187"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - AUC: 0.8123 - accuracy: 0.6582 - loss: 0.5303 - precision: 0.2729 - recall: 0.8174 - val_AUC: 0.7580 - val_accuracy: 0.6203 - val_loss: 0.5872 - val_precision: 0.2432 - val_recall: 0.8182 - learning_rate: 0.0010\n",
            "Epoch 22/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8176 - accuracy: 0.6675 - loss: 0.4858 - precision: 0.2246 - recall: 0.8706"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - AUC: 0.8137 - accuracy: 0.6679 - loss: 0.4935 - precision: 0.2298 - recall: 0.8622 - val_AUC: 0.7587 - val_accuracy: 0.6076 - val_loss: 0.5950 - val_precision: 0.2222 - val_recall: 0.7273 - learning_rate: 0.0010\n",
            "Epoch 23/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.6788 - accuracy: 0.6127 - loss: 0.6034 - precision: 0.2035 - recall: 0.6866"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.6840 - accuracy: 0.6153 - loss: 0.6051 - precision: 0.2081 - recall: 0.6916 - val_AUC: 0.7527 - val_accuracy: 0.6203 - val_loss: 0.6133 - val_precision: 0.2286 - val_recall: 0.7273 - learning_rate: 0.0010\n",
            "Epoch 24/150\n",
            "\u001b[1m16/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.7174 - accuracy: 0.6605 - loss: 0.5629 - precision: 0.2472 - recall: 0.7625"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.7254 - accuracy: 0.6600 - loss: 0.5722 - precision: 0.2536 - recall: 0.7630 - val_AUC: 0.7473 - val_accuracy: 0.6076 - val_loss: 0.6167 - val_precision: 0.2222 - val_recall: 0.7273 - learning_rate: 0.0010\n",
            "Epoch 25/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8350 - accuracy: 0.6629 - loss: 0.4881 - precision: 0.2795 - recall: 0.8902"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.8329 - accuracy: 0.6623 - loss: 0.4915 - precision: 0.2797 - recall: 0.8882 - val_AUC: 0.7513 - val_accuracy: 0.6582 - val_loss: 0.5914 - val_precision: 0.2500 - val_recall: 0.7273 - learning_rate: 0.0010\n",
            "Epoch 26/150\n",
            "\u001b[1m18/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8061 - accuracy: 0.6627 - loss: 0.5133 - precision: 0.2531 - recall: 0.8318"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.8090 - accuracy: 0.6645 - loss: 0.5131 - precision: 0.2590 - recall: 0.8371 - val_AUC: 0.7660 - val_accuracy: 0.6329 - val_loss: 0.5863 - val_precision: 0.2353 - val_recall: 0.7273 - learning_rate: 0.0010\n",
            "Epoch 27/150\n",
            "\u001b[1m17/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.8270 - accuracy: 0.6691 - loss: 0.5312 - precision: 0.3067 - recall: 0.8372"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.8268 - accuracy: 0.6686 - loss: 0.5275 - precision: 0.3034 - recall: 0.8389 - val_AUC: 0.7634 - val_accuracy: 0.6582 - val_loss: 0.5834 - val_precision: 0.2500 - val_recall: 0.7273 - learning_rate: 0.0010\n",
            "Epoch 28/150\n",
            "\u001b[1m18/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8916 - accuracy: 0.7336 - loss: 0.4491 - precision: 0.3546 - recall: 0.9065\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.8869 - accuracy: 0.7295 - loss: 0.4513 - precision: 0.3490 - recall: 0.9020 - val_AUC: 0.7667 - val_accuracy: 0.6582 - val_loss: 0.5816 - val_precision: 0.2500 - val_recall: 0.7273 - learning_rate: 0.0010\n",
            "Epoch 29/150\n",
            "\u001b[1m18/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8343 - accuracy: 0.6961 - loss: 0.4556 - precision: 0.2752 - recall: 0.8920"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.8319 - accuracy: 0.6969 - loss: 0.4625 - precision: 0.2793 - recall: 0.8801 - val_AUC: 0.7607 - val_accuracy: 0.6709 - val_loss: 0.5779 - val_precision: 0.2727 - val_recall: 0.8182 - learning_rate: 5.0000e-04\n",
            "Epoch 30/150\n",
            "\u001b[1m18/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8097 - accuracy: 0.6607 - loss: 0.4951 - precision: 0.2412 - recall: 0.8168"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.8076 - accuracy: 0.6632 - loss: 0.5005 - precision: 0.2473 - recall: 0.8144 - val_AUC: 0.7667 - val_accuracy: 0.6582 - val_loss: 0.5736 - val_precision: 0.2647 - val_recall: 0.8182 - learning_rate: 5.0000e-04\n",
            "Epoch 31/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8281 - accuracy: 0.7014 - loss: 0.5163 - precision: 0.3173 - recall: 0.7918 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.8283 - accuracy: 0.7010 - loss: 0.5140 - precision: 0.3166 - recall: 0.7992 - val_AUC: 0.7721 - val_accuracy: 0.6835 - val_loss: 0.5658 - val_precision: 0.2812 - val_recall: 0.8182 - learning_rate: 5.0000e-04\n",
            "Epoch 32/150\n",
            "\u001b[1m18/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8665 - accuracy: 0.6976 - loss: 0.4828 - precision: 0.3237 - recall: 0.9634"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - AUC: 0.8625 - accuracy: 0.6951 - loss: 0.4866 - precision: 0.3205 - recall: 0.9530 - val_AUC: 0.7714 - val_accuracy: 0.6835 - val_loss: 0.5679 - val_precision: 0.2812 - val_recall: 0.8182 - learning_rate: 5.0000e-04\n",
            "Epoch 33/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.7578 - accuracy: 0.6683 - loss: 0.5589 - precision: 0.2736 - recall: 0.7522"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.7608 - accuracy: 0.6702 - loss: 0.5562 - precision: 0.2764 - recall: 0.7634 - val_AUC: 0.7734 - val_accuracy: 0.6835 - val_loss: 0.5670 - val_precision: 0.2812 - val_recall: 0.8182 - learning_rate: 5.0000e-04\n",
            "Epoch 34/150\n",
            "\u001b[1m18/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8799 - accuracy: 0.7277 - loss: 0.4610 - precision: 0.3667 - recall: 0.9210"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.8749 - accuracy: 0.7240 - loss: 0.4628 - precision: 0.3588 - recall: 0.9143 - val_AUC: 0.7680 - val_accuracy: 0.6835 - val_loss: 0.5650 - val_precision: 0.2812 - val_recall: 0.8182 - learning_rate: 5.0000e-04\n",
            "Epoch 35/150\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.8342 - accuracy: 0.6966 - loss: 0.5199 - precision: 0.3222 - recall: 0.8420"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - AUC: 0.8347 - accuracy: 0.6960 - loss: 0.5184 - precision: 0.3210 - recall: 0.8423 - val_AUC: 0.7741 - val_accuracy: 0.6835 - val_loss: 0.5609 - val_precision: 0.2812 - val_recall: 0.8182 - learning_rate: 5.0000e-04\n",
            "Epoch 36/150\n",
            "\u001b[1m17/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.8929 - accuracy: 0.7142 - loss: 0.4037 - precision: 0.2846 - recall: 0.9280"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - AUC: 0.8891 - accuracy: 0.7161 - loss: 0.4120 - precision: 0.2947 - recall: 0.9258 - val_AUC: 0.7714 - val_accuracy: 0.6709 - val_loss: 0.5692 - val_precision: 0.2727 - val_recall: 0.8182 - learning_rate: 5.0000e-04\n",
            "Epoch 37/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.7431 - accuracy: 0.6614 - loss: 0.5603 - precision: 0.2605 - recall: 0.7438"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - AUC: 0.7525 - accuracy: 0.6642 - loss: 0.5539 - precision: 0.2651 - recall: 0.7579 - val_AUC: 0.7801 - val_accuracy: 0.6962 - val_loss: 0.5631 - val_precision: 0.2903 - val_recall: 0.8182 - learning_rate: 5.0000e-04\n",
            "Epoch 38/150\n",
            "\u001b[1m16/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - AUC: 0.8613 - accuracy: 0.7061 - loss: 0.4561 - precision: 0.3154 - recall: 0.8933"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.8445 - accuracy: 0.7041 - loss: 0.4773 - precision: 0.3127 - recall: 0.8763 - val_AUC: 0.7934 - val_accuracy: 0.6709 - val_loss: 0.5562 - val_precision: 0.2727 - val_recall: 0.8182 - learning_rate: 5.0000e-04\n",
            "Epoch 39/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8602 - accuracy: 0.6814 - loss: 0.4471 - precision: 0.2848 - recall: 0.8804"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - AUC: 0.8550 - accuracy: 0.6811 - loss: 0.4536 - precision: 0.2847 - recall: 0.8711 - val_AUC: 0.7988 - val_accuracy: 0.6835 - val_loss: 0.5564 - val_precision: 0.2812 - val_recall: 0.8182 - learning_rate: 5.0000e-04\n",
            "Epoch 40/150\n",
            "\u001b[1m19/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - AUC: 0.8381 - accuracy: 0.7079 - loss: 0.4868 - precision: 0.3364 - recall: 0.8858"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - AUC: 0.8410 - accuracy: 0.7096 - loss: 0.4833 - precision: 0.3368 - recall: 0.8905 - val_AUC: 0.7894 - val_accuracy: 0.6835 - val_loss: 0.5626 - val_precision: 0.2812 - val_recall: 0.8182 - learning_rate: 5.0000e-04\n",
            "Epoch 41/150\n",
            "\u001b[1m16/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - AUC: 0.8448 - accuracy: 0.6959 - loss: 0.4932 - precision: 0.3137 - recall: 0.7929"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "### START OF IMPROVED CODE BLOCK ###\n",
        "\n",
        "print(\"\\nStep 1: **IMPROVED** LSTM data preparation with extensive feature set...\")\n",
        "\n",
        "def prepare_lstm_improved_v2(data, sequence_length=3):\n",
        "    # Expanded and more comprehensive feature list\n",
        "    # Exclude 'grade5_count' and 'CANCDEAD' (used as label) due to leakage.\n",
        "    leakage_variables = ['CANCDEAD', 'grade5_count']\n",
        "\n",
        "    essential_features_v2 = [\n",
        "        # Demographic & Baseline (Potential new additions)\n",
        "        'AGE', 'ECOGGRN', 'RACE', 'SEX', 'DISEASE_STAGE',\n",
        "        # Dosing & Treatment\n",
        "        'EXDOSENN', 'DOSERED', 'concomitant_treatment_given',\n",
        "        'drug_withdrawn', # Keeping, but caution: if it's *result* of death, it leaks.\n",
        "        # Tumor response\n",
        "        'TARGETQN', 'NONTARQN',\n",
        "        # AE counts (safest grades)\n",
        "        'total_ae_events', 'serious_ae_count', 'grade3_plus_count',\n",
        "        'grade3_count', 'grade4_count',\n",
        "        # Time\n",
        "        'VISDAY'\n",
        "    ]\n",
        "\n",
        "    # Clean the list\n",
        "    essential_features_v2 = [col for col in essential_features_v2 if col not in leakage_variables]\n",
        "    available_features = [col for col in essential_features_v2 if col in data.columns]\n",
        "\n",
        "    print(f\"Selected {len(available_features)} essential features\")\n",
        "    print(f\"Features: {available_features}\")\n",
        "\n",
        "    data_prep = data.copy()\n",
        "\n",
        "    # --- 1. Outcome Variable Creation (Same as original) ---\n",
        "    if 'CANCDEAD' in data_prep.columns:\n",
        "        data_prep['outcome'] = data_prep['CANCDEAD'].astype(int)\n",
        "        data_prep['outcome'] = (data_prep['outcome'] > 0).astype(int)\n",
        "        print(f\"Outcome distribution: {data_prep['outcome'].value_counts().to_dict()}\")\n",
        "    else:\n",
        "        print(\"WARNING: CANCDEAD column not found.\")\n",
        "        return None\n",
        "\n",
        "    # --- 2. Remove patients with insufficient visits (Same as original) ---\n",
        "    visit_counts = data_prep.groupby('RPT').size()\n",
        "    valid_patients = visit_counts[visit_counts >= sequence_length].index\n",
        "    data_prep = data_prep[data_prep['RPT'].isin(valid_patients)]\n",
        "    print(f\"Patients with sufficient visits: {len(valid_patients)}\")\n",
        "\n",
        "    # --- 3. Feature Engineering ---\n",
        "    if 'total_ae_events' in data_prep.columns and 'VISDAY' in data_prep.columns:\n",
        "        data_prep['AE_RATE'] = data_prep['total_ae_events'] / (data_prep['VISDAY'] + 1e-6)\n",
        "        data_prep['AE_RATE'] = data_prep['AE_RATE'].replace([np.inf, -np.inf], 0)\n",
        "        available_features.append('AE_RATE')\n",
        "        print(\"  Engineered feature: AE_RATE (Total AE / Visit Day)\")\n",
        "\n",
        "    # --- 4. Categorical Encoding (Improved) ---\n",
        "    categorical_cols = [col for col in ['RACE', 'SEX', 'DISEASE_STAGE'] if col in available_features]\n",
        "    if categorical_cols:\n",
        "        data_prep = pd.get_dummies(data_prep, columns=categorical_cols, prefix=categorical_cols, drop_first=True)\n",
        "        # Update available_features to include new OHE columns, remove originals\n",
        "        for col in categorical_cols:\n",
        "            available_features.remove(col)\n",
        "            # Add all new columns created by the OHE\n",
        "            available_features.extend([c for c in data_prep.columns if c.startswith(f'{col}_') and c != f'{col}_NaN'])\n",
        "\n",
        "    # --- 5. Numeric Conversion & Imputation (Robust Imputation) ---\n",
        "    final_features = []\n",
        "    for col in available_features:\n",
        "        # For OHE columns, just check if they exist\n",
        "        if col not in data_prep.columns:\n",
        "            continue\n",
        "\n",
        "        data_prep[col] = pd.to_numeric(data_prep[col], errors='coerce')\n",
        "\n",
        "        # Use median imputation for features that are not binary\n",
        "        if data_prep[col].nunique() > 2:\n",
        "            median_val = data_prep[col].median()\n",
        "            data_prep[col] = data_prep[col].fillna(median_val)\n",
        "        else: # For binary/OHE features, impute with mode (0 or 1)\n",
        "             mode_val = data_prep[col].mode()[0] if not data_prep[col].mode().empty else 0\n",
        "             data_prep[col] = data_prep[col].fillna(mode_val)\n",
        "\n",
        "        final_features.append(col)\n",
        "\n",
        "    print(f\"Final feature count after OHE/Imputation: {len(final_features)}\")\n",
        "\n",
        "    # --- 6. Remove constant features (Same as original) ---\n",
        "    constant_features = [f for f in final_features if data_prep[f].nunique() <= 1]\n",
        "    if constant_features:\n",
        "        print(f\"Removing constant features: {constant_features}\")\n",
        "        final_features = [f for f in final_features if f not in constant_features]\n",
        "\n",
        "    # --- 7. Sequence Creation (Same as original) ---\n",
        "    patients = data_prep['RPT'].unique()\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for patient in patients:\n",
        "        patient_data = data_prep[data_prep['RPT'] == patient].sort_values('VISDAY')\n",
        "\n",
        "        if len(patient_data) >= sequence_length:\n",
        "            patient_outcome = patient_data['outcome'].iloc[0]\n",
        "            feature_matrix = patient_data[final_features].values\n",
        "\n",
        "            # Use the last 'sequence_length' time points\n",
        "            sequence_data = feature_matrix[-sequence_length:, :]\n",
        "\n",
        "            sequences.append(sequence_data)\n",
        "            labels.append(patient_outcome)\n",
        "\n",
        "    print(f\"Created {len(sequences)} sequences\")\n",
        "\n",
        "    if len(sequences) == 0:\n",
        "        raise ValueError(\"No sequences created\")\n",
        "\n",
        "    sequences_array = create_3d_array(sequences)\n",
        "\n",
        "    return {\n",
        "        'sequences': sequences_array,\n",
        "        'labels': np.array(labels),\n",
        "        'feature_names': final_features\n",
        "    }\n",
        "\n",
        "# Rerun data preparation with the improved function\n",
        "try:\n",
        "    lstm_data = prepare_lstm_improved_v2(sequential_data, sequence_length=5) # Increased sequence length to 5\n",
        "    if lstm_data is None:\n",
        "        raise ValueError(\"Data preparation failed\")\n",
        "\n",
        "    # Rerun normalization and split\n",
        "    X_sequences, scaler = robust_normalize_3d(lstm_data['sequences'].copy(), lstm_data.get('feature_names'))\n",
        "    y = lstm_data['labels']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_sequences, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    sequence_length = X_train.shape[1]\n",
        "    n_features = X_train.shape[2]\n",
        "\n",
        "    print(f\"**SUCCESS:** New Sequences dimension: {X_sequences.shape}\")\n",
        "    print(f\"New Feature count: {n_features}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR in V2 data preparation: {e}\")\n",
        "    # Fallback to original if V2 fails\n",
        "    try:\n",
        "        lstm_data = prepare_lstm_improved(sequential_data, sequence_length=3)\n",
        "        if lstm_data is None: raise ValueError\n",
        "        X_sequences, scaler = robust_normalize_3d(lstm_data['sequences'].copy(), lstm_data.get('feature_names'))\n",
        "        y = lstm_data['labels']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_sequences, y, test_size=0.3, random_state=42, stratify=y)\n",
        "        sequence_length = X_train.shape[1]\n",
        "        n_features = X_train.shape[2]\n",
        "        print(\"Using fallback data preparation.\")\n",
        "    except Exception as e_f:\n",
        "        print(f\"ERROR: Both data preparations failed: {e_f}\")\n",
        "        exit()\n",
        "\n",
        "\n",
        "print(\"\\nStep 4: **IMPROVED** Building deeper, more regularized LSTM model...\")\n",
        "\n",
        "def build_improved_lstm_model(sequence_length, n_features):\n",
        "    # Deeper architecture with stronger regularization (L2) and more units\n",
        "    model = Sequential([\n",
        "        # 1. More aggressive L2 regularization on the recurrent layer\n",
        "        LSTM(64,\n",
        "             input_shape=(sequence_length, n_features),\n",
        "             return_sequences=True, # Stacked LSTM\n",
        "             kernel_regularizer=l1_l2(l2=1e-4),\n",
        "             recurrent_regularizer=l1_l2(l2=1e-3),\n",
        "             kernel_initializer='he_uniform'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4), # Increased Dropout\n",
        "\n",
        "        # 2. Second LSTM layer to capture higher-level time dependencies\n",
        "        LSTM(32,\n",
        "             return_sequences=False,\n",
        "             kernel_regularizer=l1_l2(l2=1e-4),\n",
        "             recurrent_regularizer=l1_l2(l2=1e-3),\n",
        "             kernel_initializer='he_uniform'),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # 3. Dense layers with Batch Normalization\n",
        "        Dense(16, activation='relu', kernel_regularizer=l1_l2(l2=1e-4)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        # 4. Output\n",
        "        Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform')\n",
        "    ])\n",
        "\n",
        "    # Use a faster learning rate, trusting regularization to prevent overfitting\n",
        "    optimizer = Adam(\n",
        "        learning_rate=0.005, # Higher initial LR\n",
        "        clipnorm=1.0\n",
        "    )\n",
        "\n",
        "    # Trusting AUC as the primary metric for imbalanced classification\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=optimizer,\n",
        "        metrics=['accuracy', 'AUC']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build the improved model\n",
        "lstm_model = build_improved_lstm_model(sequence_length, n_features)\n",
        "print(\"Model architecture:\")\n",
        "lstm_model.summary()\n",
        "\n",
        "print(\"\\nStep 5: **IMPROVED** Training with aggressive early stopping and reduced LR...\")\n",
        "\n",
        "# Calculate class weights (same as original)\n",
        "class_counts = np.bincount(y_train)\n",
        "if len(class_counts) > 1:\n",
        "    total = len(y_train)\n",
        "    class_weights = {\n",
        "        0: total / (2 * class_counts[0]),\n",
        "        1: total / (2 * class_counts[1])\n",
        "    }\n",
        "    print(f\"Class weights: {class_weights}\")\n",
        "else:\n",
        "    class_weights = {0: 1, 1: 1}\n",
        "    print(\"Using equal class weights\")\n",
        "\n",
        "# Enhanced callbacks (Patience reduced, Delta tighter)\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_auc' if len(np.unique(y_train)) > 1 else 'val_loss',\n",
        "    patience=15, # Reduced from 20 for faster convergence/stop\n",
        "    restore_best_weights=True,\n",
        "    mode='max' if len(np.unique(y_train)) > 1 else 'min',\n",
        "    verbose=1,\n",
        "    min_delta=0.0005 # Tighter delta\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2, # More aggressive factor (0.5 to 0.2)\n",
        "    patience=5, # Reduced from 10\n",
        "    min_lr=1e-8,\n",
        "    verbose=1,\n",
        "    min_delta=0.001\n",
        ")\n",
        "\n",
        "# Prepare validation data (same as original)\n",
        "val_split = 0.2 if len(np.unique(y_train)) > 1 else 0.0\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "try:\n",
        "    history = lstm_model.fit(\n",
        "        x=X_train,\n",
        "        y=y_train,\n",
        "        epochs=150, # Increased epochs to allow for more patience/LR reduction\n",
        "        batch_size=32, # Increased batch size for more stable gradient\n",
        "        validation_split=val_split,\n",
        "        class_weight=class_weights,\n",
        "        verbose=1,\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "        shuffle=True\n",
        "    )\n",
        "    print(\"Training completed successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Training failed: {e}\")\n",
        "    # Fallback removed - if it fails now, something is fundamentally wrong.\n",
        "\n",
        "### END OF IMPROVED CODE BLOCK ###\n",
        "\n",
        "print(\"\\nStep 6: Comprehensive model evaluation...\")\n",
        "\n",
        "if 'lstm_model' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
        "    try:\n",
        "        # Make predictions\n",
        "        predictions = lstm_model.predict(X_test, verbose=0)\n",
        "        predicted_probs = predictions.flatten()\n",
        "\n",
        "        # Find optimal threshold using validation set\n",
        "        val_predictions = lstm_model.predict(X_val, verbose=0).flatten()\n",
        "        val_precisions, val_recalls, val_thresholds = precision_recall_curve(y_val, val_predictions)\n",
        "        val_f1_scores = 2 * (val_precisions[:-1] * val_recalls[:-1]) / (val_precisions[:-1] + val_recalls[:-1] + 1e-8)\n",
        "        optimal_idx = np.argmax(val_f1_scores)\n",
        "        optimal_threshold = val_thresholds[optimal_idx]\n",
        "\n",
        "        print(f\"Optimal threshold from validation: {optimal_threshold:.3f}\")\n",
        "\n",
        "        # Use optimal threshold for test set\n",
        "        predicted_classes = (predicted_probs > optimal_threshold).astype(int)\n",
        "\n",
        "        # Comprehensive metrics\n",
        "        conf_matrix = confusion_matrix(y_test, predicted_classes)\n",
        "        accuracy = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
        "\n",
        "        tn, fp, fn, tp = conf_matrix.ravel()\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        f1_score = 2 * (precision * sensitivity) / (precision + sensitivity + 1e-8)\n",
        "\n",
        "        # AUC and PR AUC\n",
        "        auc_val = roc_auc_score(y_test, predicted_probs)\n",
        "        precision_curve, recall_curve, _ = precision_recall_curve(y_test, predicted_probs)\n",
        "        pr_auc = np.trapz(recall_curve, precision_curve)\n",
        "\n",
        "        # Print comprehensive results\n",
        "        print(\"=\" * 70)\n",
        "        print(\"ADVANCED LSTM MODEL PERFORMANCE\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Accuracy:          {accuracy:.3f}\")\n",
        "        print(f\"Sensitivity:       {sensitivity:.3f}\")\n",
        "        print(f\"Specificity:       {specificity:.3f}\")\n",
        "        print(f\"Precision:         {precision:.3f}\")\n",
        "        print(f\"F1-Score:          {f1_score:.3f}\")\n",
        "        print(f\"AUC-ROC:           {auc_val:.3f}\")\n",
        "        print(f\"AUC-PR:            {pr_auc:.3f}\")\n",
        "        print(f\"Optimal Threshold: {optimal_threshold:.3f}\")\n",
        "        print(f\"\\nConfusion Matrix:\")\n",
        "        print(conf_matrix)\n",
        "        print(f\"\\nDetailed Classification Report:\")\n",
        "        print(classification_report(y_test, predicted_classes,\n",
        "                                  target_names=['Class 0 (Alive)', 'Class 1 (Deceased)']))\n",
        "\n",
        "        # Enhanced visualization\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "        # ROC Curve\n",
        "        fpr, tpr, _ = roc_curve(y_test, predicted_probs)\n",
        "        axes[0, 0].plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {auc_val:.3f}')\n",
        "        axes[0, 0].plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
        "        axes[0, 0].set_xlabel('False Positive Rate')\n",
        "        axes[0, 0].set_ylabel('True Positive Rate')\n",
        "        axes[0, 0].set_title('ROC Curve')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True)\n",
        "\n",
        "        # Precision-Recall Curve\n",
        "        axes[0, 1].plot(recall_curve, precision_curve, 'r-', linewidth=2, label=f'PR AUC = {pr_auc:.3f}')\n",
        "        axes[0, 1].set_xlabel('Recall')\n",
        "        axes[0, 1].set_ylabel('Precision')\n",
        "        axes[0, 1].set_title('Precision-Recall Curve')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True)\n",
        "\n",
        "        # Training history - Loss\n",
        "        axes[0, 2].plot(history.history['loss'], 'b-', label='Train Loss')\n",
        "        axes[0, 2].plot(history.history['val_loss'], 'r-', label='Val Loss')\n",
        "        axes[0, 2].set_xlabel('Epoch')\n",
        "        axes[0, 2].set_ylabel('Loss')\n",
        "        axes[0, 2].set_title('Training History - Loss')\n",
        "        axes[0, 2].legend()\n",
        "        axes[0, 2].grid(True)\n",
        "\n",
        "        # Training history - AUC\n",
        "        axes[1, 0].plot(history.history['auc'], 'b-', label='Train AUC')\n",
        "        axes[1, 0].plot(history.history['val_auc'], 'r-', label='Val AUC')\n",
        "        axes[1, 0].set_xlabel('Epoch')\n",
        "        axes[1, 0].set_ylabel('AUC')\n",
        "        axes[1, 0].set_title('Training History - AUC')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True)\n",
        "\n",
        "        # Probability distribution\n",
        "        axes[1, 1].hist([predicted_probs[y_test == 0], predicted_probs[y_test == 1]],\n",
        "                       bins=20, alpha=0.7, label=['Class 0', 'Class 1'],\n",
        "                       color=['blue', 'red'])\n",
        "        axes[1, 1].axvline(optimal_threshold, color='black', linestyle='--',\n",
        "                          label=f'Threshold = {optimal_threshold:.2f}')\n",
        "        axes[1, 1].set_xlabel('Predicted Probability')\n",
        "        axes[1, 1].set_ylabel('Count')\n",
        "        axes[1, 1].set_title('Prediction Distribution')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True)\n",
        "\n",
        "        # Confusion Matrix Heatmap\n",
        "        im = axes[1, 2].imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
        "        axes[1, 2].set_xticks([0, 1])\n",
        "        axes[1, 2].set_yticks([0, 1])\n",
        "        axes[1, 2].set_xticklabels(['Pred 0', 'Pred 1'])\n",
        "        axes[1, 2].set_yticklabels(['True 0', 'True 1'])\n",
        "        axes[1, 2].set_title('Confusion Matrix')\n",
        "\n",
        "        # Add text annotations\n",
        "        for i in range(2):\n",
        "            for j in range(2):\n",
        "                axes[1, 2].text(j, i, f'{conf_matrix[i, j]}',\n",
        "                               ha='center', va='center',\n",
        "                               color='white' if conf_matrix[i, j] > conf_matrix.max()/2 else 'black')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Feature importance analysis\n",
        "        print(\"\\nStep 7: Feature Importance Analysis...\")\n",
        "        analyze_feature_importance(lstm_model, X_train, lstm_data['feature_names'])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in evaluation: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"Cannot evaluate - model or test data not available\")\n",
        "\n",
        "def analyze_feature_importance(model, X_data, feature_names):\n",
        "    \"\"\"Analyze feature importance using permutation importance\"\"\"\n",
        "    print(\"Feature Importance Analysis:\")\n",
        "\n",
        "    # Get baseline performance\n",
        "    baseline_predictions = model.predict(X_data, verbose=0)\n",
        "    baseline_probs = baseline_predictions.flatten()\n",
        "    baseline_auc = roc_auc_score(y_train, baseline_probs) if len(np.unique(y_train)) > 1 else 0.5\n",
        "\n",
        "    importance_scores = []\n",
        "\n",
        "    # Permutation importance for each feature\n",
        "    for feature_idx in range(X_data.shape[2]):\n",
        "        X_permuted = X_data.copy()\n",
        "\n",
        "        # Permute the feature across all samples and timesteps\n",
        "        original_feature = X_permuted[:, :, feature_idx].copy()\n",
        "        permuted_feature = original_feature.reshape(-1)\n",
        "        np.random.shuffle(permuted_feature)\n",
        "        X_permuted[:, :, feature_idx] = permuted_feature.reshape(X_permuted[:, :, feature_idx].shape)\n",
        "\n",
        "        # Calculate performance with permuted feature\n",
        "        permuted_predictions = model.predict(X_permuted, verbose=0)\n",
        "        permuted_probs = permuted_predictions.flatten()\n",
        "        permuted_auc = roc_auc_score(y_train, permuted_probs) if len(np.unique(y_train)) > 1 else 0.5\n",
        "\n",
        "        # Importance score is the drop in performance\n",
        "        importance = baseline_auc - permuted_auc\n",
        "        importance_scores.append((feature_idx, importance))\n",
        "\n",
        "    # Sort by importance\n",
        "    importance_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    print(\"\\nTop 10 Most Important Features:\")\n",
        "    for i, (feature_idx, importance) in enumerate(importance_scores[:10]):\n",
        "        feature_name = feature_names[feature_idx]\n",
        "        print(f\"  {i+1:2d}. {feature_name}: {importance:.4f}\")\n",
        "\n",
        "    return importance_scores\n",
        "\n",
        "print(\"\\nStep 8: Model Interpretation and Clinical Insights...\")\n",
        "print(\"=\" * 50)\n",
        "print(\"CLINICAL INSIGHTS:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"1. The model predicts mortality risk based on sequential patient data\")\n",
        "print(\"2. Key predictive features include adverse events and treatment patterns\")\n",
        "print(\"3. Model performance indicates good discriminative ability (AUC > 0.7)\")\n",
        "print(\"4. Optimal threshold balancing sensitivity and specificity\")\n",
        "print(\"5. Can be used for early identification of high-risk patients\")\n"
      ],
      "metadata": {
        "id": "Pgv6lhHNq7B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nStep 1: **ENHANCED** LSTM data preparation with improved feature engineering...\")\n",
        "\n",
        "def prepare_lstm_enhanced(data, sequence_length=5):\n",
        "    # More selective feature set to reduce overfitting\n",
        "    leakage_variables = ['CANCDEAD', 'grade5_count']\n",
        "\n",
        "    # Focus on clinically relevant features with strong predictive power\n",
        "    enhanced_features = [\n",
        "        # Core clinical features\n",
        "        'AGE', 'ECOGGRN', 'EXDOSENN',\n",
        "        # Treatment response\n",
        "        'TARGETQN', 'NONTARQN',\n",
        "        # Safety signals (most important)\n",
        "        'serious_ae_count', 'grade3_plus_count', 'grade4_count',\n",
        "        # Time progression\n",
        "        'VISDAY'\n",
        "    ]\n",
        "\n",
        "    # Clean the list\n",
        "    enhanced_features = [col for col in enhanced_features if col not in leakage_variables]\n",
        "    available_features = [col for col in enhanced_features if col in data.columns]\n",
        "\n",
        "    print(f\"Selected {len(available_features)} focused features\")\n",
        "    print(f\"Features: {available_features}\")\n",
        "\n",
        "    data_prep = data.copy()\n",
        "\n",
        "    # Outcome variable\n",
        "    if 'CANCDEAD' in data_prep.columns:\n",
        "        data_prep['outcome'] = (data_prep['CANCDEAD'].astype(int) > 0).astype(int)\n",
        "        print(f\"Outcome distribution: {data_prep['outcome'].value_counts().to_dict()}\")\n",
        "    else:\n",
        "        print(\"WARNING: CANCDEAD column not found.\")\n",
        "        return None\n",
        "\n",
        "    # Remove patients with insufficient visits\n",
        "    visit_counts = data_prep.groupby('RPT').size()\n",
        "    valid_patients = visit_counts[visit_counts >= sequence_length].index\n",
        "    data_prep = data_prep[data_prep['RPT'].isin(valid_patients)]\n",
        "    print(f\"Patients with sufficient visits: {len(valid_patients)}\")\n",
        "\n",
        "    # Enhanced feature engineering\n",
        "    if 'total_ae_events' in data_prep.columns and 'VISDAY' in data_prep.columns:\n",
        "        data_prep['AE_RATE'] = data_prep['total_ae_events'] / (data_prep['VISDAY'] + 1e-6)\n",
        "        data_prep['AE_RATE'] = data_prep['AE_RATE'].replace([np.inf, -np.inf], 0)\n",
        "        available_features.append('AE_RATE')\n",
        "        print(\"  Engineered feature: AE_RATE\")\n",
        "\n",
        "    # Create trend features for key variables\n",
        "    trend_features = ['TARGETQN', 'NONTARQN', 'serious_ae_count']\n",
        "    for feature in trend_features:\n",
        "        if feature in available_features:\n",
        "            data_prep[f'{feature}_TREND'] = data_prep.groupby('RPT')[feature].diff().fillna(0)\n",
        "            available_features.append(f'{feature}_TREND')\n",
        "            print(f\"  Engineered feature: {feature}_TREND\")\n",
        "\n",
        "    # Simplified categorical encoding - only essential categories\n",
        "    if 'SEX' in available_features:\n",
        "        data_prep['SEX'] = data_prep['SEX'].map({'M': 0, 'F': 1}).fillna(0)\n",
        "        # If not binary, use one-hot encoding\n",
        "        if data_prep['SEX'].nunique() > 2:\n",
        "            data_prep = pd.get_dummies(data_prep, columns=['SEX'], prefix=['SEX'], drop_first=True)\n",
        "            available_features = [f for f in available_features if f != 'SEX']\n",
        "            available_features.extend([c for c in data_prep.columns if c.startswith('SEX_')])\n",
        "\n",
        "    # Robust numeric conversion & imputation\n",
        "    final_features = []\n",
        "    for col in available_features:\n",
        "        if col not in data_prep.columns:\n",
        "            continue\n",
        "\n",
        "        data_prep[col] = pd.to_numeric(data_prep[col], errors='coerce')\n",
        "\n",
        "        # Use median for continuous, mode for binary\n",
        "        if data_prep[col].nunique() > 2:\n",
        "            median_val = data_prep[col].median()\n",
        "            data_prep[col] = data_prep[col].fillna(median_val)\n",
        "        else:\n",
        "            mode_val = data_prep[col].mode()[0] if not data_prep[col].mode().empty else 0\n",
        "            data_prep[col] = data_prep[col].fillna(mode_val)\n",
        "\n",
        "        final_features.append(col)\n",
        "\n",
        "    # Remove near-constant features\n",
        "    constant_features = [f for f in final_features if data_prep[f].nunique() <= 1]\n",
        "    if constant_features:\n",
        "        print(f\"Removing constant features: {constant_features}\")\n",
        "        final_features = [f for f in final_features if f not in constant_features]\n",
        "\n",
        "    # Remove highly correlated features\n",
        "    correlation_matrix = data_prep[final_features].corr().abs()\n",
        "    upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
        "    high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.85)]\n",
        "    if high_corr_features:\n",
        "        print(f\"Removing highly correlated features: {high_corr_features}\")\n",
        "        final_features = [f for f in final_features if f not in high_corr_features]\n",
        "\n",
        "    print(f\"Final feature count: {len(final_features)}\")\n",
        "\n",
        "    # Sequence creation with balanced sampling\n",
        "    patients = data_prep['RPT'].unique()\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    patient_outcomes = data_prep.groupby('RPT')['outcome'].first()\n",
        "\n",
        "    for patient in patients:\n",
        "        patient_data = data_prep[data_prep['RPT'] == patient].sort_values('VISDAY')\n",
        "\n",
        "        if len(patient_data) >= sequence_length:\n",
        "            patient_outcome = patient_outcomes[patient]\n",
        "            feature_matrix = patient_data[final_features].values\n",
        "\n",
        "            # Use the last 'sequence_length' time points\n",
        "            sequence_data = feature_matrix[-sequence_length:, :]\n",
        "\n",
        "            sequences.append(sequence_data)\n",
        "            labels.append(patient_outcome)\n",
        "\n",
        "    print(f\"Created {len(sequences)} sequences\")\n",
        "    print(f\"Class distribution in sequences: {pd.Series(labels).value_counts().to_dict()}\")\n",
        "\n",
        "    if len(sequences) == 0:\n",
        "        raise ValueError(\"No sequences created\")\n",
        "\n",
        "    sequences_array = create_3d_array(sequences)\n",
        "\n",
        "    return {\n",
        "        'sequences': sequences_array,\n",
        "        'labels': np.array(labels),\n",
        "        'feature_names': final_features\n",
        "    }\n",
        "\n",
        "print(\"\\nStep 4: **ENHANCED** Building optimized LSTM model with better regularization...\")\n",
        "\n",
        "def build_enhanced_lstm_model(sequence_length, n_features):\n",
        "    # Simplified architecture to prevent overfitting\n",
        "    model = Sequential([\n",
        "        # First LSTM layer with moderate regularization\n",
        "        LSTM(32,\n",
        "             input_shape=(sequence_length, n_features),\n",
        "             return_sequences=False,  # Simpler architecture\n",
        "             kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4),\n",
        "             recurrent_regularizer=l1_l2(l2=1e-4),\n",
        "             dropout=0.3,  # Using built-in dropout\n",
        "             recurrent_dropout=0.2,\n",
        "             kernel_initializer='he_uniform'),\n",
        "\n",
        "        BatchNormalization(),\n",
        "\n",
        "        # Single dense layer\n",
        "        Dense(16, activation='relu',\n",
        "              kernel_regularizer=l1_l2(l2=1e-4),\n",
        "              kernel_initializer='he_uniform'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # Output\n",
        "        Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform')\n",
        "    ])\n",
        "\n",
        "    # Conservative learning rate\n",
        "    optimizer = Adam(\n",
        "        learning_rate=0.001,\n",
        "        clipnorm=1.0\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=optimizer,\n",
        "        metrics=['accuracy', 'AUC', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"\\nStep 5: **ENHANCED** Training with improved strategies...\")\n",
        "\n",
        "# Enhanced callbacks for imbalanced data\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_auc',\n",
        "    patience=25,\n",
        "    restore_best_weights=True,\n",
        "    mode='max',\n",
        "    verbose=1,\n",
        "    min_delta=0.001\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=10,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1,\n",
        "    min_delta=0.002\n",
        ")\n",
        "\n",
        "# Model checkpoint\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    'best_lstm_model.h5',\n",
        "    monitor='val_auc',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(\"Starting enhanced training...\")\n",
        "\n",
        "try:\n",
        "    history = lstm_model.fit(\n",
        "        x=X_train,\n",
        "        y=y_train,\n",
        "        epochs=200,\n",
        "        batch_size=16,  # Smaller batch size for better gradient estimation\n",
        "        validation_split=0.2,\n",
        "        class_weight=class_weights,\n",
        "        verbose=1,\n",
        "        callbacks=[early_stopping, reduce_lr, checkpoint],\n",
        "        shuffle=True\n",
        "    )\n",
        "    print(\"Enhanced training completed successfully!\")\n",
        "\n",
        "    # Load best model\n",
        "    lstm_model.load_weights('best_lstm_model.h5')\n",
        "    print(\"Loaded best model weights from checkpoint\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Enhanced training failed: {e}\")\n",
        "\n",
        "print(\"\\nStep 6: Comprehensive model evaluation with enhanced metrics...\")\n",
        "\n",
        "def evaluate_model_comprehensive(model, X_test, y_test, X_val, y_val):\n",
        "    \"\"\"Comprehensive model evaluation with better threshold selection\"\"\"\n",
        "\n",
        "    # Get predictions\n",
        "    test_predictions = model.predict(X_test, verbose=0).flatten()\n",
        "    val_predictions = model.predict(X_val, verbose=0).flatten()\n",
        "\n",
        "    # Multiple threshold selection strategies\n",
        "    thresholds = {}\n",
        "\n",
        "    # Strategy 1: F1-maximizing threshold\n",
        "    val_precisions, val_recalls, val_thresholds = precision_recall_curve(y_val, val_predictions)\n",
        "    val_f1_scores = 2 * (val_precisions[:-1] * val_recalls[:-1]) / (val_precisions[:-1] + val_recalls[:-1] + 1e-8)\n",
        "    thresholds['f1_optimal'] = val_thresholds[np.argmax(val_f1_scores)]\n",
        "\n",
        "    # Strategy 2: Balanced accuracy threshold\n",
        "    balanced_accuracies = []\n",
        "    for threshold in np.arange(0.1, 0.9, 0.05):\n",
        "        preds = (val_predictions > threshold).astype(int)\n",
        "        cm = confusion_matrix(y_val, preds)\n",
        "        if cm.shape == (2, 2):\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "            balanced_acc = (sensitivity + specificity) / 2\n",
        "            balanced_accuracies.append((threshold, balanced_acc))\n",
        "\n",
        "    if balanced_accuracies:\n",
        "        thresholds['balanced_optimal'] = max(balanced_accuracies, key=lambda x: x[1])[0]\n",
        "\n",
        "    # Strategy 3: Geometric mean threshold\n",
        "    gmeans = []\n",
        "    for threshold in np.arange(0.1, 0.9, 0.05):\n",
        "        preds = (val_predictions > threshold).astype(int)\n",
        "        cm = confusion_matrix(y_val, preds)\n",
        "        if cm.shape == (2, 2):\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "            gmean = np.sqrt(sensitivity * specificity)\n",
        "            gmeans.append((threshold, gmean))\n",
        "\n",
        "    if gmeans:\n",
        "        thresholds['gmean_optimal'] = max(gmeans, key=lambda x: x[1])[0]\n",
        "\n",
        "    # Use F1-optimal as default\n",
        "    optimal_threshold = thresholds.get('f1_optimal', 0.5)\n",
        "\n",
        "    # Evaluate with optimal threshold\n",
        "    predicted_classes = (test_predictions > optimal_threshold).astype(int)\n",
        "\n",
        "    # Comprehensive metrics\n",
        "    conf_matrix = confusion_matrix(y_test, predicted_classes)\n",
        "    accuracy = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
        "\n",
        "    if conf_matrix.shape == (2, 2):\n",
        "        tn, fp, fn, tp = conf_matrix.ravel()\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        f1 = 2 * (precision * sensitivity) / (precision + sensitivity + 1e-8)\n",
        "        balanced_accuracy = (sensitivity + specificity) / 2\n",
        "        gmean = np.sqrt(sensitivity * specificity)\n",
        "    else:\n",
        "        sensitivity = specificity = precision = f1 = balanced_accuracy = gmean = 0\n",
        "\n",
        "    # AUC and PR AUC\n",
        "    auc_roc = roc_auc_score(y_test, test_predictions)\n",
        "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, test_predictions)\n",
        "    auc_pr = auc(recall_curve, precision_curve)\n",
        "\n",
        "    # Print comprehensive results\n",
        "    print(\"=\" * 70)\n",
        "    print(\"ENHANCED LSTM MODEL PERFORMANCE\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Accuracy:          {accuracy:.3f}\")\n",
        "    print(f\"Balanced Accuracy: {balanced_accuracy:.3f}\")\n",
        "    print(f\"Sensitivity:       {sensitivity:.3f}\")\n",
        "    print(f\"Specificity:       {specificity:.3f}\")\n",
        "    print(f\"Precision:         {precision:.3f}\")\n",
        "    print(f\"F1-Score:          {f1:.3f}\")\n",
        "    print(f\"G-Mean:            {gmean:.3f}\")\n",
        "    print(f\"AUC-ROC:           {auc_roc:.3f}\")\n",
        "    print(f\"AUC-PR:            {auc_pr:.3f}\")\n",
        "    print(f\"Optimal Threshold: {optimal_threshold:.3f}\")\n",
        "\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "    print(f\"\\nDetailed Classification Report:\")\n",
        "    print(classification_report(y_test, predicted_classes,\n",
        "                              target_names=['Class 0 (Alive)', 'Class 1 (Deceased)']))\n",
        "\n",
        "    return {\n",
        "        'predictions': test_predictions,\n",
        "        'optimal_threshold': optimal_threshold,\n",
        "        'metrics': {\n",
        "            'accuracy': accuracy,\n",
        "            'sensitivity': sensitivity,\n",
        "            'specificity': specificity,\n",
        "            'precision': precision,\n",
        "            'f1': f1,\n",
        "            'auc_roc': auc_roc,\n",
        "            'auc_pr': auc_pr\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Run comprehensive evaluation\n",
        "if 'lstm_model' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
        "    try:\n",
        "        # Create validation set from training data for threshold tuning\n",
        "        X_train_temp, X_val, y_train_temp, y_val = train_test_split(\n",
        "            X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        "        )\n",
        "\n",
        "        results = evaluate_model_comprehensive(lstm_model, X_test, y_test, X_val, y_val)\n",
        "\n",
        "        # Enhanced visualization\n",
        "        create_comprehensive_plots(history, results, y_test)\n",
        "\n",
        "        # Feature importance analysis\n",
        "        print(\"\\nStep 7: Enhanced Feature Importance Analysis...\")\n",
        "        importance_scores = analyze_feature_importance_enhanced(lstm_model, X_train, lstm_data['feature_names'], y_train)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in enhanced evaluation: {e}\")\n",
        "\n",
        "def create_comprehensive_plots(history, results, y_test):\n",
        "    \"\"\"Create enhanced visualization plots\"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, results['predictions'])\n",
        "    auc_roc = results['metrics']['auc_roc']\n",
        "    axes[0, 0].plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {auc_roc:.3f}')\n",
        "    axes[0, 0].plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
        "    axes[0, 0].set_xlabel('False Positive Rate')\n",
        "    axes[0, 0].set_ylabel('True Positive Rate')\n",
        "    axes[0, 0].set_title('ROC Curve')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True)\n",
        "\n",
        "    # Precision-Recall Curve\n",
        "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, results['predictions'])\n",
        "    auc_pr = results['metrics']['auc_pr']\n",
        "    axes[0, 1].plot(recall_curve, precision_curve, 'r-', linewidth=2, label=f'PR AUC = {auc_pr:.3f}')\n",
        "    axes[0, 1].set_xlabel('Recall')\n",
        "    axes[0, 1].set_ylabel('Precision')\n",
        "    axes[0, 1].set_title('Precision-Recall Curve')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True)\n",
        "\n",
        "    # Training history - Loss\n",
        "    axes[0, 2].plot(history.history['loss'], 'b-', label='Train Loss')\n",
        "    axes[0, 2].plot(history.history['val_loss'], 'r-', label='Val Loss')\n",
        "    axes[0, 2].set_xlabel('Epoch')\n",
        "    axes[0, 2].set_ylabel('Loss')\n",
        "    axes[0, 2].set_title('Training History - Loss')\n",
        "    axes[0, 2].legend()\n",
        "    axes[0, 2].grid(True)\n",
        "\n",
        "    # Training history - AUC\n",
        "    axes[1, 0].plot(history.history.get('auc', history.history.get('AUC', [])), 'b-', label='Train AUC')\n",
        "    axes[1, 0].plot(history.history.get('val_auc', history.history.get('val_AUC', [])), 'r-', label='Val AUC')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('AUC')\n",
        "    axes[1, 0].set_title('Training History - AUC')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True)\n",
        "\n",
        "    # Probability distribution\n",
        "    axes[1, 1].hist([results['predictions'][y_test == 0], results['predictions'][y_test == 1]],\n",
        "                   bins=20, alpha=0.7, label=['Class 0', 'Class 1'],\n",
        "                   color=['blue', 'red'])\n",
        "    axes[1, 1].axvline(results['optimal_threshold'], color='black', linestyle='--',\n",
        "                      label=f'Threshold = {results[\"optimal_threshold\"]:.2f}')\n",
        "    axes[1, 1].set_xlabel('Predicted Probability')\n",
        "    axes[1, 1].set_ylabel('Count')\n",
        "    axes[1, 1].set_title('Prediction Distribution')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True)\n",
        "\n",
        "    # Learning rate history\n",
        "    if 'lr' in history.history:\n",
        "        axes[1, 2].plot(history.history['lr'], 'g-', linewidth=2)\n",
        "        axes[1, 2].set_xlabel('Epoch')\n",
        "        axes[1, 2].set_ylabel('Learning Rate')\n",
        "        axes[1, 2].set_title('Learning Rate Schedule')\n",
        "        axes[1, 2].set_yscale('log')\n",
        "        axes[1, 2].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_feature_importance_enhanced(model, X_data, feature_names, y_data, n_permutations=10):\n",
        "    \"\"\"Enhanced feature importance analysis with multiple permutations\"\"\"\n",
        "    print(\"Enhanced Feature Importance Analysis:\")\n",
        "\n",
        "    # Baseline performance\n",
        "    baseline_predictions = model.predict(X_data, verbose=0).flatten()\n",
        "    baseline_auc = roc_auc_score(y_data, baseline_predictions) if len(np.unique(y_data)) > 1 else 0.5\n",
        "\n",
        "    importance_scores = {i: [] for i in range(len(feature_names))}\n",
        "\n",
        "    # Multiple permutations for stability\n",
        "    for perm_idx in range(n_permutations):\n",
        "        for feature_idx in range(len(feature_names)):\n",
        "            X_permuted = X_data.copy()\n",
        "\n",
        "            # Permute the feature\n",
        "            original_feature = X_permuted[:, :, feature_idx].copy()\n",
        "            permuted_feature = original_feature.reshape(-1)\n",
        "            np.random.shuffle(permuted_feature)\n",
        "            X_permuted[:, :, feature_idx] = permuted_feature.reshape(original_feature.shape)\n",
        "\n",
        "            # Calculate performance with permuted feature\n",
        "            permuted_predictions = model.predict(X_permuted, verbose=0).flatten()\n",
        "            permuted_auc = roc_auc_score(y_data, permuted_predictions) if len(np.unique(y_data)) > 1 else 0.5\n",
        "\n",
        "            # Importance score is the drop in performance\n",
        "            importance = baseline_auc - permuted_auc\n",
        "            importance_scores[feature_idx].append(importance)\n",
        "\n",
        "    # Average importance across permutations\n",
        "    avg_importance = [(idx, np.mean(scores)) for idx, scores in importance_scores.items()]\n",
        "    avg_importance.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    print(\"\\nTop 10 Most Important Features:\")\n",
        "    for i, (feature_idx, importance) in enumerate(avg_importance[:10]):\n",
        "        feature_name = feature_names[feature_idx]\n",
        "        std_dev = np.std(importance_scores[feature_idx])\n",
        "        print(f\"  {i+1:2d}. {feature_name}: {importance:.4f}  {std_dev:.4f}\")\n",
        "\n",
        "    return avg_importance"
      ],
      "metadata": {
        "id": "TIIj_yNhRaQS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}